{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "8SD4RO2F-xOT"
   },
   "outputs": [],
   "source": [
    "gen_tpu = 1 << 0\n",
    "gen_gpu = 1 << 1\n",
    "gen_pytorch = 1 << 2\n",
    "gen_tf1 = 1 << 3\n",
    "gen_tf2 = 1 << 4\n",
    "gen_stylegan2 = 1 << 5\n",
    "gen_sg2_nagolinc_pt = 1 << 6\n",
    "gen_sg2_nvlabs_ada_pt = 1 << 7\n",
    "gen_sg2_tf1 = 1 << 8\n",
    "gen_sg2_tf2 = 1 << 9\n",
    "gen_sg2_rosasalberto_tf2 = 1 << 10\n",
    "gen_anime_tf2_npy = 1 << 11\n",
    "gen_tadne_tf2_npy = 1 << 12\n",
    "gen_anime_protraits_tf2_npy = 1 << 13\n",
    "gen_abctract_art_tf2_npy = 1 << 14\n",
    "gen_tf2_npy = 1 << 15\n",
    "gen_sg2_moono_tf2 = 1 << 16\n",
    "gen_anime_tf2 = 1 << 17\n",
    "gen_sg2_shawwn_tpu = 1 << 18\n",
    "gen_sg2_cyrilzakka_tpu = 1 << 19\n",
    "gen_sg2_nvlabs = 1 << 20\n",
    "gen_anime = 1 << 21\n",
    "gen_sg2_shawwn = 1 << 22\n",
    "gen_tadne = 1 << 23\n",
    "gen_sg2_nvlabs_ada = 1 << 24\n",
    "gen_anime_protraits = 1 << 25\n",
    "gen_abctract_art = 1 << 26\n",
    "gen_wavegan = 1 << 27\n",
    "gen_drums = 1 << 28\n",
    "gen_mp3 = 1 << 29\n",
    "gen_wav = 1 << 30\n",
    "gen_png = 1 << 31\n",
    "gen_jpeg = 1 << 32\n",
    "gen_heatmap = 1 << 33\n",
    "gen_thdne = 1 << 34\n",
    "gen_wg_stereo = 1 << 35\n",
    "gen_wg_st_swap = 1 << 36\n",
    "gen_stylegan3 = 1 << 37\n",
    "gen_sg3_nvlabs_pt = 1 << 38\n",
    "gen_sg2_models = 1 << 39\n",
    "gen_sg3_models = 1 << 40\n",
    "gen_sg2_ext_models = 1 << 41\n",
    "gen_sg2_pt_models = 1 << 42\n",
    "gen_sg2_tf1_models = 1 << 43\n",
    "gen_sg3_Expl0dingCat_pt = 1 << 44\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Q08NMGPUAfmh"
   },
   "outputs": [],
   "source": [
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_sg2_models\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_sg2_ext_models\n",
    "#generate = gen_gpu | gen_pytorch | gen_stylegan2 | gen_sg2_nvlabs_ada_pt | gen_sg2_models\n",
    "#generate = gen_gpu | gen_pytorch | gen_stylegan2 | gen_stylegan3 | gen_sg3_nvlabs_pt | gen_sg3_models\n",
    "generate = gen_gpu | gen_pytorch | gen_stylegan2 | gen_stylegan3 | gen_sg3_Expl0dingCat_pt | gen_sg3_models\n",
    "\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_anime_protraits\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_abctract_art\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne\n",
    "#generate = gen_gpu | gen_pytorch | gen_sg2_nagolinc_pt | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne\n",
    "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_drums\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_anime_protraits | gen_wavegan | gen_drums\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_abctract_art | gen_wavegan | gen_drums\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne | gen_wavegan | gen_drums\n",
    "#generate = gen_gpu | gen_pytorch | gen_sg2_nagolinc_pt | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne | gen_wavegan | gen_drums\n",
    "\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs | gen_anime_protraits | gen_tf2_npy\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_anime_protraits | gen_tf2_npy\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_abctract_art | gen_tf2_npy\n",
    "\n",
    "#generate = gen_gpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_anime_protraits_tf2_npy\n",
    "#generate = gen_gpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_abctract_art_tf2_npy\n",
    "#generate = gen_tpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_anime_protraits_tf2_npy\n",
    "#generate = gen_tpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_abctract_art_tf2_npy\n",
    "\n",
    "#generate = gen_tpu | gen_tf1 | gen_wavegan | gen_drums\n",
    "\n",
    "#generate = gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_anime_protraits_tf2_npy\n",
    "#generate = gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_abctract_art_tf2_npy\n",
    "#generate = gen_tf1 | gen_wavegan | gen_drums\n",
    "\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_thdne\n",
    "#generate = gen_gpu | gen_pytorch | gen_stylegan2 | gen_sg2_nvlabs_ada_pt | gen_thdne\n",
    "#generate = gen_gpu | gen_pytorch | gen_stylegan2 | gen_sg2_nvlabs_ada_pt | gen_tadne\n",
    "\n",
    "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_wg_stereo | gen_drums\n",
    "#generate = gen_tf1 | gen_wavegan | gen_wg_stereo | gen_drums\n",
    "#generate = gen_tf1 | gen_wavegan | gen_wg_stereo | gen_wg_st_swap | gen_drums\n",
    "\n",
    "generate = generate | gen_wg_stereo | gen_wg_st_swap\n",
    "\n",
    "#generate = generate | gen_png | gen_wav\n",
    "generate = generate | gen_jpeg | gen_mp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "8KNsllTIn76c"
   },
   "outputs": [],
   "source": [
    "sg2_models=0\n",
    "sg2_pt_models=0\n",
    "sg2_tf1_models=0\n",
    "sg2_ext_models=0\n",
    "sg3_models=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Mkq7jIXnJm1W"
   },
   "outputs": [],
   "source": [
    "##biosemi16-2:\n",
    "ch_names_wg = ['FP1','F3','T7','C3','P3','Pz','O1','O2','P4','C4','T8','F4','FP2','Fz']\n",
    "ch_locations_wg=[0,3,6,7,11,12,14,16,18,22,23,26,29,30]\n",
    "\n",
    "#biosemi32_l14\n",
    "ch_names_wg_l = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','PO3','O1']\n",
    "ch_locations_wg_l=[0,1,2,3,4,5,6,7,8,9,10,11,13,14]\n",
    "#biosemi32_r14\n",
    "ch_names_wg_r_ = ['O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','FP2']\n",
    "ch_locations_wg_r_=[15,16,17,18,19,20,21,22,23,24,25,26,27,28,29]\n",
    "#biosemi32_r14_\n",
    "ch_names_wg_r = ['FP2','AF4','F8','F4','FC2','FC6','T8','C4','CP2','CP6','P8','P4','PO4','O2']\n",
    "ch_locations_wg_r=[29,28,27,26,25,24,23,22,21,20,19,18,17,16,15]\n",
    "\n",
    "#biosemi32\n",
    "ch_names_sg2 = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','FP2','Fz','Cz']\n",
    "ch_locations_sg2=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
    "##Bernard's 19ch:\n",
    "#ch_names = [\"FP2\",\"FP1\",\"O2\",\"T6\",\"T4\",\"F8\",\"F4\",\"C4\",\"P4\",\"F3\",\"C3\",\"P3\",\"O1\",\"T5\",\"T3\",\"F7\",\"FZ\",\"PZ\"]#,\"other\"]\n",
    "#ch_locations=[4,24,0,1,2,3,5,6,7,25,26,27,28,29,30,31,16,12]#,8]\n",
    "##Bernard's 2ch:\n",
    "#ch_names = [\"FP2\",\"FP1\"]#,\"other\"]\n",
    "#ch_locations=[4,24]#,8]\n",
    "\n",
    "bands = [[8.,12.]]\n",
    "#bands = [[4.,7.],[8.,12.]]\n",
    "#bands = [[8.,12.],[8.,12.],[8.,12.]]\n",
    "methods = ['coh']\n",
    "#methods = ['plv']\n",
    "#methods = ['ciplv']\n",
    "#methods = ['ppc']\n",
    "#methods = ['pli']\n",
    "#methods = ['wpli']\n",
    "#methods = ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']\n",
    "\n",
    "#vol=1\n",
    "vol=6\n",
    "#vol=0.1\n",
    "\n",
    "duration=5*1/8\n",
    "overlap=0\n",
    "#overlap=duration-0.1\n",
    "xsize=512\n",
    "ysize=512\n",
    "#xsize=512/2\n",
    "#ysize=512/2\n",
    "hz=44100\n",
    "#fps=hz/(32768)\n",
    "\n",
    "#if generate_stylegan2:\n",
    "fps_sg2=1\n",
    "#if generate_wavegan:\n",
    "fps_wg=10\n",
    "#fps_wg=hz/(32768*2)\n",
    "fps_sg2=10\n",
    "#fps_sg2=fps_wg*10\n",
    "#fps_sg2=fps_wg*0.5\n",
    "#fps_sg2=fps_wg\n",
    "fps_hm=fps_wg\n",
    "\n",
    "#if 1/fps_wg-0.2>duration:\n",
    "#  duration=1/fps_wg-0.2\n",
    "#  overlap=duration-0.1\n",
    "if 2*1/fps_wg>duration:\n",
    "  duration=2*1/fps_wg\n",
    "  overlap=0\n",
    "\n",
    "if generate&gen_wavegan:\n",
    "  dim_wg = 100\n",
    "if generate&gen_stylegan2:\n",
    "  dim_sg2 = 512\n",
    "if generate&gen_sg2_shawwn:\n",
    "  dim_sg2 = 1024\n",
    "\n",
    "stepSize = 1/pow(2,24)\n",
    "vref = 2.50 #2.5V voltage ref +/- 250nV\n",
    "gain = 8\n",
    "\n",
    "vscale = (vref/gain)*stepSize #volts per step.\n",
    "uVperStep = 1000000 * ((vref/gain)*stepSize) #uV per step.\n",
    "scalar = 1/(1000000 / ((vref/gain)*stepSize)) #steps per uV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "exdhoEe151Ja"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7WErNtyaMBkg",
    "outputId": "a9b8f194-8b1d-4584-f2a7-a923acda21f7"
   },
   "outputs": [],
   "source": [
    "if generate&gen_tf1:\n",
    "  import os\n",
    "  if 'COLAB_GPU' in os.environ:\n",
    "    print(\"I'm running on Colab\")\n",
    "    %tensorflow_version 1.x\n",
    "  else:\n",
    "    !pip install testresources\n",
    "    !pip install tensorflow==1.15\n",
    "  import tensorflow as tf\n",
    "  print('Tensorflow version: {}'.format(tf.__version__) )\n",
    "if generate&gen_tf2:\n",
    "  import os\n",
    "  if 'COLAB_GPU' in os.environ:\n",
    "    print(\"I'm running on Colab\")\n",
    "    %tensorflow_version 2.x\n",
    "  else:\n",
    "#    !pip install tensorflow==2.6\n",
    "    !pip install tensorflow==2.10.0rc3\n",
    "  import tensorflow as tf\n",
    "  print('Tensorflow version: {}'.format(tf.__version__) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "BLsvM-V7Oh9S"
   },
   "outputs": [],
   "source": [
    "if generate&gen_tf1:\n",
    " if generate&gen_gpu:\n",
    "  from tensorflow.python.client import device_lib\n",
    "  print(device_lib.list_local_devices())\n",
    "\n",
    " if generate&gen_tpu:\n",
    "  import os\n",
    "  import tensorflow.compat.v1 as tf\n",
    "  tf.disable_eager_execution()\n",
    "  import pprint\n",
    "  assert 'COLAB_TPU_ADDR' in os.environ, 'Did you forget to switch to TPU?'\n",
    "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
    "\n",
    "  with tf.Session(tpu_address) as sess:\n",
    "    devices = sess.list_devices()\n",
    "  pprint.pprint(devices)\n",
    "  device_is_tpu = [True if 'TPU' in str(x) else False for x in devices]\n",
    "  assert True in device_is_tpu, 'Did you forget to switch to TPU?'\n",
    "\n",
    "if generate&gen_tf2:\n",
    " try: # detect TPUs\n",
    "  tpu = None\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.TPUStrategy(tpu)\n",
    " except ValueError: # detect GPUs\n",
    "  strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
    "  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
    "  #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
    "\n",
    " print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iaHracqcMbGG",
    "outputId": "6ec2357c-1de3-4b09-ceaa-5f5c03f998f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content\n",
      "fatal: destination path '/content/stylegan3-Expl0dingCat-pytorch' already exists and is not an empty directory.\n",
      "/mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/stylegan3-Expl0dingCat-pytorch\n"
     ]
    }
   ],
   "source": [
    "%cd /content\n",
    "if generate&gen_sg3_nvlabs_pt:\n",
    "  !git clone https://github.com/NVlabs/stylegan3.git /content/stylegan3-nvlabs-pytorch\n",
    "  %cd /content/stylegan3-nvlabs-pytorch\n",
    "if generate&gen_sg3_Expl0dingCat_pt:\n",
    "  !git clone https://github.com/Expl0dingCat/stylegan3-modified.git /content/stylegan3-Expl0dingCat-pytorch\n",
    "  %cd /content/stylegan3-Expl0dingCat-pytorch\n",
    "\n",
    "if generate&gen_sg2_nvlabs:\n",
    "  !git clone https://github.com/NVlabs/stylegan2.git /content/stylegan2-nvlabs\n",
    "  %cd /content/stylegan2-nvlabs\n",
    "if generate&gen_sg2_nvlabs_ada:\n",
    "  !git clone https://github.com/NVlabs/stylegan2-ada.git /content/stylegan2-nvlabs-ada\n",
    "  %cd /content/stylegan2-nvlabs-ada\n",
    "if generate&gen_sg2_shawwn:\n",
    "  !git clone https://github.com/shawwn/stylegan2.git /content/stylegan2-shawwn\n",
    "  %cd /content/stylegan2-shawwn\n",
    "if generate&gen_sg2_cyrilzakka_tpu:\n",
    "  !git clone https://github.com/cyrilzakka/stylegan2-tpu.git /content/stylegan2-cyrilzakka-tpu\n",
    "  %cd /content/stylegan2-cyrilzakka-tpu\n",
    "if generate&gen_sg2_shawwn_tpu:\n",
    "  !git clone --branch tpu https://github.com/shawwn/stylegan2.git /content/stylegan2-shawwn-tpu\n",
    "  %cd /content/stylegan2-shawwn-tpu\n",
    "if generate&gen_sg2_moono_tf2:\n",
    "  !git clone https://github.com/moono/stylegan2-tf-2.x.git /content/stylegan2-moono-tf2\n",
    "  %cd /content/stylegan2-moono-tf2\n",
    "if generate&gen_sg2_rosasalberto_tf2:\n",
    "  !git clone https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x.git /content/stylegan2-rosasalberto-tf2\n",
    "  %cd /content/stylegan2-rosasalberto-tf2\n",
    "if generate&gen_sg2_nagolinc_pt:\n",
    "  !git clone https://github.com/nagolinc/stylegan2-pytorch.git /content/stylegan2-nagolinc-pytorch\n",
    "  %cd /content/stylegan2-nagolinc-pytorch\n",
    "if generate&gen_sg2_nvlabs_ada_pt:\n",
    "  !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git /content/stylegan2-nvlabs-ada-pytorch\n",
    "  %cd /content/stylegan2-nvlabs-ada-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "u5dsTawDKpe1"
   },
   "outputs": [],
   "source": [
    "#fileid='1aUrChOhq5jDEddZK1v_Dp1vYNlHSBL9o'\n",
    "#filename='sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl'\n",
    "#!mkdir '/content/model'\n",
    "\n",
    "def download_file_from_google_drive(file_id,dest_path):\n",
    "  import os.path\n",
    "  if not os.path.isfile(dest_path):\n",
    "    !mkdir -p $(dirname {dest_path})\n",
    "    !wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&id='{file_id} -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' > confirm.txt\n",
    "    !wget --load-cookies cookies.txt -O {dest_path} 'https://docs.google.com/uc?export=download&id='{file_id}'&confirm='$(<confirm.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uqYszSxLKjt1",
    "outputId": "63086d46-8f15-4714-a67b-6942a96ca0fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (9.2.0)\n",
      "Requirement already satisfied: tqdm in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (4.64.0)\n",
      "Requirement already satisfied: imageio==2.4.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (2.4.1)\n",
      "Requirement already satisfied: pillow in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from imageio==2.4.1) (9.2.0)\n",
      "Requirement already satisfied: numpy in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from imageio==2.4.1) (1.23.2)\n",
      "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: pyspng==0.1.0 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.1.0)\n",
      "Requirement already satisfied: numpy in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pyspng==0.1.0) (1.23.2)\n",
      "mkdir: cannot create directory ‘/content/out’: File exists\n"
     ]
    }
   ],
   "source": [
    "#!pip install googledrivedownloader\n",
    "#from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "files_path=[]\n",
    "if generate&gen_drums:\n",
    "  files_path = [['1ZJir-_ls92s56LFmw_HVuQ7ANqFFN5WG', '/content/model/model.ckpt-18637.data-00000-of-00001'],\n",
    "              ['1d5ayi4w-70AvKYPk-8sXzsSzpK1jMRgm', '/content/model/model.ckpt-18637.index'],  \n",
    "              ['15CWn0yK3FKsHbAOGNLQYVg4eZC1oNIrL', '/content/model/model.ckpt-18637.meta'],  \n",
    "              ['1x5QEFeoochk-rhvtvJc98kIB5_SAwn0u', '/content/model/args.txt'],  \n",
    "              ['1UgSZaBTCTDXaPbfv8l0wmpHbD5u051o5', '/content/model/graph.pbtxt'],  \n",
    "              ['1LGfAkuOFvA3NdFE_rOq9WyeXGGgEOf0F', '/content/model/checkpoint'],  \n",
    "              ['1bPD0bXCC_18oWbUjmjkacF-CShlA6yNd', '/content/model/infer/infer.pbtxt'],  \n",
    "              ['13OQuRx7Ku6KJ9o9FU-JN3yB0Njul9Vem', '/content/model/infer/infer.meta']]\n",
    "for i in range(len(files_path)):\n",
    "#  gdd.download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
    "  download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
    "files_path=[]\n",
    "if generate&gen_abctract_art:\n",
    "  files_path = [['1ie1vWw1JNsfrZWRtMvhteqzVz4mt4KGa', '/content/model/sg2-ada_abstract_network-snapshot-000188.pkl',\n",
    "                 'sg2-ada_abstract_network-snapshot-000188','stylegan2-ada']]\n",
    "if generate&gen_anime_protraits:\n",
    "  files_path = [['1aUrChOhq5jDEddZK1v_Dp1vYNlHSBL9o', '/content/model/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl', \n",
    "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664','stylegan2-ada']]\n",
    "if generate&gen_tadne:\n",
    "#  files_path = [['1sdnL-lIl2kYAnuleafK-5GPiLNHfxh4W', '/content/model/sg2-ext_aydao-anime-danbooru2019s-512-5268480.pkl', \n",
    "#                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480','stylegan2-shawwn']]\n",
    "  files_path = [['1LCkyOPmcWBsPlQX_DxKAuPM1Ew_nh83I', '/content/model/sg2-ext_network-tadne.pkl', \n",
    "                 'sg2-ext_network-tadne','stylegan2-shawwn']]\n",
    "  #files_path = [['1l5zG0g_RMEAwFUK_veD1EZweVEoY9gUT', '/content/model/aydao-anime-danbooru2019s-512-5268480.pkl']]\n",
    "#  files_path = [['1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle', '/content/model/network-snapshot-017325.pkl']]\n",
    "#  files_path = [['1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez', '/content/model/network-snapshot-018528.pkl']]\n",
    "\n",
    "if generate&gen_anime:\n",
    "  files_path = [['1YckI8gwqPbZBI8X4eaQAJCgWx-CqCTdi', '/content/model/sg2_anime_network-snapshot-018528.pkl', \n",
    "                 'sg2_anime_network-snapshot-018528']]\n",
    "if generate&gen_anime_tf2:\n",
    "  files_path = [['1-1neAg_FUymzBvCStMe7CfV94-VD22kk', '/content/stylegan2-moono-tf2/official-converted/cuda/ckpt-0.data-00000-of-00001'],\n",
    "              ['1-4ih0wi68y4xH5tg0_kClpuWDSnvdmoE', '/content/stylegan2-moono-tf2/official-converted/cuda/ckpt-0.index'],\n",
    "              ['1-C6H58vmfZykqWpilR1u9puH8oPFQtcQ', '/content/stylegan2-moono-tf2/official-converted/cuda/checkpoint']]\n",
    "if generate&gen_abctract_art_tf2_npy:\n",
    "#  files_path = [['1cauGWIVGGiMJA0_OZftJU3-rVAVdFwZM', '/content/stylegan2-rosasalberto-tf2/weights/sg2-ada_abstract_network-snapshot-000188.npy',\n",
    "#                 'sg2-ada_abstract_network-snapshot-000188']]\n",
    "  files_path = [['1-CXjDfP_g5ZD5aC9AwOXEC5WNIf5dCEh', '/content/stylegan2-rosasalberto-tf2/weights/sg2-ada_abstract_network-snapshot-000188.npy',\n",
    "                 'sg2-ada_abstract_network-snapshot-000188']]\n",
    "if generate&gen_anime_protraits_tf2_npy:\n",
    "#  files_path = [['1-Cp-RRJnjvfCIrD0ylaUYxvLbxN4aj8K', '/content/stylegan2-rosasalberto-tf2/weights/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.npy', \n",
    "#                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664']]\n",
    "  files_path = [['1-AiS_pdkssIz_nU9GYSLJRZiXgJpCrSo', '/content/stylegan2-rosasalberto-tf2/weights/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.npy', \n",
    "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664']]\n",
    "if generate&gen_tadne_tf2_npy:\n",
    "  files_path = [['1-36-rfueVBWvigBvCuwzrXKl1AeVtzu6', '/content/stylegan2-rosasalberto-tf2/weights/sg2-ext_aydao-anime-danbooru2019s-512-5268480.npy', \n",
    "                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480']]\n",
    "if generate&gen_anime_tf2_npy:\n",
    "  files_path = [['1--ajK29hgTTAYNcZhQk9lLFhwUlXqxNA', '/content/stylegan2-rosasalberto-tf2/weights/sg2_anime_network-snapshot-018528.npy', \n",
    "                 'sg2_anime_network-snapshot-018528']]\n",
    "if generate&gen_thdne:\n",
    "  files_path = [['1s2mk6QP5jqQFWquP1oNsWLggrMdT-cOY', '/content/model/sg2-ext_thdne.pkl', \n",
    "                 'sg2-ext_thdne','stylegan2-shawwn']]\n",
    "#if generate&gen_thdne_256:\n",
    "#  files_path = [['1-J_b-nX0KnKK_fDkZ8KC0RgoP9CTmAxy', '/content/model/sg2-ext_network-thdne_256.pkl', \n",
    "#                 'sg2-ext_network-thdne_256','stylegan2-shawwn']]\n",
    "#if generate&gen_thdne_256_pt:\n",
    "#  files_path = [['1L3joymV2LartzOSMXyzzniGr57Gqf_1z', '/content/model/sg2-ada-pt_thdne-snapshot-256-latest.pkl',\n",
    "#                 'sg2-ada-pt_thdne-snapshot-256-latest','stylegan2-ada-pytorch']]\n",
    "\n",
    "#https://drive.google.com/file/d/1ie1vWw1JNsfrZWRtMvhteqzVz4mt4KGa/view?usp=sharing\n",
    "#network-snapshot-000188.pkl\n",
    "#https://drive.google.com/file/d/1YckI8gwqPbZBI8X4eaQAJCgWx-CqCTdi/view?usp=sharing\n",
    "#network-snapshot-018528.pkl\n",
    "\n",
    "for i in range(len(files_path)):\n",
    "#  gdd.download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
    "  download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
    "\n",
    "#if generate&gen_sg2_ext_models:\n",
    "#  files_path = [['1KxhHmGbJvAIbVpFT5u6UNntiPwq6Cjtb', '/content/sg2-ext-model/', 'sg2-ext-cosplay-faces-512x512-px_cosplayface-snapshot-004000-18160-FID367', '.pkl', 'sg2_ext_model'],\n",
    "#                ['1pOYc3O1YdlOpHYnA9LLhti4isOz1vrPl', '/content/sg2-ext-model/', 'sg2-ext-cosplay-faces-512x512-px_cosplayface-snapshot-001360-19520-FID359', '.pkl', 'sg2_ext_model']]\n",
    "#  download_file_from_google_drive(file_id=files_path[sg2_ext_models][0], dest_path=files_path[sg2_ext_models][1]+files_path[sg2_ext_models][2]+files_path[sg2_ext_models][3])\n",
    "#  files_path[0][1]=files_path[sg2_ext_models][1]+files_path[sg2_ext_models][2]+files_path[sg2_ext_models][3]\n",
    "\n",
    "if generate&gen_sg2_models:\n",
    "  files_path = [\n",
    "                ['1h8zxPcVrSqsgaY6XZS8-ciIAyYoJBM6t', '/content/sg2-model/', 'sg2_GANscapes', '.pkl', 'sg2_model'],\n",
    "                ['1yruyUn4IdykQmdaOT5Nm9Na18N4UtHDQ', '/content/sg2-model/', 'sg2_minecraft-gan-2020-12-22', '.pkl', 'sg2_model'],\n",
    "                ['1aD0cgxnP_C1MSBKkZm1PvGXZLbKGg_hk', '/content/sg2-model/', 'sg2_modern-art_network-snapshot-026392', '.pkl', 'sg2_model'],\n",
    "                ['1MRPhvrUrCJBoGj4H139bD3Mw2aVYHygs', '/content/sg2-model/', 'sg2_painting-faces_network-snapshot-metfaces2', '.pkl', 'sg2_model'],\n",
    "                ['1Zb5m_ZGMtd4ozz1uiiNI7lpYc-J4G89B', '/content/sg2-model/', 'sg2_textures', '.pkl', 'sg2_model'],\n",
    "                ['1Jb8UqqoAwTtjIx0bTci21EgSsCPHYtWW', '/content/sg2-model/', 'sg2_trypophobia', '.pkl', 'sg2_model'],\n",
    "                ['1_6IrHv971aTBqiI1OcsCriPSaKJah9WI', '/content/sg2-model/', 'sg2_wildlife_network-snapshot-027750', '.pkl', 'sg2_model'],\n",
    "                ['1ZstIAlDdoZcoIoqR9KVYoS0mbDq14gFV', '/content/sg2-model/', 'StyleGAN2_microscopev1', '.pkl', 'sg2_model'],\n",
    "                ['1vq1zasHT1PJS6l7-IBK7NU2SRWUc3FQO', '/content/sg2-model/', 'sg2_fursona_network-e621-r-512-3194880', '.pkl', 'sg2_model'],\n",
    "                ['1394o1nrjWpOPc-phbu4kY11jCu7V7ma7', '/content/sg2-model/', 'sg2_Maps_mapdreamer', '.pkl', 'sg2_model'],\n",
    "                ['1o1rajqJ_USE_VNoJkDW31oHdNm6aAwI1', '/content/sg2-model/', 'sg2_my-little-pony_network-ponies-1024-151552', '.pkl', 'sg2_model'],\n",
    "                ['1JpTTC0C7bKIZ4mggEIByU70gg_3f61dx', '/content/sg2-model/', 'stylegan2-car-config-e', '.pkl', 'sg2_model'],\n",
    "                ['18x-SfrvmwbUFECVXTp56UJj84uTeQGQM', '/content/sg2-model/', 'stylegan2-car-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qsLYOWbVKqKai5ZKpbVlEuiOB1_OKguK', '/content/sg2-model/', 'stylegan2-cat-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1IN8ThfVAWDSNKybUJmWixz1ES9yQpED8', '/content/sg2-model/', 'stylegan2-church-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qceKeMe0NUWZgnw5Dl5smVAkmLXcygai', '/content/sg2-model/', 'stylegan2-ffhq-config-e', '.pkl', 'sg2_model'],\n",
    "                ['1GVYtx73gtC3IUktrqYD-0zarlU53Jw-H', '/content/sg2-model/', 'stylegan2-ffhq-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1abhVX-KB5u-0vUXHwk9ba2FTww442Oj5', '/content/sg2-model/', 'stylegan2-horse-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1mpAOmlxrnPWy_4RjIJxnulRHI6oX09JB', '/content/sg2-model/', 'stylegan2-imagenet-512_model.ckpt-533504', '.pkl', 'sg2_model'],\n",
    "                ['1v8Wh8LaaOuBM7uGf4HoXxnsbem3KUGN_', '/content/sg2-model/', 'stylegan2-wikiart-conditional-model_network-snapshot-012052', '.pkl', 'sg2_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_models][0], dest_path=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3])\n",
    "  files_path[0][1]=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3]\n",
    "\n",
    "if generate&gen_pytorch:\n",
    " if generate&gen_sg2_pt_models:\n",
    "  files_path = [\n",
    "        #        ['1KxhHmGbJvAIbVpFT5u6UNntiPwq6Cjtb', '/content/sg2-model/', 'sg2-cosplay-faces-512x512-px_cosplayface-snapshot-004000-18160-FID367', '.pkl', 'sg2_model'],\n",
    "        #        ['1pOYc3O1YdlOpHYnA9LLhti4isOz1vrPl', '/content/sg2-model/', 'sg2-cosplay-faces-512x512-px_cosplayface-snapshot-001360-19520-FID359', '.pkl', 'sg2_model'],\n",
    "                ['1ZufizRwpPk21CxK7FBUiGy_cCfSWEyo_', '/content/sg2-model/', 'sg2_network-snapshot-sneakGAN-0000144', '.pkl', 'sg2_pt_model']\n",
    "                ]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_pt_models][0], dest_path=files_path[sg2_pt_models][1]+files_path[sg2_pt_models][2]+files_path[sg2_pt_models][3])\n",
    "  files_path[0][1]=files_path[sg2_pt_models][1]+files_path[sg2_pt_models][2]+files_path[sg2_pt_models][3]\n",
    "if generate&gen_tf1:\n",
    " if generate&gen_sg2_tf1_models:\n",
    "  files_path = [\n",
    "                ['1EdKrIa3ASx63hgq4qt5-bnAYjlyPCMy4', '/content/sg2-model/', 'sg2_ukiyoe-faces_ukiyoe-256-slim-diffAug-002789', '.pkl', 'sg2_tf1_model'],\n",
    "                ['1BmGxteqoSvpik-6VgbhOU-PaU5hZVtGw', '/content/sg2-model/', 'stylegan2-100-shot-grumpy_cat', '.pkl', 'sg2_tf1_model'],\n",
    "                ['1bSC97gtbp621mnLDpmwnQHN8Z2WLAahM', '/content/sg2-model/', 'stylegan2-100-shot-obama', '.pkl', 'sg2_tf1_model'],\n",
    "                ['1UYX_yQjCZ8nLQW0VWbLgmN8V09ChGNAn', '/content/sg2-model/', 'stylegan2-100-shot-panda', '.pkl', 'sg2_tf1_model'],\n",
    "                ['11-hSrs8F03rWuOh9Ijvfm5W0xLE6Jnve', '/content/sg2-model/', 'stylegan2-ffhq', '.pkl', 'sg2_tf1_model'],\n",
    "                ['1QD8iPkTJaQmQ-Q0E875CBiJrXI_-r8Zj', '/content/sg2-model/', 'sg2_ffhq-256-config-e-003810', '.pkl', 'sg2_tf1_model'],\n",
    "                ['1DAisKVy71O0YloSlonYL1rWOUbk_2LDF', '/content/sg2-model/', 'sg2_ffhq-512-avg-tpurun1', '.pkl', 'sg2_tf1_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_tf1_models][0], dest_path=files_path[sg2_tf1_models][1]+files_path[sg2_tf1_models][2]+files_path[sg2_tf1_models][3])\n",
    "  files_path[0][1]=files_path[sg2_models][1]+files_path[sg2_tf1_models][2]+files_path[sg2_tf1_models][3]\n",
    "\n",
    "if generate&gen_sg3_models:\n",
    "  files_path = [['1UP200H32RIvVYA_9TduGqIbvqfsFjpkg', '/content/sg3-model/', 'stylegan3-anime-faces-generator_akiyamasho', '.pkl', 'sg3_model'],\n",
    "                ['1aMsP1juT3DzZpbEhcNWO_gJVw9lt7Ant', '/content/sg3-model/', 'stylegan3-r-afhqv2-512x512', '.pkl', 'sg3_model'],\n",
    "                ['1Buunx_0kHIWdNWqRq6CBG0ILlAlcPVOb', '/content/sg3-model/', 'stylegan3-r-ffhq-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1YiCvVqosdRwta3qwMQHNAzuSRGKnSRp1', '/content/sg3-model/', 'stylegan3-r-ffhqu-256x256', '.pkl', 'sg3_model'],\n",
    "                ['1z42DkzZUFhMpuWFHtMNvD6GApcL1lwG7', '/content/sg3-model/', 'stylegan3-r-ffhqu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1BOln2JzcatBT6LTqbsdmrwVb8GJzvhNa', '/content/sg3-model/', 'stylegan3-r-metfaces-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1lh8nIxnX-xmBuu1QQokfFPBvZQPXEo0e', '/content/sg3-model/', 'stylegan3-r-metfacesu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['18ZAuZj9fWwbHx07RB8COJsepnOYtyHli', '/content/sg3-model/', 'stylegan3-t-afhqv2-512x512', '.pkl', 'sg3_model'],\n",
    "                ['14OyRIEfpvhKkHooMpCKnzM3cDkOTXr6p', '/content/sg3-model/', 'stylegan3-t-ffhq-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1Yb5Cvf2DQ57-hX37gc4dq_Mo2UFMetnw', '/content/sg3-model/', 'stylegan3-t-ffhqu-256x256', '.pkl', 'sg3_model'],\n",
    "                ['1XwObqI_egXDiKXoEaCn83utVEzM7Miln', '/content/sg3-model/', 'stylegan3-t-ffhqu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1DH6C87Xr5wSG5mPZ8Y9GZgymsgBMTzMP', '/content/sg3-model/', 'stylegan3-t-metfaces-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['11Mn6U-mcJulhSzUetwX1Q03h7EXrZxS_', '/content/sg3-model/', 'stylegan3-t-metfacesu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1Ncs7wUsbfSEPJCcxiTLDOYjLT6UY9wT2', '/content/sg3-model/', 'sg3_alien-sunglases-256_network-snapshot-000074', '.pkl', 'sg3_model'],\n",
    "                ['1CtKjqv7Te5X3L0KuZLIbzi7fbmpLakYS', '/content/sg3-model/', 'sg3_Benches-512_network-snapshot-011000', '.pkl', 'sg3_model'],\n",
    "                ['15LkW8nCsVRrzjjYTVGlUJSnfGDi1RwyI', '/content/sg3-model/', 'sg3_flowers-256_network-snapshot-000069', '.pkl', 'sg3_model'],\n",
    "                ['1RcmJNbWy9As2OMVGiVhMFM0qUKCYB1IK', '/content/sg3-model/', 'sg3_Landscapes_lhq-256-stylegan3-t-25Mimg', '.pkl', 'sg3_model'],\n",
    "                ['1iO_T0MvNw59MPAueoqUHKzpoh40vyLrZ', '/content/sg3-model/', 'sg3_mechanical-devices-from-the-future-256_network-snapshot-000029', '.pkl', 'sg3_model'],\n",
    "                ['1mMZSFynUd_6AIuC8PkDWdeHWY4VyIqYm', '/content/sg3-model/', 'sg3_scifi-city-256_network-snapshot-000210', '.pkl', 'sg3_model'],\n",
    "                ['14DpmYfsX3K9JhkS0BV5YtgZ71wJOInsd', '/content/sg3-model/', 'sg3_scifi-spaceship-256_network-snapshot-000162', '.pkl', 'sg3_model'],\n",
    "                ['13Q5bDnng7VfqYq6g-t8jVybR-E_Df_q3', '/content/sg3-model/', 'sg3_wikiart-1024-stylegan3-t-17.2Mimg', '.pkl', 'sg3_model'],\n",
    "                ['10Q6npsBKdRWMb0LxZUzN6FBSNeB4KTA6', '/content/sg3-model/', 'sg3_yellow-alien-512_network-snapshot-000236', '.pkl', 'sg3_model'],\n",
    "                ['10l7ADbHmZgjSrrpNzOD8r5grJqwxfRd3', '/content/sg3-model/', 'stylegan3_sneaksnap', '.pkl', 'sg3_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg3_models][0], dest_path=files_path[sg3_models][1]+files_path[sg3_models][2]+files_path[sg3_models][3])\n",
    "  files_path[0][1]=files_path[sg3_models][1]+files_path[sg3_models][2]+files_path[sg3_models][3]\n",
    "\n",
    "\n",
    "if generate&gen_stylegan2:\n",
    "  !pip install Pillow\n",
    "  import PIL.Image \n",
    "  !pip install tqdm\n",
    "  from tqdm import tqdm\n",
    "  !pip install imageio==2.4.1\n",
    "  !pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0\n",
    "\n",
    "if generate&gen_sg2_rosasalberto_tf2:\n",
    "  import tensorflow as tf\n",
    "  import numpy as np\n",
    "  !pip install matplotlib\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  from utils.utils_stylegan2 import convert_images_to_uint8\n",
    "\n",
    "  def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n",
    "    \"\"\" plot images from generator output \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
    "    for i in range(3):\n",
    "    \n",
    "        # creating random latent vector\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        z = rnd.randn(1, 512).astype('float32')\n",
    "\n",
    "        # running mapping network\n",
    "        dlatents = gen.mapping_network(z)\n",
    "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
    "        dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
    "        # running synthesis network\n",
    "        out = gen.synthesis_network(dlatents)\n",
    "\n",
    "        #converting image/s to uint8\n",
    "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
    "\n",
    "        #plotting images\n",
    "        ax[i].axis('off')\n",
    "        img_plot = ax[i].imshow(img.numpy()[0])\n",
    "        \n",
    "        seed += 1\n",
    "\n",
    "  impl = 'ref' # 'ref' if cuda is not available in your machine\n",
    "  gpu = False # False if tensorflow cpu is used\n",
    "  if generate&gen_tpu:\n",
    "    impl = 'ref' # 'ref' if cuda is not available in your machine\n",
    "    gpu = False # False if tensorflow cpu is used\n",
    "  if generate&gen_gpu:\n",
    "    impl = 'cuda' # 'ref' if cuda is not available in your machine\n",
    "    gpu = True # False if tensorflow cpu is used\n",
    "\n",
    "  import tensorflow as tf\n",
    "  import numpy as np\n",
    "\n",
    "  from utils.weights_map import available_weights, synthesis_weights, mapping_weights, weights_stylegan2_dir\n",
    "  from utils.utils_stylegan2 import nf\n",
    "  from layers.dense_layer import DenseLayer\n",
    "  from layers.synthesis_main_layer import SynthesisMainLayer\n",
    "  from layers.to_rgb_layer import ToRgbLayer\n",
    "  from dnnlib.ops.upfirdn_2d import upsample_2d\n",
    "\n",
    "  class MappingNetwork(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    StyleGan2 generator mapping network, from z to dlatents for tensorflow 2.x\n",
    "    \"\"\"\n",
    "    def __init__(self, resolution=1024, **kwargs):\n",
    "        \n",
    "        super(MappingNetwork, self).__init__(**kwargs)\n",
    "        \n",
    "        self.dlatent_size = 512\n",
    "        self.dlatent_vector = (int(np.log2(resolution))-1)*2\n",
    "        self.mapping_layers = 8\n",
    "        self.lrmul = 0.01\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "\n",
    "        self.weights_dict = {}\n",
    "        for i in range(self.mapping_layers):\n",
    "            setattr(self, 'Dense{}'.format(i), DenseLayer(fmaps=512, lrmul=self.lrmul, name='Dense{}'.format(i)))\n",
    "    \n",
    "        self.g_mapping_broadcast = tf.keras.layers.RepeatVector(self.dlatent_vector)\n",
    "            \n",
    "    def call(self, z):\n",
    "        \n",
    "        z = tf.cast(z, 'float32')\n",
    "        \n",
    "        # Normalize inputs\n",
    "        scale = tf.math.rsqrt(tf.reduce_mean(tf.square(z), axis=1, keepdims=True) + 1e-8)\n",
    "        x = tf.math.multiply(z, scale)\n",
    "        \n",
    "        # Mapping\n",
    "        for i in range(self.mapping_layers):\n",
    "        \n",
    "            x = getattr(self, 'Dense{}'.format(i))(x)\n",
    "            x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n",
    "        \n",
    "        # Broadcasting\n",
    "        dlatents = self.g_mapping_broadcast(x)\n",
    "        \n",
    "        return dlatents\n",
    "\n",
    "  class SynthesisNetwork(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    StyleGan2 generator synthesis network from dlatents to img tensor for tensorflow 2.x\n",
    "    \"\"\"\n",
    "    def __init__(self, resolution=1024, impl='cuda', gpu=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        resolution : int, optional\n",
    "            Resolution output of the synthesis network, will be parsed to the floor integer power of 2. \n",
    "            The default is 1024.\n",
    "        impl : str, optional\n",
    "            Wether to run some convolutions in custom tensorflow operations or cuda operations. 'ref' and 'cuda' available.\n",
    "            The default is 'cuda'.\n",
    "        gpu : boolean, optional\n",
    "            Wether to use gpu. The default is True.\n",
    "        \"\"\"\n",
    "        super(SynthesisNetwork, self).__init__(**kwargs)\n",
    "        \n",
    "        self.impl = impl\n",
    "        self.gpu = gpu\n",
    "        self.resolution = resolution\n",
    "        \n",
    "        self.resolution_log2 = int(np.log2(self.resolution))\n",
    "        self.resample_kernel = [1, 3, 3, 1]\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        #constant layer\n",
    "        self.const_4_4 = self.add_weight(name='4x4/Const/const', shape=(1, 512, 4, 4), \n",
    "                                        initializer=tf.random_normal_initializer(0, 1), trainable=True)\n",
    "        #early layer 4x4\n",
    "        self.layer_4_4 = SynthesisMainLayer(fmaps=nf(1), impl=self.impl, gpu=self.gpu, name='4x4')\n",
    "        self.torgb_4_4 = ToRgbLayer(impl=self.impl, gpu=self.gpu, name='4x4')\n",
    "        #main layers\n",
    "        for res in range(3, self.resolution_log2 + 1):\n",
    "            res_str = str(2**res)\n",
    "            setattr(self, 'layer_{}_{}_up'.format(res_str, res_str), \n",
    "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, up=True, name='{}x{}'.format(res_str, res_str)))\n",
    "            setattr(self, 'layer_{}_{}'.format(res_str, res_str), \n",
    "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
    "            setattr(self, 'torgb_{}_{}'.format(res_str, res_str), \n",
    "                    ToRgbLayer(impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
    "        \n",
    "    def call(self, dlatents_in):\n",
    "        \n",
    "        dlatents_in = tf.cast(dlatents_in, 'float32')\n",
    "        y = None\n",
    "        \n",
    "        # Early layers\n",
    "        x = tf.tile(tf.cast(self.const_4_4, 'float32'), [tf.shape(dlatents_in)[0], 1, 1, 1])\n",
    "        x = self.layer_4_4(x, dlatents_in[:, 0])\n",
    "        y = self.torgb_4_4(x, dlatents_in[:, 1], y)\n",
    "                \n",
    "        # Main layers\n",
    "        for res in range(3, self.resolution_log2 + 1):\n",
    "            x = getattr(self, 'layer_{}_{}_up'.format(2**res, 2**res))(x, dlatents_in[:, res*2-5])\n",
    "            x = getattr(self, 'layer_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-4])\n",
    "            y = upsample_2d(y, k=self.resample_kernel, impl=self.impl, gpu=self.gpu)\n",
    "            y = getattr(self, 'torgb_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-3], y)\n",
    "                    \n",
    "        images_out = y\n",
    "        return tf.identity(images_out, name='images_out')\n",
    "    \n",
    "  class StyleGan2Generator(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    StyleGan2 generator config f for tensorflow 2.x\n",
    "    \"\"\"\n",
    "    def __init__(self, resolution=1024, weights=None, impl='cuda', gpu=True, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        resolution : int, optional\n",
    "            Resolution output of the synthesis network, will be parsed \n",
    "            to the floor integer power of 2. \n",
    "            The default is 1024.\n",
    "        weights : string, optional\n",
    "            weights name in weights dir to be loaded. The default is None.\n",
    "        impl : str, optional\n",
    "            Wether to run some convolutions in custom tensorflow operations \n",
    "            or cuda operations. 'ref' and 'cuda' available.\n",
    "            The default is 'cuda'.\n",
    "        gpu : boolean, optional\n",
    "            Wether to use gpu. The default is True.\n",
    "        \"\"\"\n",
    "        super(StyleGan2Generator, self).__init__(**kwargs)\n",
    "        \n",
    "        self.resolution = resolution\n",
    "        if weights is not None: self.__adjust_resolution(weights)\n",
    "\n",
    "        self.mapping_network = MappingNetwork(resolution=self.resolution,name='Mapping_network')\n",
    "        self.synthesis_network = SynthesisNetwork(resolution=self.resolution, impl=impl, \n",
    "                                                  gpu=gpu, name='Synthesis_network')\n",
    "        \n",
    "        # load weights\n",
    "        if weights is not None:\n",
    "            #we run the network to define it, not the most efficient thing to do...\n",
    "            _ = self(tf.zeros(shape=(1, 512)))\n",
    "            self.__load_weights(weights)\n",
    "        \n",
    "    def call(self, z):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : tensor, latent vector of shape [batch, 512]\n",
    "        Returns\n",
    "        -------\n",
    "        img : tensor, image generated by the generator of shape  [batch, channel, height, width]\n",
    "        \"\"\"\n",
    "        dlatents = self.mapping_network(z)\n",
    "        img = self.synthesis_network(dlatents)\n",
    "\n",
    "        return img\n",
    "    \n",
    "    def __adjust_resolution(self, weights_name):\n",
    "        \"\"\"\n",
    "        Adjust resolution of the synthesis network output. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_name : name of the weights\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        if  weights_name == 'ffhq': \n",
    "            self.resolution = 1024\n",
    "        elif weights_name == 'car': \n",
    "            self.resolution = 512\n",
    "        elif weights_name in ['cat', 'church', 'horse']: \n",
    "            self.resolution = 256\n",
    "        elif weights_name == 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664': \n",
    "            self.resolution = 512\n",
    "        elif weights_name == 'sg2_anime_network-snapshot-018528': \n",
    "            self.resolution = 512\n",
    "        elif weights_name == 'sg2-ext_aydao-anime-danbooru2019s-512-5268480': \n",
    "            self.resolution = 1024\n",
    "        elif weights_name == 'sg2-ada_abstract_network-snapshot-000188': \n",
    "            self.resolution = 1024    \n",
    "    def __load_weights(self, weights_name):\n",
    "        \"\"\"\n",
    "        Load pretrained weights, stored as a dict with numpy arrays.\n",
    "        Parameters\n",
    "        ----------\n",
    "        weights_name : name of the weights\n",
    "        Returns\n",
    "        -------\n",
    "        None.\n",
    "        \"\"\"\n",
    "        \n",
    "        if (weights_name in available_weights) and type(weights_name) == str:\n",
    "            data = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
    "            #datatmp = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
    "            #data=datatmp.copy()\n",
    "            #for key in datatmp.keys(): \n",
    "            #  if not (key[:4]=='disc'):\n",
    "            #    del data[key]\n",
    "            for key in data.keys(): \n",
    "              print(key)\n",
    "            \n",
    "            weights_mapping = [data.get(key) for key in mapping_weights]\n",
    "            print(weights_mapping)\n",
    "            weights_synthesis = [data.get(key) for key in synthesis_weights[weights_name]]\n",
    "            #print(weights_synthesis)\n",
    "            \n",
    "            self.mapping_network.set_weights(weights_mapping)\n",
    "            self.synthesis_network.set_weights(weights_synthesis)\n",
    "            \n",
    "            print(\"Loaded {} generator weights!\".format(weights_name))\n",
    "        else:\n",
    "            raise Exception('Cannot load {} weights'.format(weights_name))\n",
    "\n",
    "  def generate_and_plot_images_notrunc(gen, seed):\n",
    "    \"\"\" plot images from generator output \"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
    "    for i in range(3):\n",
    "    \n",
    "        # creating random latent vector\n",
    "        rnd = np.random.RandomState(seed)\n",
    "        z = rnd.randn(1, 512).astype('float32')\n",
    "\n",
    "        # running mapping network\n",
    "        dlatents = gen.mapping_network(z)\n",
    "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
    "        #dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
    "        # running synthesis network\n",
    "        out = gen.synthesis_network(dlatents)\n",
    "\n",
    "        #converting image/s to uint8\n",
    "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
    "\n",
    "        #plotting images\n",
    "        ax[i].axis('off')\n",
    "        img_plot = ax[i].imshow(img.numpy()[0])\n",
    "        #plt.axis('off')\n",
    "        #plt.imshow(img.numpy()[0])\n",
    "        #plt.show()\n",
    "        seed += 1\n",
    "\n",
    "\n",
    "  weights_name = files_path[0][2]\n",
    "\n",
    "  from utils.weights_map import synthesis_weights_1024, synthesis_weights_512, synthesis_weights_256\n",
    "  from utils.weights_map import discriminator_weights_1024, discriminator_weights_512, discriminator_weights_256\n",
    "\n",
    "  available_weights = ['ffhq', 'car', 'cat', 'church', 'horse', \n",
    "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664',\n",
    "    'sg2_anime_network-snapshot-018528',\n",
    "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480',\n",
    "    'sg2-ada_abstract_network-snapshot-000188']\n",
    "\n",
    "  mapping_weights = [ 'Dense0/weight', 'Dense0/bias',\n",
    "                    'Dense1/weight', 'Dense1/bias'\n",
    "                    ,\n",
    "                    'Dense2/weight', 'Dense2/bias',\n",
    "                    'Dense3/weight', 'Dense3/bias',\n",
    "                    'Dense4/weight', 'Dense4/bias',\n",
    "                    'Dense5/weight', 'Dense5/bias',\n",
    "                    'Dense6/weight', 'Dense6/bias',\n",
    "                    'Dense7/weight', 'Dense7/bias'\n",
    "                    ]\n",
    "\n",
    "  synthesis_weights = {\n",
    "    'ffhq' : synthesis_weights_1024,\n",
    "    'car' : synthesis_weights_512,\n",
    "    'cat' : synthesis_weights_256,\n",
    "    'horse' : synthesis_weights_256,\n",
    "    'church' : synthesis_weights_256,\n",
    "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : synthesis_weights_512,\n",
    "    'sg2_anime_network-snapshot-018528' : synthesis_weights_512,\n",
    "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : synthesis_weights_1024,\n",
    "    'sg2-ada_abstract_network-snapshot-000188' : synthesis_weights_1024\n",
    "    }\n",
    "\n",
    "  discriminator_weights = {\n",
    "    'ffhq' : discriminator_weights_1024,\n",
    "    'car' : discriminator_weights_512,\n",
    "    'cat' : discriminator_weights_256,\n",
    "    'horse' : discriminator_weights_256,\n",
    "    'church' : discriminator_weights_256,\n",
    "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : discriminator_weights_512,\n",
    "    'sg2_anime_network-snapshot-018528' : discriminator_weights_512,\n",
    "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : discriminator_weights_1024,\n",
    "    'sg2-ada_abstract_network-snapshot-000188' : discriminator_weights_1024\n",
    "    }\n",
    "\n",
    "  # instantiating generator network\n",
    "  generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
    "\n",
    "  # loading w average\n",
    "  #w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
    "\n",
    "if generate&gen_sg2_moono_tf2:\n",
    "  \n",
    "  import os\n",
    "  import numpy as np\n",
    "  import tensorflow as tf\n",
    "  from PIL import Image\n",
    "  from stylegan2.utils import postprocess_images\n",
    "  from load_models import load_generator\n",
    "  from copy_official_weights import convert_official_weights_together\n",
    "  \n",
    "  if True:\n",
    "    from tf_utils import allow_memory_growth\n",
    "\n",
    "    allow_memory_growth()\n",
    "\n",
    "    # common variables\n",
    "    ckpt_dir_base = './official-converted'\n",
    "\n",
    "    use_custom_cuda=True\n",
    "    # saving phase\n",
    "    #for use_custom_cuda in [True, False]:\n",
    "    #    ckpt_dir = os.path.join(ckpt_dir_base, 'cuda') if use_custom_cuda else os.path.join(ckpt_dir_base, 'ref')\n",
    "    #    convert_official_weights_together(ckpt_dir, use_custom_cuda)\n",
    "\n",
    "    # inference phase\n",
    "    ckpt_dir_cuda = os.path.join(ckpt_dir_base, 'cuda')\n",
    "    ckpt_dir_ref = os.path.join(ckpt_dir_base, 'ref')\n",
    "\n",
    "    g_clone = load_generator(g_params=None, is_g_clone=True, ckpt_dir=ckpt_dir_cuda, custom_cuda=use_custom_cuda)\n",
    "\n",
    "#if generate_stylegan2_tpu:\n",
    "#  tflib.init_tf()\n",
    "#  import pretrained_networks\n",
    "#  _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
    "if generate&gen_stylegan2:\n",
    " if generate&gen_tf1:\n",
    "#if generate_stylegan2_ada or generate_stylegan2_ext:\n",
    "  import dnnlib\n",
    "  import dnnlib.tflib as tflib  \n",
    "  tflib.init_tf()\n",
    "  \n",
    "  import pickle\n",
    "  network_pkl=files_path[0][1]\n",
    "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
    " #       _G, _D, Gs = pickle.load(fp)\n",
    "  _G, _D, Gs = pickle.load(open(network_pkl, \"rb\"))\n",
    "\n",
    "  if generate&gen_tf2_npy:\n",
    "    import numpy as np\n",
    "    data = {}\n",
    "\n",
    "#    import pretrained_networks\n",
    "#    g, d, Gs_network = pretrained_networks.load_networks('/content/model/2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl')\n",
    "#    for key in  d.trainables.keys():\n",
    "#        data['disc_'+ key] = d.get_var(key)\n",
    "    #print(_G)\n",
    "    #print(_D)\n",
    "    #print(Gs)\n",
    "    _G.print_layers()\n",
    "    _D.print_layers()\n",
    "    Gs.print_layers()\n",
    "\n",
    "    \n",
    "    for key in  _G.trainables.keys():\n",
    "        data[key[key.find('/')+1:]] = _G.get_var(key)\n",
    "    #for key in  Gs.trainables.keys():\n",
    "    #    data[key[key.find('/')+1:]] = Gs.get_var(key)\n",
    "    #for key in  _G.trainables.keys():\n",
    "    #    data[key] = _G.get_var(key)\n",
    "    #for key in  Gs.trainables.keys():\n",
    "    #    data['gens_'+ key] = Gs.get_var(key)\n",
    "\n",
    "    for key in  _D.trainables.keys():\n",
    "        data['disc_'+ key] = _D.get_var(key)\n",
    "    np.save('/content/model/{}.npy'.format(files_path[0][2]), data, allow_pickle=True)\n",
    "    #from google.colab import files\n",
    "    #files.download('/content/model/{}.npy'.format(files_path[0][2]))\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    !mkdir /content/gdrive/MyDrive/EEG-GAN-audio-video/models\n",
    "    !cp -r -v \"/content/model/{files_path[0][2]}.npy\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video/models/{files_path[0][2]}.npy\"\n",
    "\n",
    "\n",
    "!mkdir '/content/out'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "bhYyUwxJ1oxu"
   },
   "outputs": [],
   "source": [
    "if generate&gen_sg2_nagolinc_pt:\n",
    "\n",
    "  import subprocess\n",
    "\n",
    "  CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
    "  print(\"CUDA version:\", CUDA_version)\n",
    "\n",
    "  if CUDA_version == \"10.0\":\n",
    "    torch_version_suffix = \"+cu100\"\n",
    "  elif CUDA_version == \"10.1\":\n",
    "    torch_version_suffix = \"+cu101\"\n",
    "  elif CUDA_version == \"10.2\":\n",
    "    torch_version_suffix = \"\"\n",
    "  else:\n",
    "    torch_version_suffix = \"+cu110\"\n",
    "\n",
    "  !pip install ninja\n",
    "\n",
    "  !pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
    "\n",
    "  #%cd /content/stylegan2-pytorch\n",
    "  from convert_weight import convertStyleGan2\n",
    "\n",
    "#conver the model from tf to torch\n",
    "  ckpt, g, disc,g_train = convertStyleGan2(_G,_D,Gs)#,style_dim=dim_sg2,max_channel_size=dim_sg2)\n",
    "  latent_avg=ckpt[\"latent_avg\"]\n",
    "\n",
    "  import torch\n",
    "\n",
    "  import matplotlib.pyplot as plt\n",
    "\n",
    "  def fmtImg(r):\n",
    "    img = ((r+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
    "    return PIL.Image.fromarray(img, 'RGB')\n",
    "\n",
    "  device='cuda'\n",
    "  n_sample=1\n",
    "\n",
    "  g = g.to(device)\n",
    "\n",
    "  inputSize=1024#dim_sg2\n",
    "  import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "m6Un-xtW4V_8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (1.9.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.18.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from scipy) (1.23.2)\n",
      "Requirement already satisfied: click in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (8.1.3)\n",
      "Requirement already satisfied: requests in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (2.28.1)\n",
      "Requirement already satisfied: tqdm in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (4.64.0)\n",
      "Requirement already satisfied: pyspng in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.1.0)\n",
      "Requirement already satisfied: ninja in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (1.10.2.3)\n",
      "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: numpy in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pyspng) (1.23.2)\n"
     ]
    }
   ],
   "source": [
    "if generate&gen_sg3_Expl0dingCat_pt:\n",
    "\n",
    "  !pip install scipy\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "#  !pip install torch\n",
    "#  !pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G3m = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U2PUPkVECsig",
    "outputId": "dba6b021-3687-47ce-9f80-6c90bf67a669"
   },
   "outputs": [],
   "source": [
    "if generate&gen_sg3_nvlabs_pt:\n",
    "\n",
    "  !pip install scipy\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "#  !pip install torch\n",
    "#  !pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G3 = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "JrgaAwdJOkee"
   },
   "outputs": [],
   "source": [
    "if generate&gen_sg2_nvlabs_ada_pt:\n",
    "\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "#  !pip install torch==1.12.1\n",
    "#  !pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "EUKP12wZTYT7"
   },
   "outputs": [],
   "source": [
    "#generate_and_plot_images_notrunc(generator, seed=396)\n",
    "\n",
    "# not using truncation\n",
    "#generate_and_plot_images(generator, seed=96, w_avg=w_average)\n",
    "\n",
    "# using truncation 0.5\n",
    "#generate_and_plot_images(generator, seed=96, w_avg=w_average, truncation_psi=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "wrZhTCe5USvq"
   },
   "outputs": [],
   "source": [
    "#def gen():\n",
    "#  global generator\n",
    "#  seed = 6600\n",
    "#  # creating random latent vector\n",
    "#  rnd = np.random.RandomState(seed)\n",
    "#  __z = rnd.randn(1, 512).astype('float32')\n",
    "#  # running mapping network\n",
    "#  dlatents = generator.mapping_network(__z)  \n",
    "# \n",
    "#  out = generator.synthesis_network(dlatents)\n",
    "#  #converting image/s to uint8\n",
    "#  images = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
    "#gen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "8aA95OcEv5YU"
   },
   "outputs": [],
   "source": [
    "if generate&gen_wavegan:\n",
    " if generate&gen_drums:\n",
    "  # Load the model\n",
    "  tf.reset_default_graph()\n",
    "  saver = tf.train.import_meta_graph('/content/model/infer/infer.meta')\n",
    "  graph = tf.get_default_graph()\n",
    "  sess = tf.InteractiveSession()\n",
    "  sess.close()\n",
    "  sess = tf.InteractiveSession()\n",
    "  saver.restore(sess, f'/content/model/model.ckpt-18637')\n",
    "  #dim = 100\n",
    "  break_len = 65536\n",
    "\n",
    "  z = graph.get_tensor_by_name('z:0')\n",
    "  G_z = graph.get_tensor_by_name('G_z:0')\n",
    "\n",
    "  import numpy as np\n",
    "  from IPython.display import display, Audio\n",
    "  #from google.colab import files\n",
    "  import scipy.io.wavfile\n",
    "  import matplotlib.pyplot as plt\n",
    "  %matplotlib inline\n",
    "  !mkdir \"./neuralfunk examples\"\n",
    "\n",
    "  def generate_trajectory(n_iter, _z0=None, mov_last=None, jump=0.3, smooth=0.3, include_z0=True):\n",
    "    _z = np.empty((n_iter + int(not include_z0), dim))\n",
    "    _z[0] = _z0 if _z0 is not None else np.random.random(dim)*2-1\n",
    "    mov = mov_last if mov_last is not None else (np.random.random(dim)*2-1)*jump\n",
    "    for i in range(1, len(_z)):\n",
    "        mov = mov*smooth + (np.random.random(dim)*2-1)*jump*(1-smooth)\n",
    "        mov -= (np.abs(_z[i-1] + mov) > 1) * 2 * mov\n",
    "        _z[i] = _z[i-1] + mov\n",
    "    return _z[-n_iter:], mov  \n",
    "  !pip install pydub\n",
    "  from pydub import AudioSegment\n",
    "  !pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lt3tZX8iYM1",
    "outputId": "175e16c1-5273-43da-d128-1dd18be56057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mne==0.23.3 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.23.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from mne==0.23.3) (1.9.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from mne==0.23.3) (1.23.2)\n",
      "Requirement already satisfied: pandas in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (1.4.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pandas) (1.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (1.23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (4.37.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mne==0.23.3\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "\n",
    "import mne\n",
    "from mne import io\n",
    "from mne.datasets import sample\n",
    "from mne.minimum_norm import read_inverse_operator, compute_source_psd\n",
    "\n",
    "from mne.connectivity import spectral_connectivity, seed_target_indices\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "FwhsStNzSHeW",
    "outputId": "c66fb9b3-da3b-4652-f733-99ac5d47640e",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div id=\"buttons\"></div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "//Joshua Brewster, GPL (copyleft)\n",
       " \n",
       "//import 'regenerator-runtime/runtime' //For async functions on node\\\n",
       " \n",
       " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
       " \n",
       "    constructor(\n",
       "        onDecodedCallback = this.onDecodedCallback,\n",
       "        onConnectedCallback = this.onConnectedCallback,\n",
       "        onDisconnectedCallback = this.onDisconnectedCallback,\n",
       "        CustomDecoder = this.decode,\n",
       "        baudrate = 921600//115200\n",
       "        ) {\n",
       " \n",
       "        this.onDecodedCallback = onDecodedCallback;\n",
       "        this.onConnectedCallback = onConnectedCallback;\n",
       "        this.onDisconnectedCallback = onDisconnectedCallback;\n",
       "        this.decode = CustomDecoder;\n",
       "        //Free EEG 32 data structure:\n",
       "        \n",
       "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
       "        //    Total = 105 bytes/line\n",
       "        \n",
       "        this.connected = false;\n",
       "        this.subscribed = false;\n",
       "        this.buffer = [];\n",
       "        this.startByte = 160; // Start byte value\n",
       "        this.stopByte = 192; // Stop byte value\n",
       "        this.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
       "        this.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
       "        this.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
       " \n",
       "        this.sps = 512; // Sample rate\n",
       "        this.nChannels = 32;\n",
       "        this.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
       "        this.updateMs = 1000/this.sps; //even spacing\n",
       "        this.stepSize = 1/Math.pow(2,24);\n",
       "        this.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
       "        this.gain = 8;\n",
       " \n",
       "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
       "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
       "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
       " \n",
       "        this.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
       "        \n",
       "        this.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
       "            count: 0,\n",
       "            startms: 0,\n",
       "            ms: [],\n",
       "            'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
       "            'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
       "            'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
       "            'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
       "            'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
       "        };\n",
       " \n",
       "    this.bufferednewLines = 0;\n",
       "    this.data_slice=[];\n",
       "    this.data_slice_size=512*(5*1/8+0.1);\n",
       "    this.ready_to_send_data = false;\n",
       "    this.data_send_count=0;\n",
       "\n",
       "    this.xsize=512;\n",
       "    this.ysize=512;\n",
       "\n",
       "    this.generate_stylegan2=true;\n",
       "    this.generate_stylegan2=32;\n",
       "    \n",
       "    //this.generate_stylegan2=false;\n",
       "    this.generate_wavegan=true;\n",
       "    this.generate_wavegan=0;\n",
       "    this.generate_heatmap=true;\n",
       "    this.generate_heatmap=0;\n",
       "    //data:audio/wav;base64,\n",
       "    //data:image/jpeg;base64,\n",
       "    this.time100=Date.now();\n",
       "    this.time000=Date.now();\n",
       "    this.this_frame_wg=-1;\n",
       "    this.last_frame_wg=-1;\n",
       "    this.send_wg=false;\n",
       "    this.this_frame_sg2=-1;\n",
       "    this.last_frame_sg2=-1;\n",
       "    this.send_sg2=false;\n",
       "\n",
       "    this.frame_last=0;\n",
       "\n",
       "    if(this.generate_stylegan2)\n",
       "    {\n",
       "      this.fps_sg2=1;\n",
       "    }\n",
       "    if(this.generate_wavegan)\n",
       "    {\n",
       "      this.hz=44100;\n",
       "      this.fps_wg=this.hz/(32768*2);\n",
       "      //this.fps=this.hz/(32768);\n",
       "    }\n",
       "      this.fps_sg2=this.fps_wg;\n",
       "      this.fps_wg=10.000000;\n",
       "      this.fps_sg2=10.000000;\n",
       "      this.fps_hm=10.000000;\n",
       "      this.fps=Math.max(this.fps_wg,this.fps_sg2,this.fps_hm)*4;\n",
       "      \n",
       "    this.samples_count=0;\n",
       "    //this.channel=None;\n",
       " \n",
       "        this.resetDataBuffers();\n",
       " \n",
       "        //navigator.serial utils\n",
       "        if(!navigator.serial){\n",
       "            console.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
       "        }\n",
       "        this.port = null;\n",
       "        this.reader = null;\n",
       "        this.baudrate = baudrate;\n",
       " \n",
       "    }\n",
       "    \n",
       "    resetDataBuffers(){\n",
       "        this.data.count = 0;\n",
       "        this.data.startms = 0;\n",
       "        for(const prop in this.data) {\n",
       "            if(typeof this.data[prop] === \"object\"){\n",
       "                this.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
       "            }\n",
       "        }\n",
       "    }\n",
       " \n",
       "    setScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
       "        this.stepSize = stepSize;\n",
       "        this.vref = vref; //2.5V voltage ref +/- 250nV\n",
       "        this.gain = gain;\n",
       " \n",
       "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
       "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
       "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
       "    }\n",
       " \n",
       "    getLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
       "        let ct = count;\n",
       "        if(ct <= 1) {\n",
       "            return [this.data[channel][this.data.count-1]];\n",
       "        }\n",
       "        else {\n",
       "            if(ct > this.data.count) {\n",
       "                ct = this.data.count;\n",
       "            }\n",
       "            return this.data[channel].slice(this.data.count-ct,this.data.count);\n",
       "        }\n",
       "    }\n",
       " \n",
       "    bytesToInt16(x0,x1){\n",
       "        return x0 * 256 + x1;\n",
       "    }\n",
       " \n",
       "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
       "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
       "    }\n",
       " \n",
       "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
       "        return x0 * 65536 + x1 * 256 + x2;\n",
       "    }\n",
       " \n",
       "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
       "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
       "    }\n",
       " \n",
       "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
       " \n",
       "        var needle = this.searchString\n",
       "        var haystack = buffer;\n",
       "        var search = this.boyerMoore(needle);\n",
       "        var skip = search.byteLength;\n",
       "        var indices = [];\n",
       "        let newLines = 0;\n",
       "    \n",
       "        for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
       "            indices.push(i);\n",
       "        }\n",
       "        //console.log(indices);\n",
       "        if(indices.length >= 2){\n",
       "            for(let k = 1; k < indices.length; k++) {\n",
       "                if(indices[k] - indices[k-1] !== 105) {\n",
       "                    \n",
       "                } //This is not a valid sequence going by size, drop sequence and return\n",
       "                else {\n",
       "                    var line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
       "                    \n",
       "                    // line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
       " \n",
       "                    //line found, decode.\n",
       "                    if(this.data.count < this.maxBufferedSamples){\n",
       "                        this.data.count++;\n",
       "                    }\n",
       " \n",
       "                    if(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
       "                    else {\n",
       "                        this.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
       "                        \n",
       "                        if(this.data.count >= this.maxBufferedSamples) {\n",
       "                            this.data.ms.splice(0,5120);\n",
       "                            this.data.ms.push(new Array(5120).fill(0));\n",
       "                        }\n",
       "                    }//Assume no dropped samples\n",
       "                  var sample_count = line[2];\n",
       "                  var sample_count_diff = sample_count-this.samples_count;\n",
       "          if(sample_count_diff<0){\n",
       "            sample_count_diff+=256;\n",
       "          }\n",
       "          if(sample_count_diff!=1)\n",
       "          {\n",
       "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
       "          }\n",
       "          this.samples_count=sample_count;\n",
       " \n",
       "                    for(var i = 3; i < 99; i+=3) {\n",
       "                        var channel = \"A\"+(i-3)/3;\n",
       "                        this.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
       "                        if(this.data.count >= this.maxBufferedSamples) { \n",
       "                            this.data[channel].splice(0,5120);\n",
       "                            this.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
       "                        }\n",
       "                            //console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
       "                    }\n",
       " \n",
       "                    this.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
       "                    this.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
       "                    this.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
       " \n",
       "                    \n",
       "                    if(this.data.count >= this.maxBufferedSamples) { \n",
       "                        this.data[\"Ax\"].splice(0,5120);\n",
       "                        this.data[\"Ay\"].splice(0,5120);\n",
       "                        this.data[\"Az\"].splice(0,5120);\n",
       "                        this.data[\"Ax\"].push(new Array(5120).fill(0))\n",
       "                        this.data[\"Ay\"].push(new Array(5120).fill(0))\n",
       "                        this.data[\"Az\"].push(new Array(5120).fill(0))\n",
       "                        this.data.count -= 5120;\n",
       "                    }\n",
       "                    //console.log(this.data)\n",
       "                    newLines++;\n",
       "                    //console.log(indices[k-1],indices[k])\n",
       "                    //console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
       "                    //indices.shift();\n",
       "                }\n",
       "                \n",
       "            }\n",
       "            if(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
       "   \n",
       "            return newLines;\n",
       "            //Continue\n",
       "        }\n",
       "        //else {this.buffer = []; return false;}\n",
       "    }\n",
       "    //Callbacks\n",
       "    onDecodedCallback(newLinesInt){\n",
       "        //console.log(\"new samples:\", newLinesInt);\n",
       "        this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
       "    }\n",
       " \n",
       "    onConnectedCallback() {\n",
       "        console.log(\"port connected!\");\n",
       "    }\n",
       " \n",
       "    onDisconnectedCallback() {\n",
       "        console.log(\"port disconnected!\");\n",
       "    }\n",
       " \n",
       "    onReceive(value){\n",
       "        this.buffer.push(...value);\n",
       " \n",
       "        let newLines = this.decode(this.buffer);\n",
       "        //console.log(this.data)\n",
       "        //console.log(\"decoding... \", this.buffer.length)\n",
       "        if(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
       "    }\n",
       " \n",
       "    async onPortSelected(port,baud=this.baudrate) {\n",
       "        try{\n",
       "            try {\n",
       "                await port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
       "                this.onConnectedCallback();\n",
       "                this.connected = true;\n",
       "                this.subscribed = true;\n",
       "                this.subscribe(port);//this.subscribeSafe(port);\n",
       "        \n",
       "            } //API inconsistency in syntax between linux and windows\n",
       "            catch {\n",
       "                await port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
       "                this.onConnectedCallback();\n",
       "                this.connected = true;\n",
       "                this.subscribed = true;\n",
       "                this.subscribe(port);//this.subscribeSafe(port);\n",
       "            }\n",
       "        }\n",
       "        catch(err){\n",
       "            console.log(err);\n",
       "            this.connected = false;\n",
       "        }\n",
       "    }\n",
       " \n",
       "    async subscribe(port){\n",
       "        if (this.port.readable && this.subscribed === true) {\n",
       "            this.reader = port.readable.getReader();\n",
       "            const streamData = async () => {\n",
       "                try {\n",
       "                    const { value, done } = await this.reader.read();\n",
       "                    if (done || this.subscribed === false) {\n",
       "                        // Allow the serial port to be closed later.\n",
       "                        await this.reader.releaseLock();\n",
       "                        \n",
       "                    }\n",
       "                    if (value) {\n",
       "                        //console.log(value.length);\n",
       "                        try{\n",
       "                            this.onReceive(value);\n",
       "                        }\n",
       "                        catch (err) {console.log(err)}\n",
       "                        //console.log(\"new Read\");\n",
       "                        //console.log(this.decoder.decode(value));\n",
       "                    }\n",
       "                    if(this.subscribed === true) {\n",
       "                        setTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
       "                    }\n",
       "                } catch (error) {\n",
       "                    console.log(error);// TODO: Handle non-fatal read error.\n",
       "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
       "                        this.subscribed = false;\n",
       "                        setTimeout(async ()=>{\n",
       "                            try{\n",
       "                            if (this.reader) {\n",
       "                                await this.reader.releaseLock();\n",
       "                                this.reader = null;\n",
       "                            }\n",
       "                            } catch (er){ console.error(er);}\n",
       "                            this.subscribed = true; \n",
       "                            this.subscribe(port);\n",
       "                            //if that fails then close port and reopen it\n",
       "                        },30); //try to resubscribe \n",
       "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
       "                        if(this.port){\n",
       "                            this.subscribed = false;\n",
       "                            setTimeout(async () => {\n",
       "                                try{\n",
       "                                if (this.reader) {\n",
       "                                    await this.reader.releaseLock();\n",
       "                                    this.reader = null;\n",
       "                                }\n",
       "                                await port.close();\n",
       "                                } catch (er){ console.error(er);}\n",
       "                                //this.port = null;\n",
       "                                this.connected = false;\n",
       "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
       "                            }, 50);\n",
       "                        }\n",
       "                    }\n",
       "                     else {\n",
       "                        this.closePort();   \n",
       "                    }   \n",
       "                }\n",
       "            }\n",
       "            streamData();\n",
       "        }\n",
       "    }\n",
       " \n",
       "    //Unfinished\n",
       "    async subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
       "        var readable = new Promise((resolve,reject) => {\n",
       "            while(this.port.readable && this.subscribed === true){\n",
       "                this.reader = port.readable.getReader();\n",
       "                var looper = true;\n",
       "                var prom1 = new Promise((resolve,reject) => {\n",
       "                    return this.reader.read();\n",
       "                });\n",
       " \n",
       "                var prom2 = new Promise((resolve,reject) => {\n",
       "                    setTimeout(resolve,100,\"readfail\");\n",
       "                });\n",
       "                while(looper === true ) {\n",
       "                    //console.log(\"reading...\");\n",
       "                    Promise.race([prom1,prom2]).then((result) => {\n",
       "                        console.log(\"newpromise\")\n",
       "                        if(result === \"readfail\"){\n",
       "                            console.log(result);\n",
       "                        }\n",
       "                        else{\n",
       "                            const {value, done} = result;\n",
       "                            if(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
       "                                resolve(this.reader.releaseLock())}).then(() => {\n",
       "                                    looper = false;\n",
       "                                    return;\n",
       "                                });\n",
       "                            }\n",
       "                            else{\n",
       "                                this.onReceive(value);\n",
       "                            }\n",
       "                        }\n",
       "                    });\n",
       "                }\n",
       "            }\n",
       "            resolve(\"not readable\");\n",
       "        });\n",
       "    }\n",
       " \n",
       "    async closePort(port=this.port) {\n",
       "        //if(this.reader) {this.reader.releaseLock();}\n",
       "        if(this.port){\n",
       "            this.subscribed = false;\n",
       "            setTimeout(async () => {\n",
       "                if (this.reader) {\n",
       "                    await this.reader.releaseLock();\n",
       "                    this.reader = null;\n",
       "                }\n",
       "                await port.close();\n",
       "                this.port = null;\n",
       "                this.connected = false;\n",
       "                this.onDisconnectedCallback();\n",
       "            }, 100);\n",
       "        }\n",
       "    }\n",
       " \n",
       "    async setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
       " \n",
       "        const filters = [\n",
       "            { usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
       "        ];\n",
       " \n",
       "        this.port = await navigator.serial.requestPort();\n",
       "        navigator.serial.addEventListener(\"disconnect\",(e) => {\n",
       "            this.closePort(this.port);\n",
       "        });\n",
       "        this.onPortSelected(this.port,baudrate);\n",
       " \n",
       "        //navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
       " \n",
       "    }\n",
       " \n",
       " \n",
       "    //Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
       "    asUint8Array(input) {\n",
       "        if (input instanceof Uint8Array) {\n",
       "            return input;\n",
       "        } else if (typeof(input) === 'string') {\n",
       "            // This naive transform only supports ASCII patterns. UTF-8 support\n",
       "            // not necessary for the intended use case here.\n",
       "            var arr = new Uint8Array(input.length);\n",
       "            for (var i = 0; i < input.length; i++) {\n",
       "            var c = input.charCodeAt(i);\n",
       "            if (c > 127) {\n",
       "                throw new TypeError(\"Only ASCII patterns are supported\");\n",
       "            }\n",
       "            arr[i] = c;\n",
       "            }\n",
       "            return arr;\n",
       "        } else {\n",
       "            // Assume that it's already something that can be coerced.\n",
       "            return new Uint8Array(input);\n",
       "        }\n",
       "    }\n",
       " \n",
       "    boyerMoore(patternBuffer) {\n",
       "        // Implementation of Boyer-Moore substring search ported from page 772 of\n",
       "        // Algorithms Fourth Edition (Sedgewick, Wayne)\n",
       "        // http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
       "        \n",
       "//      USAGE:\n",
       "            // needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
       "            // haystack should be an ArrayBuffer or Uint8Array\n",
       "//          var search = boyerMoore(needle);\n",
       "//          var skip = search.byteLength;\n",
       "//          var indices = [];\n",
       "//          for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
       "//              indices.push(i);\n",
       "//          }\n",
       "        \n",
       "        var pattern = this.asUint8Array(patternBuffer);\n",
       "        var M = pattern.length;\n",
       "        if (M === 0) {\n",
       "            throw new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
       "        }\n",
       "        // radix\n",
       "        var R = 256;\n",
       "        var rightmost_positions = new Int32Array(R);\n",
       "        // position of the rightmost occurrence of the byte c in the pattern\n",
       "        for (var c = 0; c < R; c++) {\n",
       "            // -1 for bytes not in pattern\n",
       "            rightmost_positions[c] = -1;\n",
       "        }\n",
       "        for (var j = 0; j < M; j++) {\n",
       "            // rightmost position for bytes in pattern\n",
       "            rightmost_positions[pattern[j]] = j;\n",
       "        }\n",
       "        var boyerMooreSearch = (txtBuffer, start, end) => {\n",
       "            // Return offset of first match, -1 if no match.\n",
       "            var txt = this.asUint8Array(txtBuffer);\n",
       "            if (start === undefined) start = 0;\n",
       "            if (end === undefined) end = txt.length;\n",
       "            var pat = pattern;\n",
       "            var right = rightmost_positions;\n",
       "            var lastIndex = end - pat.length;\n",
       "            var lastPatIndex = pat.length - 1;\n",
       "            var skip;\n",
       "            for (var i = start; i <= lastIndex; i += skip) {\n",
       "                skip = 0;\n",
       "                for (var j = lastPatIndex; j >= 0; j--) {\n",
       "                var c = txt[i + j];\n",
       "                if (pat[j] !== c) {\n",
       "                    skip = Math.max(1, j - right[c]);\n",
       "                    break;\n",
       "                }\n",
       "                }\n",
       "                if (skip === 0) {\n",
       "                return i;\n",
       "                }\n",
       "            }\n",
       "            return -1;\n",
       "        };\n",
       "        boyerMooreSearch.byteLength = pattern.byteLength;\n",
       "        return boyerMooreSearch;\n",
       "    }\n",
       "    //---------------------end copy/pasted solution------------------------\n",
       " \n",
       "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
       "        //this.lastnewLines=this.bufferednewLines;\n",
       "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
       "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
       "     {\n",
       "      //this.ready_to_send_data = false;\n",
       "      this.data_slice = [\n",
       "        //this.data.ms.slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
       "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
       "        ];\n",
       "  this.bufferednewLines=0;\n",
       "  //const buffer = new Uint8Array(10);\n",
       "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
       "  //  buffer[i] = i\n",
       "  //}\n",
       "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
       "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
       "  this.data_send_count++;\n",
       "  //if(this.channel==None)\n",
       "  //{\n",
       "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
       "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
       "  //} else \n",
       "  //{\n",
       "    //this.channel.send(this.data_send_count.toString())\n",
       "  //}\n",
       "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
       "\n",
       "//const comm = Jupyter.notebook.kernel.comm_manager.new_comm('my_comm_target', {'foo': 6})\n",
       "// Send data\n",
       "//comm.send({'foo': 7})\n",
       "\n",
       "// Register a handler\n",
       "//comm.on_msg(function(msg) {\n",
       "//    console.log(msg.content.data.foo);\n",
       "//});\n",
       "\n",
       "//  const comm = Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', {'foo': 6});\n",
       "  const comm = Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', array_to_send_as_json);\n",
       "//  const channel = await Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', array_to_send_as_json, []);\n",
       "\n",
       "//console.log('9');\n",
       "//comm.send({'foo': 7})\n",
       "//console.log(comm);\n",
       "//comm.send(array_to_send_as_json)\n",
       "//comm.on_msg(function(msg) {\n",
       "//    console.log(msg);\n",
       "//});\n",
       "\n",
       "//  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
       "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
       "  let success = false;\n",
       "  //for await (const message of channel.messages) \n",
       "//  if(0)\n",
       " comm.on_msg(function(message) \n",
       " {\n",
       "  {\n",
       "    if (message.content.data.response == 'close') {\n",
       "    //if (message.data.response == 'got comm open!') {\n",
       "      //const responseBuffer = new Uint8Array(message.buffers[0]);\n",
       "      //for (let i = 0; i < buffer.length; ++i) {\n",
       "      //  if (responseBuffer[i] != buffer[i]) {\n",
       "      //    console.error('comm buffer different at ' + i);\n",
       "      //    document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
       "      //    return;\n",
       "      //  }\n",
       "      //}\n",
       "      // Close the channel once the expected message is received. This should\n",
       "      // cause the messages iterator to complete and for the for-await loop to\n",
       "      // end.\n",
       "      //console.error('comm buffer same ' + responseBuffer);\n",
       "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
       "      ////channel.close();\n",
       "    }\n",
       "    //console.log('audio&image received');\n",
       "    //var message_parsed=JSON.parse(message.data.response);\n",
       "    //console.log('audio&image decoded');\n",
       "    //for(let i = 0; i < message_parsed.length; ++i)\n",
       "    {\n",
       "      \n",
       "      if (generate_wavegan)\n",
       "      {\n",
       "        //if((typeof message_parsed[i]) === 'string')\n",
       "        {\n",
       "          if(message.content.data.response.startsWith('data:audio'))\n",
       "          //if(message_parsed[i].startsWith('data:audio'))\n",
       "          {\n",
       "            //document.body.appendChild(document.createTextNode('audio decoded'));\n",
       "            //await \n",
       "            //playAudio1(message_parsed[i]);\n",
       "            //await \n",
       "            playAudio1(message.content.data.response);\n",
       "            time000=Date.now();\n",
       "            var frame_time=parseInt((1000/fps_wg));\n",
       "            var next_time=frame_time-((time000-time100)%frame_time);\n",
       "            setTimeout(playAudio2,next_time);\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      if (generate_stylegan2)\n",
       "      {\n",
       "        //if((typeof message_parsed[i]) === 'string')\n",
       "        {\n",
       "          //console.log(\"image string\");\n",
       "          if(message.content.data.response.startsWith('data:image'))\n",
       "          //if(message_parsed[i].startsWith('data:image'))\n",
       "          {\n",
       "            //document.body.appendChild(document.createTextNode('image decoded'));\n",
       "            //await \n",
       "            //displayPhoto1(message_parsed[i]);\n",
       "            //await \n",
       "            displayPhoto1(message.content.data.response,xsize,ysize);\n",
       "            time000=Date.now();\n",
       "            var frame_time=parseInt((1000/fps_sg2));\n",
       "            var next_time=frame_time-((time000-time100)%frame_time);\n",
       "            setTimeout(displayPhoto4,next_time);\n",
       "            var frame_now=(time000-time100)/frame_time;\n",
       "            if(Math.round(frame_now-frame_last)!=1)\n",
       "            {\n",
       "              console.log('f2:'+next_time+','+frame_time+','+\n",
       "                frame_now+','+frame_last+','+\n",
       "                (frame_now-frame_last));\n",
       "            }\n",
       "            frame_last=frame_now;\n",
       "          }\n",
       "        }\n",
       "        //else\n",
       "        {\n",
       "          //console.log(\"image not string\");\n",
       "          //displayPhoto3(message_parsed[i]);\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "  }\n",
       " });\n",
       "      this.ready_to_send_data = true;\n",
       "  //document.body.appendChild(document.createTextNode('done2.'));\n",
       "     } \n",
       " \n",
       "    }\n",
       " \n",
       "}\n",
       " \n",
       "var device = new eeg32();\n",
       "\n",
       "var generate_wavegan=device.generate_wavegan;\n",
       "var generate_stylegan2=device.generate_stylegan2;\n",
       "var xsize=device.xsize;\n",
       "var ysize=device.ysize;\n",
       "var time000=device.time000;\n",
       "var fps_wg=device.fps_wg;\n",
       "var fps_sg2=device.fps_sg2;\n",
       "var time100=device.time100;\n",
       "var frame_last=device.frame_last;\n",
       " \n",
       "    var connect = async () => {\n",
       "        await this.device.setupSerialAsync();\n",
       "    }\n",
       " \n",
       "    var disconnect = () => {\n",
       "        if (this.ui) this.ui.deleteNode()\n",
       "        this.device.closePort();\n",
       "    }\n",
       " \n",
       " \n",
       "        //const canvas = document.createElement('canvas');\n",
       "      //const audio = document.createElement('audio');\n",
       "      //const audio1 = document.createElement('audio');\n",
       "      //const audio2 = document.createElement('audio');\n",
       "      var audios = new Array();\n",
       "      if(device.generate_wavegan)\n",
       "      {\n",
       "        const audios_length = 5;\n",
       "        for(let i = 0; i < audios_length; i++)\n",
       "        {\n",
       "          audios[i]=document.createElement('audio');\n",
       "        }\n",
       "      }\n",
       " \n",
       "          //var ctx = canvas.getContext(\"2d\");\n",
       " \n",
       "      var images = new Array();\n",
       "      var canvases = new Array();\n",
       "      if(device.generate_stylegan2)\n",
       "      {\n",
       "        const images_length = 1;\n",
       "        const canvases_length = images_length;\n",
       "        for(let i = 0; i < images_length; i++)\n",
       "        {\n",
       "          //images[i]=document.createElement('image');\n",
       "          canvases[i]=document.createElement('canvas');\n",
       "          var ctx = canvases[i].getContext(\"2d\");\n",
       "          images[i]=new Image();\n",
       "          //images[i].onload = function() {\n",
       "          //  ctx.drawImage(images[i], 0, 0);\n",
       "          //};\n",
       "        }\n",
       "      }\n",
       "      //var image = new Image();\n",
       "      //image.onload = function() {\n",
       "      //  ctx.drawImage(image, 0, 0);\n",
       "      //};\n",
       "const div = document.createElement('div');\n",
       "const div2 = document.createElement('div');\n",
       "const div3 = document.createElement('div');\n",
       "const btnconnect = document.createElement('button');\n",
       "const btndisconnect = document.createElement('button');\n",
       "const capture = document.createElement('button');\n",
       "                  \n",
       "    async function takePhoto2(quality=1) {\n",
       "      btnconnect.remove();\n",
       "      capture.remove();\n",
       "      device.ready_to_send_data = true;\n",
       "    }\n",
       " \n",
       "    async function takePhoto(quality=1) {\n",
       " \n",
       "      btnconnect.textContent = 'connect';\n",
       "      div.appendChild(btnconnect);\n",
       "      btnconnect.onclick = async () => {\n",
       "        await device.setupSerialAsync();\n",
       "    };\n",
       "//      btnconnect.onclick = this.connect;\n",
       "      \n",
       "      btndisconnect.textContent = 'disconnect';\n",
       "      div.appendChild(btndisconnect);\n",
       "      btndisconnect.onclick = async () => {\n",
       "        //if (this.ui) this.ui.deleteNode()\n",
       "        device.closePort();\n",
       "    };\n",
       "//      btndisconnect.onclick = this.disconnect;\n",
       "      \n",
       "      capture.textContent = 'Capture';\n",
       "      capture.onclick = takePhoto2;\n",
       "      div.appendChild(capture);\n",
       "     \n",
       "      //div.appendChild(canvas);\n",
       "      //div.appendChild(audio);\n",
       "      //div.appendChild(audio1);\n",
       "      //div.appendChild(audio2);\n",
       "      if(device.generate_wavegan)\n",
       "      {\n",
       "        for(let i = 0; i < audios.length; i++)\n",
       "        {\n",
       "          div2.appendChild(audios[i]);\n",
       "          //audios[i].controls = true;\n",
       "          //audios[i].autoplay = true;\n",
       "        }\n",
       "      }\n",
       "      if(device.generate_stylegan2)\n",
       "      {\n",
       "        for(let i = 0; i <canvases.length; i++)\n",
       "        {\n",
       "          div3.appendChild(canvases[i]);\n",
       "        }\n",
       "      }\n",
       "      //for(let i = 0; i < images.length; i++)\n",
       "      //{\n",
       "      //  div.appendChild(images[i]);\n",
       "      //}\n",
       " \n",
       "      document.querySelector(\"#buttons\").appendChild(div);\n",
       "      document.querySelector(\"#buttons\").appendChild(div2);\n",
       "      document.querySelector(\"#buttons\").appendChild(div3);\n",
       "//      document.body.appendChild(div);\n",
       "//      document.body.appendChild(div2);\n",
       "//      document.body.appendChild(div3);\n",
       "         await new Promise((resolve) => capture.onclick = resolve);\n",
       " \n",
       "      btnconnect.remove();\n",
       "      capture.remove();\n",
       "      device.ready_to_send_data = true;\n",
       "    }\n",
       " \n",
       "    async function takePhoto1(quality=1) {  \n",
       "      //var data_slice_send=this.device.data_slice;\n",
       "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
       "      //var data_slice_send=[this.device.data_slice[0]];\n",
       "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
       "        //console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
       "        //console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
       "      device.bufferednewLines=0;\n",
       "      return data_slice_send;      \n",
       "    }\n",
       " \n",
       "    async function displayPhoto1(photodata,photoWidth=512,photoHeight=512) {\n",
       "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
       "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
       "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
       "    }\n",
       "    var image_now=0;\n",
       "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
       "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
       "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
       "     //image.src = photodata;\n",
       "      {\n",
       "       if(canvases[image_now%images.length].width != photoWidth)\n",
       "       {\n",
       "         canvases[image_now%images.length].width = photoWidth;\n",
       "       }\n",
       "       if(canvases[image_now%images.length].height != photoHeight) \n",
       "       {\n",
       "         canvases[image_now%images.length].height = photoHeight;\n",
       "       }\n",
       "       images[image_now%images.length].src = photodata;\n",
       "        //audios[audio_now%audios.length].play();\n",
       "      }\n",
       "      //image_now++;\n",
       "    }\n",
       "    async function displayPhoto4(photodata){//},photoWidth,photoHeight) {\n",
       "      ctx.drawImage(images[image_now%images.length], 0, 0);\n",
       "      image_now++;\n",
       "    }\n",
       "    var img_step=0;\n",
       "    async function displayPhoto3(photodata,photoWidth=512,photoHeight=512) {\n",
       "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
       "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
       "      fs.writeFile('img0.jpg', photodata, function (err) {\n",
       "        // console.log(\"save img!\" );\n",
       "      });\n",
       "      var photofile='img0.jpg?'+img_step;\n",
       "      img_step+=1;\n",
       "      //console.log(\"save img!\" );\n",
       "      await displayPhoto2(photofile,photoWidth,photoHeight);\n",
       "    }\n",
       " \n",
       "    var audio_now=0;\n",
       "    async function playAudio1(audiodata){//},photoWidth=512,photoHeight=512) {\n",
       "      //const canvas = document.createElement('canvas');\n",
       "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
       "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
       "      //audio.controls = true;\n",
       "      //audio.autoplay = true;\n",
       "      //audio1.controls = true;\n",
       "      //audio1.autoplay = true;\n",
       "      //audio2.controls = true;\n",
       "      //audio2.autoplay = true;\n",
       " \n",
       "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
       "      //var canvas = document.getElementById(\"c\");\n",
       "      ///var ctx = canvas.getContext(\"2d\");\n",
       " \n",
       "      ///var image = new Image();\n",
       "      ///image.onload = function() {\n",
       "      ///  ctx.drawImage(image, 0, 0);\n",
       "      ///};\n",
       "      //audio.src = audiodata;\n",
       "      //audio.play()\n",
       "      //if(audio_now%2==0)\n",
       "      //{\n",
       "      //  audio1.src = audiodata;\n",
       "      //  audio1.play()\n",
       "      //}\n",
       "      //else\n",
       "      //{\n",
       "      //  audio2.src = audiodata;\n",
       "      //  audio2.play()\n",
       "      //}\n",
       "      //for(let i = 0; i < audios.length; ++i)\n",
       "      {\n",
       "        audios[audio_now%audios.length].src = audiodata;\n",
       "        //if(audio_now==0)\n",
       "        {\n",
       "          audios[audio_now%audios.length].controls = true;\n",
       "          //audios[audio_now%audios.length].autoplay = true;\n",
       "        }\n",
       "        //audios[audio_now%audios.length].play();\n",
       "      }\n",
       "      //audio_now++;\n",
       " \n",
       "    }\n",
       "    async function playAudio2(audiodata){//},photoWidth=512,photoHeight=512) {\n",
       "      audios[audio_now%audios.length].play();\n",
       "      audio_now++;\n",
       "    }\n",
       "    \n",
       "  takePhoto();\n",
       "  var data_count=0;\n",
       "  var frame_last=0;\n",
       "\n",
       "async function check_to_send() {\n",
       "  //while(true)\n",
       "  {\n",
       "   if(device.bufferednewLines)\n",
       "   {\n",
       "    //if(this.bufferednewLines>this.data_slice_size)\n",
       "    //  {\n",
       "    //    this.bufferednewLines=this.data_slice_size;\n",
       "    //  }\n",
       "    /*device.time000=Date.now();\n",
       "    if(device.generate_wavegan)\n",
       "    {\n",
       "      device.this_frame_wg=parseInt((device.time000-device.time100)*device.fps_wg);\n",
       "      if(device.this_frame_wg>device.last_frame_wg)\n",
       "      {\n",
       "        device.last_frame_wg=device.this_frame_wg;\n",
       "        device.send_wg=true;\n",
       "      }\n",
       "    }\n",
       "    if(device.generate_stylegan2)\n",
       "    {\n",
       "      device.this_frame_sg2=parseInt((device.time000-device.time100)*device.fps_sg2);\n",
       "      if(device.this_frame_sg2>device.last_frame_sg2)\n",
       "      {\n",
       "        device.last_frame_sg2=device.this_frame_sg2;\n",
       "        device.send_sg2=true;\n",
       "      }\n",
       "    }\n",
       "    if(device.send_wg || device.send_sg2)\n",
       "    //if(this.bufferednewLines>512/(this.fps_sg2))\n",
       "    if(device.ready_to_send_data)*/\n",
       "    {\n",
       "      //this.bufferednewLines=512/this.fps;\n",
       " \n",
       "        device.takeandsendSlice(device.data.count-1-device.bufferednewLines,device.data.count-1);\n",
       "      device.send_wg=false;\n",
       "      device.send_sg2=false;\n",
       "    }\n",
       "        //console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
       "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
       "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
       "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
       "   }\n",
       "  }\n",
       "  device.time000=Date.now();\n",
       "//  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
       "  var frame_time=parseInt((1000/device.fps));\n",
       "  var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
       "  setTimeout(check_to_send,next_time);\n",
       "  var frame_now=(device.time000-device.time100)/frame_time;\n",
       "  if(Math.round(frame_now-frame_last)!=1)\n",
       "  {\n",
       "    console.log('f1:'+next_time+','+frame_time+','+frame_now+','+\n",
       "      frame_last+','+(frame_now-frame_last));\n",
       "  }\n",
       "  frame_last=frame_now;\n",
       "}\n",
       "  device.time000=Date.now();\n",
       "  var frame_time=parseInt((1000/device.fps));\n",
       "  var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
       "  setTimeout(check_to_send,next_time);\n",
       "  //console.log(next_time);\n",
       "//var intervalID = setInterval(check_to_send,(1000/device.fps_wg)/10);\n",
       "//  window.requestAnimationFrame\n",
       " \n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfreq = 512 \n",
    "#ch_types=['eeg']*len(ch_names)\n",
    "#info = mne.create_info(ch_names = ch_names, sfreq = sfreq, ch_types=ch_types)\n",
    "ch_types_wg=['eeg']*len(ch_names_wg)\n",
    "info_wg = mne.create_info(ch_names = ch_names_wg, sfreq = sfreq, ch_types=ch_types_wg)\n",
    "ch_types_wg_l=['eeg']*len(ch_names_wg_l)\n",
    "info_wg_l = mne.create_info(ch_names = ch_names_wg_l, sfreq = sfreq, ch_types=ch_types_wg_l)\n",
    "ch_types_wg_r=['eeg']*len(ch_names_wg_r)\n",
    "info_wg_r = mne.create_info(ch_names = ch_names_wg_r, sfreq = sfreq, ch_types=ch_types_wg_r)\n",
    "ch_types_sg2=['eeg']*len(ch_names_sg2)\n",
    "info_sg2 = mne.create_info(ch_names = ch_names_sg2, sfreq = sfreq, ch_types=ch_types_sg2)\n",
    " \n",
    "#label_names = ch_names\n",
    "#no_names = [''] * len(label_names)\n",
    " \n",
    "from IPython.display import Javascript\n",
    "from IPython.display import display, Javascript\n",
    "#from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "from IPython.display import Javascript\n",
    "\n",
    "import IPython\n",
    "display(IPython.display.HTML('''\n",
    "    <div id=\"buttons\"></div>\n",
    "    '''))\n",
    "\n",
    "#import ipywidgets as widgets\n",
    "\n",
    "\n",
    "#def clicked(arg):\n",
    "#    print(\"button has been clicked!\")\n",
    "\n",
    "#rand_num_output = widgets.Output()\n",
    "\n",
    "#button_connect = widgets.Button(description = 'connect')   \n",
    "#button_download.on_click(clicked)\n",
    "#display(button_connect)\n",
    "#button_disconnect = widgets.Button(description = 'disconnect')   \n",
    "#button_download.on_click(clicked)\n",
    "#display(button_disconnect)\n",
    "#button_Capture = widgets.Button(description = 'Capture')   \n",
    "#button_download.on_click(clicked)\n",
    "#display(button_Capture)\n",
    "\n",
    "import json\n",
    "data_read=False\n",
    " \n",
    "import base64\n",
    "from io import BytesIO\n",
    " \n",
    "data_read=None\n",
    "data_buffer=None\n",
    "data_analyse=None\n",
    "\n",
    "from time import perf_counter\n",
    "time100=perf_counter()\n",
    "time_dir=f'{(time100*1000):9.0f}'\n",
    "#%mkdir '/content/gdrive/MyDrive/EEG-GAN-audio-video/out/{time_dir}'\n",
    "\n",
    "if generate&gen_stylegan2:#_ada or generate_stylegan2_ext:\n",
    "  from IPython.display import Image\n",
    "  import matplotlib.figure\n",
    "  import imageio\n",
    "  #fps=3\n",
    "  #video_out = imageio.get_writer('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+time_dir+'/output.mp4', mode='I', fps=fps_sg2, codec='libx264', bitrate='16M')\n",
    " \n",
    "  js_image = \"\"\n",
    "  from PIL import ImageFont, ImageDraw\n",
    " \n",
    "  if generate&gen_sg2_rosasalberto_tf2:\n",
    "    __z = None\n",
    "    dlatents = None\n",
    "  if generate&gen_sg2_moono_tf2:\n",
    "    seed = 6600\n",
    "    rnd = np.random.RandomState(seed)\n",
    "    latents = rnd.randn(1, g_clone.z_dim)\n",
    "    labels = rnd.randn(1, g_clone.labels_dim)\n",
    "    latents = latents.astype(np.float32)\n",
    "    labels = labels.astype(np.float32)\n",
    "    #print([latents, labels])\n",
    "    #image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
    "    #Gs_kwargs.randomize_noise = False\n",
    "    #image_out = postprocess_images(image_out)\n",
    "    #image_out = image_out.numpy()\n",
    "    #print(image_out)\n",
    "  if generate&gen_sg2_nagolinc_pt:\n",
    "    __z1 = None\n",
    "  if generate&gen_sg2_nvlabs_ada_pt:\n",
    "    ws=None\n",
    "  if generate&gen_sg3_nvlabs_pt:\n",
    "    ws3=None\n",
    "  if generate&gen_sg3_Expl0dingCat_pt:\n",
    "    ws3m=None\n",
    "  if generate&gen_sg2_shawwn:\n",
    "    Gs_kwargs = dnnlib.EasyDict()\n",
    "    Gs_kwargs.randomize_noise = False\n",
    "    _z1 = None\n",
    "  elif generate&gen_tf1:\n",
    "   Gs_kwargs = dnnlib.EasyDict()\n",
    "   #Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False)\n",
    "   Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
    "   Gs_kwargs.randomize_noise = False\n",
    "   _z1 = None\n",
    " \n",
    "if generate&gen_wavegan:\n",
    "  _G_z = None\n",
    "  _G_z_full = None\n",
    "  _G_z_full2 = None\n",
    "  _z = None\n",
    " \n",
    "samples=0\n",
    " \n",
    "last_frame_wg=-1\n",
    "last_frame_sg2=-1\n",
    "time111=perf_counter()\n",
    " \n",
    "last_time=0\n",
    "def target_func1(comm, msg):\n",
    "#print('00')\n",
    "#def target_func1(comm, open_msg):\n",
    " #print('0')\n",
    " #print(open_msg)\n",
    " #@comm.on_msg\n",
    " #def _recv(msg):\n",
    "  #print('1')\n",
    "  #print(msg)\n",
    "  # Use msg['content']['data'] for the data in the message\n",
    "  #comm.send({'echo': msg['content']['data']})\n",
    "        \n",
    "  time000=perf_counter()\n",
    "  #import dnnlib \n",
    "  #import dnnlib.tflib as tflib \n",
    "  #import PIL.Image \n",
    "  #from tqdm import tqdm\n",
    "  ##global _G, _D, Gs\n",
    "  #tflib.init_tf()\n",
    "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
    "  #   _G, _D, Gs = pickle.load(fp)\n",
    " \n",
    "  # Only send the response if it's the data we are expecting.\n",
    "  #if msg['content']['data'] == 'the data':\n",
    "  #  comm.send({\n",
    "  #        'response': 'got comm open!',\n",
    "  #      }, None, msg['buffers']);\n",
    "  #  print(msg['buffers'])\n",
    "  #else:\n",
    "    #print(msg['content']['data'])\n",
    "    #data_read=True\n",
    "  global last_time\n",
    "  global time100\n",
    "  global samples\n",
    "  #array_to_receive_as_json = '[[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0]]'\n",
    "  array_to_receive_as_json = msg['content']['data']\n",
    "  #global data_read\n",
    "  data_read = json.loads(array_to_receive_as_json)\n",
    "  #print('got data')\n",
    "  #print(data_read)\n",
    "  new_data_len=len(data_read[0])\n",
    "  #print(new_data_len)\n",
    "  samples=samples+new_data_len#len(data_analyse[0])\n",
    "  time110=perf_counter()\n",
    "  out_text=f'{(samples):7.0f}'+' sam, '\n",
    "  out_text=out_text+f'{(new_data_len):4.0f}'+\" sam/pac, \"\n",
    "  out_text=out_text+f'{(time110-time100):7.2f}'+\" sec, \"\n",
    "  out_text=out_text+f'{(samples/(time110-time100)):7.2f}'+' sam/sec'\n",
    "  out_text=out_text+f'{(time110-time100)-last_time:7.2f}'+\" sec, \"\n",
    "  out_text=out_text+f'{(new_data_len/((time110-time100)-last_time)):7.2f}'+' sam/sec'\n",
    "  last_time=(time110-time100)\n",
    "  #comm.send({\n",
    "  #        'response': out_text,\n",
    "  #      }, None, msg['buffers']);\n",
    "  #print(out_text)\n",
    "  global ch_locations,bands,duration,overlap,methods,uVperStep,sfreq,dim_sg2,dim_wg\n",
    "  global ch_names_wg, info_wg, ch_names_wg_l, info_wg_l, ch_names_wg_r, info_wg_r, ch_names_sg2, info_sg2\n",
    "  #global label_names,ch_locations,info,bands,duration,overlap,methods,uVperStep,sfreq,dim_sg2,dim_wg\n",
    "  #print(duration)\n",
    "  send_wg=False\n",
    "  send_sg2=False\n",
    "  \n",
    "  if not (data_read is None):\n",
    "      #print('read_data-data_read')\n",
    "      #print(len(data_read[0]))\n",
    "      global data_buffer, data_analyse\n",
    "      if data_buffer is None:\n",
    "        data_buffer=data_read\n",
    "      else:\n",
    "        data_buffer=np.concatenate((data_buffer,data_read),axis=1)\n",
    "      data_read = None\n",
    " \n",
    "      data_buffer_len=len(data_buffer[0])\n",
    "      #print(data_buffer_len)\n",
    "      #if (int(duration*sfreq)+1)>(int(sfreq/fps)):\n",
    "      if True:\n",
    "        data_slice_len=int(duration*sfreq)+1\n",
    "      #else:\n",
    "      #  data_slice_len=int(sfreq/fps)+1\n",
    "      #print(data_slice_len)\n",
    "      if data_buffer_len>data_slice_len:\n",
    "        data_buffer=data_buffer[0:len(data_buffer),data_buffer_len-data_slice_len:data_buffer_len]\n",
    "      #print(len(data_buffer[0]))\n",
    "      #print(data_slice_len)\n",
    "      data_analyse=None\n",
    "      if len(data_buffer[0])==data_slice_len:\n",
    "       global last_frame_sg2, fps_sg2\n",
    "       global last_frame_wg, fps_wg\n",
    "       if generate&gen_wavegan: \n",
    "        this_frame_wg=int((time000-time100)*fps_wg+1/(2*fps_sg2/fps_wg))\n",
    "        if this_frame_wg>last_frame_wg:\n",
    "          data_analyse=data_buffer\n",
    "          last_frame_wg=this_frame_wg\n",
    "          send_wg=True\n",
    "          #print(f'{(time000-time100)*fps_wg:7.2f}'+\" frame wavegan\")\n",
    "       if generate&gen_stylegan2:   \n",
    "        #global last_frame_sg2, fps_sg2\n",
    "        this_frame_sg2=int((time000-time100)*fps_sg2)\n",
    "        if this_frame_sg2>last_frame_sg2:\n",
    "          #if not send_wg:\n",
    "          data_analyse=data_buffer\n",
    "          last_frame_sg2=this_frame_sg2\n",
    "          send_sg2=True\n",
    "          #print(f'{(time000-time100)*fps_sg2:7.2f}'+\" frame stylegan2\")\n",
    "      #data_buffer=data_analyse\n",
    "      #print('read_data-data_analyse')\n",
    "      #print(len(data_analyse[0]))\n",
    "  \n",
    "  #if False: \n",
    "  #if True: \n",
    "  if not(data_analyse is None):\n",
    "    #if (time111-time000)>=(1/fps):\n",
    "    parts=1\n",
    "    if (generate&gen_wg_stereo):\n",
    "      if (send_wg):\n",
    "        parts=2\n",
    "    for part in range(parts):\n",
    "      #print(parts)\n",
    "      time111=perf_counter()\n",
    "      if send_wg:\n",
    "        ch_names=ch_names_wg\n",
    "        ch_locations=ch_locations_wg\n",
    "        info=info_wg\n",
    "        if generate&gen_wg_stereo:\n",
    "          #print(part)\n",
    "          if part==0:\n",
    "            ch_names=ch_names_wg_l\n",
    "            ch_locations=ch_locations_wg_l\n",
    "            info=info_wg_l\n",
    "            #print('l')\n",
    "          if part==1:\n",
    "            ch_names=ch_names_wg_r\n",
    "            ch_locations=ch_locations_wg_r\n",
    "            info=info_wg_r\n",
    "            #print('r')\n",
    "      elif send_sg2:\n",
    "        ch_names=ch_names_sg2\n",
    "        ch_locations=ch_locations_sg2\n",
    "        info=info_sg2\n",
    "      data_uv = [0]*len(ch_names)\n",
    "      for j in range(len(ch_names)):\n",
    "        data_uv[j]=[0]*len(data_analyse[ch_locations[j]])\n",
    "        for i in range(len(data_analyse[ch_locations[j]])):\n",
    "          data_uv[j][i] = data_analyse[ch_locations[j]][i] * uVperStep * 2\n",
    "      if (part==parts-1):\n",
    "        data_analyse=None\n",
    "  \n",
    "      time002=perf_counter()\n",
    "      #print (f'002: {(time002-time000):.1f}s')\n",
    "\n",
    "      raw = mne.io.RawArray(data_uv, info, verbose=50)\n",
    "      time003=perf_counter()\n",
    "      #print (f'003: {(time003-time000):.1f}s')\n",
    "      datas=[]\n",
    "      for band in range(len(bands)):\n",
    "        datas.append(raw)\n",
    "      time004=perf_counter()\n",
    "      epochs = []\n",
    "      #print (f'004: {(time004-time000):.1f}s')\n",
    "      for band in range(len(bands)):\n",
    "        epochs.append(mne.make_fixed_length_epochs(datas[band], duration=duration/2, preload=True, overlap=overlap, verbose=50))\n",
    "      time005=perf_counter()\n",
    "      #print (f'005: {(time005-time000):.1f}s')\n",
    "      n_generate=int((float(len(data_uv[0]))/float(sfreq))/duration)\n",
    "      n_generate=1\n",
    "      part_len = 10\n",
    "      #dim = 512\n",
    "      part_len = 1\n",
    " \n",
    "      n_parts = n_generate//part_len\n",
    "      if n_generate%part_len>0:\n",
    "        n_parts=n_parts+1\n",
    "      n_parts=1\n",
    "      global vol\n",
    "    \n",
    "      if generate&gen_wavegan:\n",
    "        psd_array_wg=np.random.rand(part_len, dim_wg) \n",
    "      if generate&gen_stylegan2:\n",
    "        psd_array_sg2=np.random.rand(part_len, dim_sg2) \n",
    "      time006=perf_counter()\n",
    "      #print (f'006: {(time006-time000):.1f}s')\n",
    "    \n",
    "      for j in range(n_parts): # display separate audio for each break\n",
    "        for i in range(part_len): # display separate audio for each break\n",
    "            ji = j * part_len + i\n",
    "            \n",
    "            if (i==0) and (n_generate-ji<part_len):\n",
    "              if generate&gen_wavegan:\n",
    "                psd_array_wg=np.random.rand((n_generate-ji), dim_wg) \n",
    "              if generate&gen_stylegan2:\n",
    "                psd_array_sg2=np.random.rand((n_generate-ji), dim_sg2) \n",
    "        \n",
    "            sfreq = raw.info['sfreq']  # the sampling frequency\n",
    "            time0061=perf_counter()\n",
    "            #print (f'0061: {(time0061-time000):.1f}s')\n",
    "            \n",
    "            if generate&gen_wavegan:# and send_wg:\n",
    "              psds_wg=np.zeros(dim_wg)\n",
    "            if generate&gen_stylegan2:\n",
    "              psds_sg2=np.zeros(dim_sg2)\n",
    "            \n",
    "            for method in range(len(methods)):\n",
    "             for band in range(len(bands)):\n",
    "              fmin=bands[band][0]\n",
    "              fmax=bands[band][1]\n",
    "              time0071=perf_counter()\n",
    "              #print (f'0071: {(time0071-time000):.1f}s')\n",
    "              #if band == 0:\n",
    "              #print(epochs[band])\n",
    "              con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
    "                #epochs[band], method=methods[method], mode='fourier', sfreq=sfreq, fmin=fmin,\n",
    "                epochs[band], method=methods[method], mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "                #epochs[band][ji:ji+1], method=methods[method], mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
    "                #fmax=fmax, faverage=True, mt_adaptive=False, n_jobs=1, verbose=50)\n",
    "                fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1, verbose=50)\n",
    "              time007=perf_counter()\n",
    "              #print (f'007: {(time007-time000):.1f}s')\n",
    "              coh_len=int(len(ch_names)*(len(ch_names)-1)/2)\n",
    "              psds_shift1=int(round(method*len(bands)+band)*coh_len)\n",
    "              ji1=0\n",
    "              for j1 in range(0,len(ch_names)): # display separate audio for each break\n",
    "                for i1 in range(0,j1): # display separate audio for each break\n",
    "                  #print(ji1)\n",
    "                  if generate&gen_wavegan:\n",
    "                   if ji1+psds_shift1<dim_wg:\n",
    "                    psds_wg[ji1+psds_shift1]=(con[j1][i1][0]-0.5)*1\n",
    "                  if generate&gen_stylegan2:\n",
    "                   for i01 in range(0,int(dim_sg2/coh_len)):\n",
    "                     if ji1+psds_shift1+coh_len*i01<dim_sg2:\n",
    "                      #print(ji1+psds_shift1+coh_len*i01)\n",
    "                      psds_sg2[ji1+psds_shift1+coh_len*i01]=(con[j1][i1][0]-0.5)*1\n",
    "                  ji1 = ji1+1\n",
    "            if generate&gen_wavegan:\n",
    "              psd_array_wg[i]=psds_wg\n",
    "            if generate&gen_stylegan2:\n",
    "              psd_array_sg2[i]=psds_sg2\n",
    "            if (i==part_len-1) or (ji==n_generate-1) :\n",
    "             encodeds=[]\n",
    "             #print('encodeds=[]')\n",
    "             if generate&gen_wavegan:\n",
    "               if send_wg:\n",
    "                global G_z, z, _G_z, _G_z_full, _G_z_full2#, _z\n",
    "                _z = psd_array_wg * vol\n",
    "                #print('>>sess.run')\n",
    "                _G_z = sess.run(G_z, {z: _z})[:,:,0]\n",
    "                #print('<<sess.run')\n",
    "                if j==0:\n",
    "                  _G_z_full=_G_z\n",
    "                else:\n",
    "                  _G_z_full=np.append(_G_z_full,_G_z)\n",
    "                #if _G_z_full2 is None:\n",
    "                #  _G_z_full2=_G_z_full\n",
    "                #else:\n",
    "                #  _G_z_full2=np.append(_G_z_full2,_G_z_full)\n",
    "                                    \n",
    "                if (ji==n_generate-1):\n",
    "                  if (part==0) and not (part==parts-1):\n",
    "                    #print(_G_z_full)\n",
    "                    _G_z_full_l=_G_z_full.flatten()\n",
    "                    #print(_G_z_full_l)\n",
    "                  if (part==parts-1):\n",
    "                    if (part==0):\n",
    "                      _G_z_full=_G_z_full.flatten()\n",
    "                    if (part==1):\n",
    "                      #_G_z_full_lr=_G_z_full.flatten()\n",
    "                      #_G_z_full_lr=_G_z_full\n",
    "                      _G_z_full_r=_G_z_full.flatten()\n",
    "                      #print(_G_z_full_r)\n",
    "                      #_G_z_full=_G_z_full_l\n",
    "                      if generate&gen_wg_st_swap:\n",
    "                        _G_z_full=np.append([_G_z_full_l],[_G_z_full_r], axis=0)\n",
    "                      else:\n",
    "                        _G_z_full=np.append([_G_z_full_r],[_G_z_full_l], axis=0)\n",
    "                      #print(_G_z_full)\n",
    "                      if _G_z_full.ndim > 1 and _G_z_full.shape[0] == 2:\n",
    "                        _G_z_full = _G_z_full.T\n",
    "\n",
    "                    buffer = BytesIO()\n",
    "                    if generate&gen_mp3:\n",
    "                      buffer_wav = BytesIO()\n",
    "                      scipy.io.wavfile.write(buffer_wav, hz, _G_z_full) # change rate for different tempo\n",
    "                      AudioSegment.from_wav(buffer_wav).export(buffer, format=\"mp3\")\n",
    "                    if generate&gen_wav:\n",
    "                      scipy.io.wavfile.write(buffer, hz, _G_z_full) # change rate for different tempo\n",
    "                    \n",
    "                    #wave.open(buffer, mode='wb')\n",
    "                    #AudioSegment.from_wav(buffer).export('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+\n",
    "                    #               f'{(time100*1000):9.0f}'+'/'+f'{(time000*1000):9.0f}'+'.mp3', format=\"mp3\")\n",
    " \n",
    "                    buffer.seek(0)\n",
    "                    mysound = buffer.getvalue()\n",
    "                    if generate&gen_mp3:\n",
    "                      encoded= \"data:audio/mp3;base64,\"+base64.b64encode(mysound).decode()\n",
    "                    if generate&gen_wav:\n",
    "                      encoded= \"data:audio/wav;base64,\"+base64.b64encode(mysound).decode()\n",
    "                    #print('audio encoded')\n",
    " \n",
    "                    time110=perf_counter()\n",
    "                    #print (f'110: {(time110-time000):.1f}s')\n",
    "                    #js_image=js\n",
    "                    #encodeds.append(encoded)\n",
    "                    comm.send({\n",
    "                      'response': encoded,\n",
    "                      }, None, msg['buffers']);\n",
    "                    #break\n",
    "    \n",
    "                  #encoded = base64.b64encode(image_asarray).decode('ascii')\n",
    "                  #js='''this.photo.src = \"data:image/png;base64,{0}\"'''.format(encoded)\n",
    " \n",
    "                  \n",
    "                  #js='''senderChannel.postMessage(\"{0}\")'''.format(encoded)\n",
    "                    #js='''playAudio1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
    "                    #js_image=js\n",
    "             if generate&gen_stylegan2:\n",
    "              if send_sg2:#_ada or generate_stylegan2_ext:\n",
    "               if generate&gen_sg2_rosasalberto_tf2:\n",
    "                global generator, dlatents, __z\n",
    " \n",
    "                #seed = 6600\n",
    "                # creating random latent vector\n",
    "                #rnd = np.random.RandomState(seed)\n",
    "                #__z = rnd.randn(1, 512).astype('float32')\n",
    "                # running mapping network\n",
    "                time1101=perf_counter()\n",
    "                #print (f'1101: {(time1101-time000):.1f}s')\n",
    "                #dlatents = generator.mapping_network(__z)  \n",
    "                time1102=perf_counter()\n",
    "                #print (f'1102: {(time1102-time000):.1f}s')\n",
    " \n",
    "                __z = psd_array_sg2 * vol\n",
    "                dlatents = generator.mapping_network(__z)\n",
    "                time1103=perf_counter()\n",
    "                #print (f'1103: {(time1103-time000):.1f}s')\n",
    "                image_out = generator.synthesis_network(dlatents)\n",
    "                time1104=perf_counter()\n",
    "                #print (f'1104: {(time1104-time000):.1f}s')\n",
    "                #converting image/s to uint8\n",
    "                img = convert_images_to_uint8(image_out, nchw_to_nhwc=True, uint8_cast=True)\n",
    "                #plotting images\n",
    "                #ax[i].axis('off')\n",
    "                #img_plot = ax[i].imshow(img.numpy()[0])   \n",
    "                time1105=perf_counter()\n",
    "                #print (f'1105: {(time1105-time000):.1f}s')\n",
    "                #images=[img.numpy()[0]]\n",
    "                images=img.numpy()\n",
    "               elif generate&gen_sg2_moono_tf2:\n",
    "                 global g_clone, latents, labels\n",
    "                 latents = psd_array_sg2 * vol\n",
    "                 image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
    "                 image_out = postprocess_images(image_out)\n",
    "                 image = image_out.numpy()\n",
    "               elif generate&gen_sg2_nagolinc_pt:\n",
    "                global device, __z1, g, latent_avg\n",
    "                __z1 = psd_array_sg2 * vol\n",
    "                with torch.no_grad():\n",
    "                  img_pt, _ = g(\n",
    "                    [torch.from_numpy(np.float32(__z1)).to(device)],\n",
    "                    truncation=0.5,\n",
    "                    truncation_latent=latent_avg.to(device),\n",
    "                    randomize_noise=False,\n",
    "                  )\n",
    "                images=img_pt.cpu().numpy()\n",
    "               elif generate&gen_sg2_nvlabs_ada_pt:\n",
    "                global G, ws#, device\n",
    "                device = torch.device('cuda')\n",
    " \n",
    "                z_samples = psd_array_sg2 * vol\n",
    "                w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "                w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
    "                w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
    "                w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
    "                ws = (w_opt).repeat([1, G.mapping.num_ws, 1])\n",
    " \n",
    "                synth_images = G.synthesis(ws, noise_mode='const')\n",
    "                synth_images = (synth_images + 1) * (255/2)\n",
    "                synth_images = synth_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "                #out.append_data(synth_images)\n",
    "                images=[synth_images]\n",
    "               elif generate&gen_sg3_nvlabs_pt:\n",
    "                global G3, ws3#, device\n",
    "                device = torch.device('cuda')\n",
    " \n",
    "                z_samples = psd_array_sg2 * vol\n",
    "                w_samples = G3.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "                w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
    "                w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
    "                w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
    "                ws3 = (w_opt).repeat([1, G3.mapping.num_ws, 1])\n",
    " \n",
    "                synth_images = G3.synthesis(ws3, noise_mode='const')\n",
    "                synth_images = (synth_images + 1) * (255/2)\n",
    "                synth_images = synth_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "                #out.append_data(synth_images)\n",
    "                images=[synth_images]\n",
    "               elif generate&gen_sg3_Expl0dingCat_pt:\n",
    "                global G3m, ws3m#, device\n",
    "                device = torch.device('cuda')\n",
    " \n",
    "                z_samples = psd_array_sg2 * vol\n",
    "                w_samples = G3m.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "                w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
    "                w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
    "                w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
    "                ws3m = (w_opt).repeat([1, G3m.mapping.num_ws, 1])\n",
    " \n",
    "                synth_images = G3m.synthesis(ws3m, noise_mode='const')\n",
    "                synth_images = (synth_images + 1) * (255/2)\n",
    "                synth_images = synth_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "                #out.append_data(synth_images)\n",
    "                images=[synth_images]\n",
    "               elif generate&gen_tf1:\n",
    "                global _G, _D, Gs, Gs_kwargs, _z1\n",
    "                _z1 = psd_array_sg2 * vol\n",
    "                time1101=perf_counter()\n",
    "                #print (f'1101: {(time1101-time000):.1f}s')\n",
    "                #print('>>Gs.run')\n",
    "                images = Gs.run(_z1, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
    "                #print('<<Gs.run')\n",
    "                time1102=perf_counter()\n",
    "                #print (f'1102: {(time1102-time000):.1f}s')\n",
    "                #if generate&gen_sg2_shawwn:\n",
    "                #  n_sample=1\n",
    "                #  inputSize=1024\n",
    "                #  z = np.random.randn(n_sample, inputSize).astype(\"float32\")\n",
    "                #  images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
    "\n",
    "               if True:\n",
    "                for image in images:\n",
    "                  time1110=perf_counter()\n",
    "                  #print (f'1110: {(time1110-time000):.1f}s')\n",
    "                  #print(image)\n",
    "                  if generate&gen_sg2_nagolinc_pt:\n",
    "                    image = ((image+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
    "                  elif generate&gen_sg2_shawwn:\n",
    "                    image = ((image+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
    "                  #if generate_stylega2_ada_pytorch:\n",
    " \n",
    "                  image_pil=PIL.Image.fromarray(image, 'RGB')\n",
    "                  #if generate&gen_sg2_shawwn:\n",
    "                  #  display(image_pil)\n",
    "                  #print(image_pil)\n",
    "                  image_asarray=np.asarray(image_pil)\n",
    "                  #print(image_asarray)\n",
    "                  time1111=perf_counter()\n",
    "                  #print (f'1111: {(time1111-time000):.1f}s')\n",
    "                  #global video_out\n",
    "                  #video_out.append_data(image_asarray)\n",
    "                  time1112=perf_counter()\n",
    "                  #print (f'1112: {(time1112-time000):.1f}s')\n",
    "                  img=image_pil.resize((xsize,ysize),PIL.Image.ANTIALIAS)\n",
    "                  #print(img)\n",
    "                  time1113=perf_counter()\n",
    "                  #print (f'1113: {(time1113-time000):.1f}s')\n",
    "                  buffer = BytesIO()\n",
    "                  if generate&gen_jpeg:\n",
    "                    img.save(buffer,format=\"JPEG\")                  #Enregistre l'image dans le buffer\n",
    "                  if generate&gen_png:\n",
    "                    img.save(buffer,format=\"PNG\")                  #Enregistre l'image dans le buffer\n",
    "                  #img.save('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+\n",
    "                  #          f'{(time100*1000):9.0f}'+'/'+f'{(time000*1000):9.0f}'+'.png',format=\"PNG\")\n",
    "\n",
    " \n",
    "                  buffer.seek(0)\n",
    "                  time1114=perf_counter()\n",
    "                  #print (f'1114: {(time1114-time000):.1f}s')\n",
    "                  myimage = buffer.getvalue()   \n",
    "                  #encoded=myimage\n",
    "                  if generate&gen_jpeg:\n",
    "                    encoded= \"data:image/jpeg;base64,\"+base64.b64encode(myimage).decode()\n",
    "                  if generate&gen_png:\n",
    "                    encoded= \"data:image/png;base64,\"+base64.b64encode(myimage).decode()\n",
    "                  #print('image encoded')\n",
    "                  js='''displayPhoto1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
    "                if (ji==n_generate-1) :\n",
    "                    time110=perf_counter()\n",
    "                    #print (f'110: {(time110-time000):.1f}s')\n",
    "                    #js_image=js\n",
    "                    #print('>>encodeds.append(encoded)')\n",
    "                    #encodeds.append(encoded)\n",
    "                    #print('<<encodeds.append(encoded)')\n",
    "                    comm.send({\n",
    "                      'response': encoded,\n",
    "                      })#, None, msg['buffers']);\n",
    "                    #print('image sent')\n",
    "                    #break\n",
    "              #print('audio&image send')\n",
    "              #comm.send({\n",
    "              #  'response': 'close',\n",
    "                #'response': json.dumps(encodeds),\n",
    "              #}, None, msg['buffers']);\n",
    "              #break\n",
    " \n",
    "    #if not(js_image==\"\"):\n",
    "    #  js=js_image\n",
    "    #  js_image=\"\"\n",
    "    #  eval_js(js)\n",
    "#      if True:\n",
    "      if False:\n",
    "                    time111=perf_counter()\n",
    "                    print (f'000: {(time111-time000):.1f}s, '+\n",
    "                      f'001: {(time111-time001):.1f}s, '+\n",
    "                      f'110: {(time111-time110):.1f}s, '+\n",
    "                      f'001-000: {(time001-time000):.1f}s, {(time001-time000)*100/(time111-time000):.0f}%, '+\n",
    "                      f'110-001: {(time110-time001):.1f}s, {(time110-time001)*100/(time111-time000):.0f}%. '+\n",
    "                      f'111-110: {(time111-time110):.1f}s, {(time111-time110)*100/(time111-time000):.0f}%')\n",
    " \n",
    "  if False:\n",
    "    comm.send({\n",
    "      'response': 'close',\n",
    "      #'response': json.dumps(encodeds),\n",
    "      }, None, msg['buffers']);\n",
    " \n",
    "# comm.send({'echo': msg['content']['data']})\n",
    " #comm.send({'echo': 'ok'})\n",
    "\n",
    "data_read=False\n",
    "get_ipython().kernel.comm_manager.register_target('comm_target1', target_func1)\n",
    "#target_func1('{1}','{1}')\n",
    "#for i in range(100):\n",
    "#  get_ipython().kernel.comm_manager.register_target(str(i), target_func1)\n",
    " \n",
    "Javascript('''\n",
    "//Joshua Brewster, GPL (copyleft)\n",
    " \n",
    "//import 'regenerator-runtime/runtime' //For async functions on node\\\\\n",
    " \n",
    " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
    " \n",
    "    constructor(\n",
    "        onDecodedCallback = this.onDecodedCallback,\n",
    "        onConnectedCallback = this.onConnectedCallback,\n",
    "        onDisconnectedCallback = this.onDisconnectedCallback,\n",
    "        CustomDecoder = this.decode,\n",
    "        baudrate = 921600//115200\n",
    "        ) {\n",
    " \n",
    "        this.onDecodedCallback = onDecodedCallback;\n",
    "        this.onConnectedCallback = onConnectedCallback;\n",
    "        this.onDisconnectedCallback = onDisconnectedCallback;\n",
    "        this.decode = CustomDecoder;\n",
    "        //Free EEG 32 data structure:\n",
    "        \n",
    "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
    "        //    Total = 105 bytes/line\n",
    "        \n",
    "        this.connected = false;\n",
    "        this.subscribed = false;\n",
    "        this.buffer = [];\n",
    "        this.startByte = 160; // Start byte value\n",
    "        this.stopByte = 192; // Stop byte value\n",
    "        this.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
    "        this.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
    "        this.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
    " \n",
    "        this.sps = 512; // Sample rate\n",
    "        this.nChannels = 32;\n",
    "        this.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
    "        this.updateMs = 1000/this.sps; //even spacing\n",
    "        this.stepSize = 1/Math.pow(2,24);\n",
    "        this.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
    "        this.gain = 8;\n",
    " \n",
    "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
    "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
    "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
    " \n",
    "        this.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
    "        \n",
    "        this.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
    "            count: 0,\n",
    "            startms: 0,\n",
    "            ms: [],\n",
    "            'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
    "            'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
    "            'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
    "            'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
    "            'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
    "        };\n",
    " \n",
    "    this.bufferednewLines = 0;\n",
    "    this.data_slice=[];\n",
    "    this.data_slice_size=512*(5*1/8+0.1);\n",
    "    this.ready_to_send_data = false;\n",
    "    this.data_send_count=0;\n",
    "\n",
    "    this.xsize=%(xsize)d;\n",
    "    this.ysize=%(ysize)d;\n",
    "\n",
    "    this.generate_stylegan2=true;\n",
    "    this.generate_stylegan2=%(generate_stylegan2)d;\n",
    "    \n",
    "    //this.generate_stylegan2=false;\n",
    "    this.generate_wavegan=true;\n",
    "    this.generate_wavegan=%(generate_wavegan)d;\n",
    "    this.generate_heatmap=true;\n",
    "    this.generate_heatmap=%(generate_heatmap)d;\n",
    "    //data:audio/wav;base64,\n",
    "    //data:image/jpeg;base64,\n",
    "    this.time100=Date.now();\n",
    "    this.time000=Date.now();\n",
    "    this.this_frame_wg=-1;\n",
    "    this.last_frame_wg=-1;\n",
    "    this.send_wg=false;\n",
    "    this.this_frame_sg2=-1;\n",
    "    this.last_frame_sg2=-1;\n",
    "    this.send_sg2=false;\n",
    "\n",
    "    this.frame_last=0;\n",
    "\n",
    "    if(this.generate_stylegan2)\n",
    "    {\n",
    "      this.fps_sg2=1;\n",
    "    }\n",
    "    if(this.generate_wavegan)\n",
    "    {\n",
    "      this.hz=44100;\n",
    "      this.fps_wg=this.hz/(32768*2);\n",
    "      //this.fps=this.hz/(32768);\n",
    "    }\n",
    "      this.fps_sg2=this.fps_wg;\n",
    "      this.fps_wg=%(fps_wg)f;\n",
    "      this.fps_sg2=%(fps_sg2)f;\n",
    "      this.fps_hm=%(fps_hm)f;\n",
    "      this.fps=Math.max(this.fps_wg,this.fps_sg2,this.fps_hm)*4;\n",
    "      \n",
    "    this.samples_count=0;\n",
    "    //this.channel=None;\n",
    " \n",
    "        this.resetDataBuffers();\n",
    " \n",
    "        //navigator.serial utils\n",
    "        if(!navigator.serial){\n",
    "            console.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
    "        }\n",
    "        this.port = null;\n",
    "        this.reader = null;\n",
    "        this.baudrate = baudrate;\n",
    " \n",
    "    }\n",
    "    \n",
    "    resetDataBuffers(){\n",
    "        this.data.count = 0;\n",
    "        this.data.startms = 0;\n",
    "        for(const prop in this.data) {\n",
    "            if(typeof this.data[prop] === \"object\"){\n",
    "                this.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
    "            }\n",
    "        }\n",
    "    }\n",
    " \n",
    "    setScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
    "        this.stepSize = stepSize;\n",
    "        this.vref = vref; //2.5V voltage ref +/- 250nV\n",
    "        this.gain = gain;\n",
    " \n",
    "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
    "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
    "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
    "    }\n",
    " \n",
    "    getLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
    "        let ct = count;\n",
    "        if(ct <= 1) {\n",
    "            return [this.data[channel][this.data.count-1]];\n",
    "        }\n",
    "        else {\n",
    "            if(ct > this.data.count) {\n",
    "                ct = this.data.count;\n",
    "            }\n",
    "            return this.data[channel].slice(this.data.count-ct,this.data.count);\n",
    "        }\n",
    "    }\n",
    " \n",
    "    bytesToInt16(x0,x1){\n",
    "        return x0 * 256 + x1;\n",
    "    }\n",
    " \n",
    "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
    "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
    "    }\n",
    " \n",
    "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
    "        return x0 * 65536 + x1 * 256 + x2;\n",
    "    }\n",
    " \n",
    "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
    "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
    "    }\n",
    " \n",
    "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
    " \n",
    "        var needle = this.searchString\n",
    "        var haystack = buffer;\n",
    "        var search = this.boyerMoore(needle);\n",
    "        var skip = search.byteLength;\n",
    "        var indices = [];\n",
    "        let newLines = 0;\n",
    "    \n",
    "        for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
    "            indices.push(i);\n",
    "        }\n",
    "        //console.log(indices);\n",
    "        if(indices.length >= 2){\n",
    "            for(let k = 1; k < indices.length; k++) {\n",
    "                if(indices[k] - indices[k-1] !== 105) {\n",
    "                    \n",
    "                } //This is not a valid sequence going by size, drop sequence and return\n",
    "                else {\n",
    "                    var line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
    "                    \n",
    "                    // line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
    " \n",
    "                    //line found, decode.\n",
    "                    if(this.data.count < this.maxBufferedSamples){\n",
    "                        this.data.count++;\n",
    "                    }\n",
    " \n",
    "                    if(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
    "                    else {\n",
    "                        this.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
    "                        \n",
    "                        if(this.data.count >= this.maxBufferedSamples) {\n",
    "                            this.data.ms.splice(0,5120);\n",
    "                            this.data.ms.push(new Array(5120).fill(0));\n",
    "                        }\n",
    "                    }//Assume no dropped samples\n",
    "                  var sample_count = line[2];\n",
    "                  var sample_count_diff = sample_count-this.samples_count;\n",
    "          if(sample_count_diff<0){\n",
    "            sample_count_diff+=256;\n",
    "          }\n",
    "          if(sample_count_diff!=1)\n",
    "          {\n",
    "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
    "          }\n",
    "          this.samples_count=sample_count;\n",
    " \n",
    "                    for(var i = 3; i < 99; i+=3) {\n",
    "                        var channel = \"A\"+(i-3)/3;\n",
    "                        this.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
    "                        if(this.data.count >= this.maxBufferedSamples) { \n",
    "                            this.data[channel].splice(0,5120);\n",
    "                            this.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
    "                        }\n",
    "                            //console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
    "                    }\n",
    " \n",
    "                    this.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
    "                    this.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
    "                    this.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
    " \n",
    "                    \n",
    "                    if(this.data.count >= this.maxBufferedSamples) { \n",
    "                        this.data[\"Ax\"].splice(0,5120);\n",
    "                        this.data[\"Ay\"].splice(0,5120);\n",
    "                        this.data[\"Az\"].splice(0,5120);\n",
    "                        this.data[\"Ax\"].push(new Array(5120).fill(0))\n",
    "                        this.data[\"Ay\"].push(new Array(5120).fill(0))\n",
    "                        this.data[\"Az\"].push(new Array(5120).fill(0))\n",
    "                        this.data.count -= 5120;\n",
    "                    }\n",
    "                    //console.log(this.data)\n",
    "                    newLines++;\n",
    "                    //console.log(indices[k-1],indices[k])\n",
    "                    //console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
    "                    //indices.shift();\n",
    "                }\n",
    "                \n",
    "            }\n",
    "            if(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
    "   \n",
    "            return newLines;\n",
    "            //Continue\n",
    "        }\n",
    "        //else {this.buffer = []; return false;}\n",
    "    }\n",
    "    //Callbacks\n",
    "    onDecodedCallback(newLinesInt){\n",
    "        //console.log(\"new samples:\", newLinesInt);\n",
    "        this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
    "    }\n",
    " \n",
    "    onConnectedCallback() {\n",
    "        console.log(\"port connected!\");\n",
    "    }\n",
    " \n",
    "    onDisconnectedCallback() {\n",
    "        console.log(\"port disconnected!\");\n",
    "    }\n",
    " \n",
    "    onReceive(value){\n",
    "        this.buffer.push(...value);\n",
    " \n",
    "        let newLines = this.decode(this.buffer);\n",
    "        //console.log(this.data)\n",
    "        //console.log(\"decoding... \", this.buffer.length)\n",
    "        if(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
    "    }\n",
    " \n",
    "    async onPortSelected(port,baud=this.baudrate) {\n",
    "        try{\n",
    "            try {\n",
    "                await port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
    "                this.onConnectedCallback();\n",
    "                this.connected = true;\n",
    "                this.subscribed = true;\n",
    "                this.subscribe(port);//this.subscribeSafe(port);\n",
    "        \n",
    "            } //API inconsistency in syntax between linux and windows\n",
    "            catch {\n",
    "                await port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
    "                this.onConnectedCallback();\n",
    "                this.connected = true;\n",
    "                this.subscribed = true;\n",
    "                this.subscribe(port);//this.subscribeSafe(port);\n",
    "            }\n",
    "        }\n",
    "        catch(err){\n",
    "            console.log(err);\n",
    "            this.connected = false;\n",
    "        }\n",
    "    }\n",
    " \n",
    "    async subscribe(port){\n",
    "        if (this.port.readable && this.subscribed === true) {\n",
    "            this.reader = port.readable.getReader();\n",
    "            const streamData = async () => {\n",
    "                try {\n",
    "                    const { value, done } = await this.reader.read();\n",
    "                    if (done || this.subscribed === false) {\n",
    "                        // Allow the serial port to be closed later.\n",
    "                        await this.reader.releaseLock();\n",
    "                        \n",
    "                    }\n",
    "                    if (value) {\n",
    "                        //console.log(value.length);\n",
    "                        try{\n",
    "                            this.onReceive(value);\n",
    "                        }\n",
    "                        catch (err) {console.log(err)}\n",
    "                        //console.log(\"new Read\");\n",
    "                        //console.log(this.decoder.decode(value));\n",
    "                    }\n",
    "                    if(this.subscribed === true) {\n",
    "                        setTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
    "                    }\n",
    "                } catch (error) {\n",
    "                    console.log(error);// TODO: Handle non-fatal read error.\n",
    "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
    "                        this.subscribed = false;\n",
    "                        setTimeout(async ()=>{\n",
    "                            try{\n",
    "                            if (this.reader) {\n",
    "                                await this.reader.releaseLock();\n",
    "                                this.reader = null;\n",
    "                            }\n",
    "                            } catch (er){ console.error(er);}\n",
    "                            this.subscribed = true; \n",
    "                            this.subscribe(port);\n",
    "                            //if that fails then close port and reopen it\n",
    "                        },30); //try to resubscribe \n",
    "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
    "                        if(this.port){\n",
    "                            this.subscribed = false;\n",
    "                            setTimeout(async () => {\n",
    "                                try{\n",
    "                                if (this.reader) {\n",
    "                                    await this.reader.releaseLock();\n",
    "                                    this.reader = null;\n",
    "                                }\n",
    "                                await port.close();\n",
    "                                } catch (er){ console.error(er);}\n",
    "                                //this.port = null;\n",
    "                                this.connected = false;\n",
    "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
    "                            }, 50);\n",
    "                        }\n",
    "                    }\n",
    "                     else {\n",
    "                        this.closePort();   \n",
    "                    }   \n",
    "                }\n",
    "            }\n",
    "            streamData();\n",
    "        }\n",
    "    }\n",
    " \n",
    "    //Unfinished\n",
    "    async subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
    "        var readable = new Promise((resolve,reject) => {\n",
    "            while(this.port.readable && this.subscribed === true){\n",
    "                this.reader = port.readable.getReader();\n",
    "                var looper = true;\n",
    "                var prom1 = new Promise((resolve,reject) => {\n",
    "                    return this.reader.read();\n",
    "                });\n",
    " \n",
    "                var prom2 = new Promise((resolve,reject) => {\n",
    "                    setTimeout(resolve,100,\"readfail\");\n",
    "                });\n",
    "                while(looper === true ) {\n",
    "                    //console.log(\"reading...\");\n",
    "                    Promise.race([prom1,prom2]).then((result) => {\n",
    "                        console.log(\"newpromise\")\n",
    "                        if(result === \"readfail\"){\n",
    "                            console.log(result);\n",
    "                        }\n",
    "                        else{\n",
    "                            const {value, done} = result;\n",
    "                            if(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
    "                                resolve(this.reader.releaseLock())}).then(() => {\n",
    "                                    looper = false;\n",
    "                                    return;\n",
    "                                });\n",
    "                            }\n",
    "                            else{\n",
    "                                this.onReceive(value);\n",
    "                            }\n",
    "                        }\n",
    "                    });\n",
    "                }\n",
    "            }\n",
    "            resolve(\"not readable\");\n",
    "        });\n",
    "    }\n",
    " \n",
    "    async closePort(port=this.port) {\n",
    "        //if(this.reader) {this.reader.releaseLock();}\n",
    "        if(this.port){\n",
    "            this.subscribed = false;\n",
    "            setTimeout(async () => {\n",
    "                if (this.reader) {\n",
    "                    await this.reader.releaseLock();\n",
    "                    this.reader = null;\n",
    "                }\n",
    "                await port.close();\n",
    "                this.port = null;\n",
    "                this.connected = false;\n",
    "                this.onDisconnectedCallback();\n",
    "            }, 100);\n",
    "        }\n",
    "    }\n",
    " \n",
    "    async setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
    " \n",
    "        const filters = [\n",
    "            { usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
    "        ];\n",
    " \n",
    "        this.port = await navigator.serial.requestPort();\n",
    "        navigator.serial.addEventListener(\"disconnect\",(e) => {\n",
    "            this.closePort(this.port);\n",
    "        });\n",
    "        this.onPortSelected(this.port,baudrate);\n",
    " \n",
    "        //navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
    " \n",
    "    }\n",
    " \n",
    " \n",
    "    //Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
    "    asUint8Array(input) {\n",
    "        if (input instanceof Uint8Array) {\n",
    "            return input;\n",
    "        } else if (typeof(input) === 'string') {\n",
    "            // This naive transform only supports ASCII patterns. UTF-8 support\n",
    "            // not necessary for the intended use case here.\n",
    "            var arr = new Uint8Array(input.length);\n",
    "            for (var i = 0; i < input.length; i++) {\n",
    "            var c = input.charCodeAt(i);\n",
    "            if (c > 127) {\n",
    "                throw new TypeError(\"Only ASCII patterns are supported\");\n",
    "            }\n",
    "            arr[i] = c;\n",
    "            }\n",
    "            return arr;\n",
    "        } else {\n",
    "            // Assume that it's already something that can be coerced.\n",
    "            return new Uint8Array(input);\n",
    "        }\n",
    "    }\n",
    " \n",
    "    boyerMoore(patternBuffer) {\n",
    "        // Implementation of Boyer-Moore substring search ported from page 772 of\n",
    "        // Algorithms Fourth Edition (Sedgewick, Wayne)\n",
    "        // http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
    "        \n",
    "//      USAGE:\n",
    "            // needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
    "            // haystack should be an ArrayBuffer or Uint8Array\n",
    "//          var search = boyerMoore(needle);\n",
    "//          var skip = search.byteLength;\n",
    "//          var indices = [];\n",
    "//          for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
    "//              indices.push(i);\n",
    "//          }\n",
    "        \n",
    "        var pattern = this.asUint8Array(patternBuffer);\n",
    "        var M = pattern.length;\n",
    "        if (M === 0) {\n",
    "            throw new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
    "        }\n",
    "        // radix\n",
    "        var R = 256;\n",
    "        var rightmost_positions = new Int32Array(R);\n",
    "        // position of the rightmost occurrence of the byte c in the pattern\n",
    "        for (var c = 0; c < R; c++) {\n",
    "            // -1 for bytes not in pattern\n",
    "            rightmost_positions[c] = -1;\n",
    "        }\n",
    "        for (var j = 0; j < M; j++) {\n",
    "            // rightmost position for bytes in pattern\n",
    "            rightmost_positions[pattern[j]] = j;\n",
    "        }\n",
    "        var boyerMooreSearch = (txtBuffer, start, end) => {\n",
    "            // Return offset of first match, -1 if no match.\n",
    "            var txt = this.asUint8Array(txtBuffer);\n",
    "            if (start === undefined) start = 0;\n",
    "            if (end === undefined) end = txt.length;\n",
    "            var pat = pattern;\n",
    "            var right = rightmost_positions;\n",
    "            var lastIndex = end - pat.length;\n",
    "            var lastPatIndex = pat.length - 1;\n",
    "            var skip;\n",
    "            for (var i = start; i <= lastIndex; i += skip) {\n",
    "                skip = 0;\n",
    "                for (var j = lastPatIndex; j >= 0; j--) {\n",
    "                var c = txt[i + j];\n",
    "                if (pat[j] !== c) {\n",
    "                    skip = Math.max(1, j - right[c]);\n",
    "                    break;\n",
    "                }\n",
    "                }\n",
    "                if (skip === 0) {\n",
    "                return i;\n",
    "                }\n",
    "            }\n",
    "            return -1;\n",
    "        };\n",
    "        boyerMooreSearch.byteLength = pattern.byteLength;\n",
    "        return boyerMooreSearch;\n",
    "    }\n",
    "    //---------------------end copy/pasted solution------------------------\n",
    " \n",
    "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
    "        //this.lastnewLines=this.bufferednewLines;\n",
    "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
    "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
    "     {\n",
    "      //this.ready_to_send_data = false;\n",
    "      this.data_slice = [\n",
    "        //this.data.ms.slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
    "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
    "        ];\n",
    "  this.bufferednewLines=0;\n",
    "  //const buffer = new Uint8Array(10);\n",
    "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
    "  //  buffer[i] = i\n",
    "  //}\n",
    "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
    "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
    "  this.data_send_count++;\n",
    "  //if(this.channel==None)\n",
    "  //{\n",
    "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
    "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
    "  //} else \n",
    "  //{\n",
    "    //this.channel.send(this.data_send_count.toString())\n",
    "  //}\n",
    "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
    "\n",
    "//const comm = Jupyter.notebook.kernel.comm_manager.new_comm('my_comm_target', {'foo': 6})\n",
    "// Send data\n",
    "//comm.send({'foo': 7})\n",
    "\n",
    "// Register a handler\n",
    "//comm.on_msg(function(msg) {\n",
    "//    console.log(msg.content.data.foo);\n",
    "//});\n",
    "\n",
    "//  const comm = Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', {'foo': 6});\n",
    "  const comm = Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', array_to_send_as_json);\n",
    "//  const channel = await Jupyter.notebook.kernel.comm_manager.new_comm('comm_target1', array_to_send_as_json, []);\n",
    "\n",
    "//console.log('9');\n",
    "//comm.send({'foo': 7})\n",
    "//console.log(comm);\n",
    "//comm.send(array_to_send_as_json)\n",
    "//comm.on_msg(function(msg) {\n",
    "//    console.log(msg);\n",
    "//});\n",
    "\n",
    "//  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
    "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
    "  let success = false;\n",
    "  //for await (const message of channel.messages) \n",
    "//  if(0)\n",
    " comm.on_msg(function(message) \n",
    " {\n",
    "  {\n",
    "    if (message.content.data.response == 'close') {\n",
    "    //if (message.data.response == 'got comm open!') {\n",
    "      //const responseBuffer = new Uint8Array(message.buffers[0]);\n",
    "      //for (let i = 0; i < buffer.length; ++i) {\n",
    "      //  if (responseBuffer[i] != buffer[i]) {\n",
    "      //    console.error('comm buffer different at ' + i);\n",
    "      //    document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
    "      //    return;\n",
    "      //  }\n",
    "      //}\n",
    "      // Close the channel once the expected message is received. This should\n",
    "      // cause the messages iterator to complete and for the for-await loop to\n",
    "      // end.\n",
    "      //console.error('comm buffer same ' + responseBuffer);\n",
    "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
    "      ////channel.close();\n",
    "    }\n",
    "    //console.log('audio&image received');\n",
    "    //var message_parsed=JSON.parse(message.data.response);\n",
    "    //console.log('audio&image decoded');\n",
    "    //for(let i = 0; i < message_parsed.length; ++i)\n",
    "    {\n",
    "      \n",
    "      if (generate_wavegan)\n",
    "      {\n",
    "        //if((typeof message_parsed[i]) === 'string')\n",
    "        {\n",
    "          if(message.content.data.response.startsWith('data:audio'))\n",
    "          //if(message_parsed[i].startsWith('data:audio'))\n",
    "          {\n",
    "            //document.body.appendChild(document.createTextNode('audio decoded'));\n",
    "            //await \n",
    "            //playAudio1(message_parsed[i]);\n",
    "            //await \n",
    "            playAudio1(message.content.data.response);\n",
    "            time000=Date.now();\n",
    "            var frame_time=parseInt((1000/fps_wg));\n",
    "            var next_time=frame_time-((time000-time100)%%frame_time);\n",
    "            setTimeout(playAudio2,next_time);\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "      if (generate_stylegan2)\n",
    "      {\n",
    "        //if((typeof message_parsed[i]) === 'string')\n",
    "        {\n",
    "          //console.log(\"image string\");\n",
    "          if(message.content.data.response.startsWith('data:image'))\n",
    "          //if(message_parsed[i].startsWith('data:image'))\n",
    "          {\n",
    "            //document.body.appendChild(document.createTextNode('image decoded'));\n",
    "            //await \n",
    "            //displayPhoto1(message_parsed[i]);\n",
    "            //await \n",
    "            displayPhoto1(message.content.data.response,xsize,ysize);\n",
    "            time000=Date.now();\n",
    "            var frame_time=parseInt((1000/fps_sg2));\n",
    "            var next_time=frame_time-((time000-time100)%%frame_time);\n",
    "            setTimeout(displayPhoto4,next_time);\n",
    "            var frame_now=(time000-time100)/frame_time;\n",
    "            if(Math.round(frame_now-frame_last)!=1)\n",
    "            {\n",
    "              console.log('f2:'+next_time+','+frame_time+','+\n",
    "                frame_now+','+frame_last+','+\n",
    "                (frame_now-frame_last));\n",
    "            }\n",
    "            frame_last=frame_now;\n",
    "          }\n",
    "        }\n",
    "        //else\n",
    "        {\n",
    "          //console.log(\"image not string\");\n",
    "          //displayPhoto3(message_parsed[i]);\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    " });\n",
    "      this.ready_to_send_data = true;\n",
    "  //document.body.appendChild(document.createTextNode('done2.'));\n",
    "     } \n",
    " \n",
    "    }\n",
    " \n",
    "}\n",
    " \n",
    "var device = new eeg32();\n",
    "\n",
    "var generate_wavegan=device.generate_wavegan;\n",
    "var generate_stylegan2=device.generate_stylegan2;\n",
    "var xsize=device.xsize;\n",
    "var ysize=device.ysize;\n",
    "var time000=device.time000;\n",
    "var fps_wg=device.fps_wg;\n",
    "var fps_sg2=device.fps_sg2;\n",
    "var time100=device.time100;\n",
    "var frame_last=device.frame_last;\n",
    " \n",
    "    var connect = async () => {\n",
    "        await this.device.setupSerialAsync();\n",
    "    }\n",
    " \n",
    "    var disconnect = () => {\n",
    "        if (this.ui) this.ui.deleteNode()\n",
    "        this.device.closePort();\n",
    "    }\n",
    " \n",
    " \n",
    "        //const canvas = document.createElement('canvas');\n",
    "      //const audio = document.createElement('audio');\n",
    "      //const audio1 = document.createElement('audio');\n",
    "      //const audio2 = document.createElement('audio');\n",
    "      var audios = new Array();\n",
    "      if(device.generate_wavegan)\n",
    "      {\n",
    "        const audios_length = 5;\n",
    "        for(let i = 0; i < audios_length; i++)\n",
    "        {\n",
    "          audios[i]=document.createElement('audio');\n",
    "        }\n",
    "      }\n",
    " \n",
    "          //var ctx = canvas.getContext(\"2d\");\n",
    " \n",
    "      var images = new Array();\n",
    "      var canvases = new Array();\n",
    "      if(device.generate_stylegan2)\n",
    "      {\n",
    "        const images_length = 1;\n",
    "        const canvases_length = images_length;\n",
    "        for(let i = 0; i < images_length; i++)\n",
    "        {\n",
    "          //images[i]=document.createElement('image');\n",
    "          canvases[i]=document.createElement('canvas');\n",
    "          var ctx = canvases[i].getContext(\"2d\");\n",
    "          images[i]=new Image();\n",
    "          //images[i].onload = function() {\n",
    "          //  ctx.drawImage(images[i], 0, 0);\n",
    "          //};\n",
    "        }\n",
    "      }\n",
    "      //var image = new Image();\n",
    "      //image.onload = function() {\n",
    "      //  ctx.drawImage(image, 0, 0);\n",
    "      //};\n",
    "const div = document.createElement('div');\n",
    "const div2 = document.createElement('div');\n",
    "const div3 = document.createElement('div');\n",
    "const btnconnect = document.createElement('button');\n",
    "const btndisconnect = document.createElement('button');\n",
    "const capture = document.createElement('button');\n",
    "                  \n",
    "    async function takePhoto2(quality=1) {\n",
    "      btnconnect.remove();\n",
    "      capture.remove();\n",
    "      device.ready_to_send_data = true;\n",
    "    }\n",
    " \n",
    "    async function takePhoto(quality=1) {\n",
    " \n",
    "      btnconnect.textContent = 'connect';\n",
    "      div.appendChild(btnconnect);\n",
    "      btnconnect.onclick = async () => {\n",
    "        await device.setupSerialAsync();\n",
    "    };\n",
    "//      btnconnect.onclick = this.connect;\n",
    "      \n",
    "      btndisconnect.textContent = 'disconnect';\n",
    "      div.appendChild(btndisconnect);\n",
    "      btndisconnect.onclick = async () => {\n",
    "        //if (this.ui) this.ui.deleteNode()\n",
    "        device.closePort();\n",
    "    };\n",
    "//      btndisconnect.onclick = this.disconnect;\n",
    "      \n",
    "      capture.textContent = 'Capture';\n",
    "      capture.onclick = takePhoto2;\n",
    "      div.appendChild(capture);\n",
    "     \n",
    "      //div.appendChild(canvas);\n",
    "      //div.appendChild(audio);\n",
    "      //div.appendChild(audio1);\n",
    "      //div.appendChild(audio2);\n",
    "      if(device.generate_wavegan)\n",
    "      {\n",
    "        for(let i = 0; i < audios.length; i++)\n",
    "        {\n",
    "          div2.appendChild(audios[i]);\n",
    "          //audios[i].controls = true;\n",
    "          //audios[i].autoplay = true;\n",
    "        }\n",
    "      }\n",
    "      if(device.generate_stylegan2)\n",
    "      {\n",
    "        for(let i = 0; i <canvases.length; i++)\n",
    "        {\n",
    "          div3.appendChild(canvases[i]);\n",
    "        }\n",
    "      }\n",
    "      //for(let i = 0; i < images.length; i++)\n",
    "      //{\n",
    "      //  div.appendChild(images[i]);\n",
    "      //}\n",
    " \n",
    "      document.querySelector(\"#buttons\").appendChild(div);\n",
    "      document.querySelector(\"#buttons\").appendChild(div2);\n",
    "      document.querySelector(\"#buttons\").appendChild(div3);\n",
    "//      document.body.appendChild(div);\n",
    "//      document.body.appendChild(div2);\n",
    "//      document.body.appendChild(div3);\n",
    "         await new Promise((resolve) => capture.onclick = resolve);\n",
    " \n",
    "      btnconnect.remove();\n",
    "      capture.remove();\n",
    "      device.ready_to_send_data = true;\n",
    "    }\n",
    " \n",
    "    async function takePhoto1(quality=1) {  \n",
    "      //var data_slice_send=this.device.data_slice;\n",
    "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
    "      //var data_slice_send=[this.device.data_slice[0]];\n",
    "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
    "        //console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
    "        //console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
    "      device.bufferednewLines=0;\n",
    "      return data_slice_send;      \n",
    "    }\n",
    " \n",
    "    async function displayPhoto1(photodata,photoWidth=512,photoHeight=512) {\n",
    "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
    "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
    "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
    "    }\n",
    "    var image_now=0;\n",
    "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
    "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
    "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
    "     //image.src = photodata;\n",
    "      {\n",
    "       if(canvases[image_now%%images.length].width != photoWidth)\n",
    "       {\n",
    "         canvases[image_now%%images.length].width = photoWidth;\n",
    "       }\n",
    "       if(canvases[image_now%%images.length].height != photoHeight) \n",
    "       {\n",
    "         canvases[image_now%%images.length].height = photoHeight;\n",
    "       }\n",
    "       images[image_now%%images.length].src = photodata;\n",
    "        //audios[audio_now%%audios.length].play();\n",
    "      }\n",
    "      //image_now++;\n",
    "    }\n",
    "    async function displayPhoto4(photodata){//},photoWidth,photoHeight) {\n",
    "      ctx.drawImage(images[image_now%%images.length], 0, 0);\n",
    "      image_now++;\n",
    "    }\n",
    "    var img_step=0;\n",
    "    async function displayPhoto3(photodata,photoWidth=512,photoHeight=512) {\n",
    "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
    "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
    "      fs.writeFile('img0.jpg', photodata, function (err) {\n",
    "        // console.log(\"save img!\" );\n",
    "      });\n",
    "      var photofile='img0.jpg?'+img_step;\n",
    "      img_step+=1;\n",
    "      //console.log(\"save img!\" );\n",
    "      await displayPhoto2(photofile,photoWidth,photoHeight);\n",
    "    }\n",
    " \n",
    "    var audio_now=0;\n",
    "    async function playAudio1(audiodata){//},photoWidth=512,photoHeight=512) {\n",
    "      //const canvas = document.createElement('canvas');\n",
    "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
    "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
    "      //audio.controls = true;\n",
    "      //audio.autoplay = true;\n",
    "      //audio1.controls = true;\n",
    "      //audio1.autoplay = true;\n",
    "      //audio2.controls = true;\n",
    "      //audio2.autoplay = true;\n",
    " \n",
    "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
    "      //var canvas = document.getElementById(\"c\");\n",
    "      ///var ctx = canvas.getContext(\"2d\");\n",
    " \n",
    "      ///var image = new Image();\n",
    "      ///image.onload = function() {\n",
    "      ///  ctx.drawImage(image, 0, 0);\n",
    "      ///};\n",
    "      //audio.src = audiodata;\n",
    "      //audio.play()\n",
    "      //if(audio_now%%2==0)\n",
    "      //{\n",
    "      //  audio1.src = audiodata;\n",
    "      //  audio1.play()\n",
    "      //}\n",
    "      //else\n",
    "      //{\n",
    "      //  audio2.src = audiodata;\n",
    "      //  audio2.play()\n",
    "      //}\n",
    "      //for(let i = 0; i < audios.length; ++i)\n",
    "      {\n",
    "        audios[audio_now%%audios.length].src = audiodata;\n",
    "        //if(audio_now==0)\n",
    "        {\n",
    "          audios[audio_now%%audios.length].controls = true;\n",
    "          //audios[audio_now%%audios.length].autoplay = true;\n",
    "        }\n",
    "        //audios[audio_now%%audios.length].play();\n",
    "      }\n",
    "      //audio_now++;\n",
    " \n",
    "    }\n",
    "    async function playAudio2(audiodata){//},photoWidth=512,photoHeight=512) {\n",
    "      audios[audio_now%%audios.length].play();\n",
    "      audio_now++;\n",
    "    }\n",
    "    \n",
    "  takePhoto();\n",
    "  var data_count=0;\n",
    "  var frame_last=0;\n",
    "\n",
    "async function check_to_send() {\n",
    "  //while(true)\n",
    "  {\n",
    "   if(device.bufferednewLines)\n",
    "   {\n",
    "    //if(this.bufferednewLines>this.data_slice_size)\n",
    "    //  {\n",
    "    //    this.bufferednewLines=this.data_slice_size;\n",
    "    //  }\n",
    "    /*device.time000=Date.now();\n",
    "    if(device.generate_wavegan)\n",
    "    {\n",
    "      device.this_frame_wg=parseInt((device.time000-device.time100)*device.fps_wg);\n",
    "      if(device.this_frame_wg>device.last_frame_wg)\n",
    "      {\n",
    "        device.last_frame_wg=device.this_frame_wg;\n",
    "        device.send_wg=true;\n",
    "      }\n",
    "    }\n",
    "    if(device.generate_stylegan2)\n",
    "    {\n",
    "      device.this_frame_sg2=parseInt((device.time000-device.time100)*device.fps_sg2);\n",
    "      if(device.this_frame_sg2>device.last_frame_sg2)\n",
    "      {\n",
    "        device.last_frame_sg2=device.this_frame_sg2;\n",
    "        device.send_sg2=true;\n",
    "      }\n",
    "    }\n",
    "    if(device.send_wg || device.send_sg2)\n",
    "    //if(this.bufferednewLines>512/(this.fps_sg2))\n",
    "    if(device.ready_to_send_data)*/\n",
    "    {\n",
    "      //this.bufferednewLines=512/this.fps;\n",
    " \n",
    "        device.takeandsendSlice(device.data.count-1-device.bufferednewLines,device.data.count-1);\n",
    "      device.send_wg=false;\n",
    "      device.send_sg2=false;\n",
    "    }\n",
    "        //console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
    "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
    "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
    "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
    "   }\n",
    "  }\n",
    "  device.time000=Date.now();\n",
    "//  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
    "  var frame_time=parseInt((1000/device.fps));\n",
    "  var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
    "  setTimeout(check_to_send,next_time);\n",
    "  var frame_now=(device.time000-device.time100)/frame_time;\n",
    "  if(Math.round(frame_now-frame_last)!=1)\n",
    "  {\n",
    "    console.log('f1:'+next_time+','+frame_time+','+frame_now+','+\n",
    "      frame_last+','+(frame_now-frame_last));\n",
    "  }\n",
    "  frame_last=frame_now;\n",
    "}\n",
    "  device.time000=Date.now();\n",
    "  var frame_time=parseInt((1000/device.fps));\n",
    "  var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
    "  setTimeout(check_to_send,next_time);\n",
    "  //console.log(next_time);\n",
    "//var intervalID = setInterval(check_to_send,(1000/device.fps_wg)/10);\n",
    "//  window.requestAnimationFrame\n",
    " \n",
    "''' % {'xsize':xsize,'ysize':ysize,'generate_stylegan2':generate&gen_stylegan2,'generate_wavegan':generate&gen_wavegan,'generate_heatmap':generate&gen_heatmap,\n",
    "       'fps_sg2':fps_sg2,'fps_wg':fps_wg,'fps_hm':fps_hm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "id": "FLhd7pdGj-PY",
    "outputId": "cc55b1ef-bceb-4861-eb35-b3173261cfc9",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mstop\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter labextension list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter labextension install @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbextension disable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter labextension enable @jupyter-widgets/jupyterlab-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "HmniZp04t7io",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (8.1.3)\r\n",
      "Requirement already satisfied: requests in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (2.28.1)\r\n",
      "Requirement already satisfied: tqdm in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (4.64.0)\r\n",
      "Requirement already satisfied: pyspng in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.1.0)\r\n",
      "Requirement already satisfied: ninja in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (1.10.2.3)\r\n",
      "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (0.4.3)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (3.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (2022.6.15)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from requests) (1.26.12)\r\n",
      "Requirement already satisfied: numpy in /mnt/6b052ea3-d4af-4897-a048-fe540f13d756/content/env/lib/python3.9/site-packages (from pyspng) (1.23.2)\r\n"
     ]
    }
   ],
   "source": [
    "sg2_models=0\n",
    "sg2_ext_models=0\n",
    "sg3_models=0\n",
    "#sg3_models=16\n",
    "\n",
    "if generate&gen_sg3_models:\n",
    "  files_path = [['1yZCo8Zc0B5Lo-WXQ9Pg6OUdYTBM8D-xa', '/content/sg3-model/', 'stylegan3-anime-Expl0dingCat-011100', '.pkl', 'sg3_model'],\n",
    "#if generate&gen_sg3_models:\n",
    "#  files_path = [['1UP200H32RIvVYA_9TduGqIbvqfsFjpkg', '/content/sg3-model/', 'stylegan3-anime-faces-generator_akiyamasho', '.pkl', 'sg3_model'],\n",
    "                ['1aMsP1juT3DzZpbEhcNWO_gJVw9lt7Ant', '/content/sg3-model/', 'stylegan3-r-afhqv2-512x512', '.pkl', 'sg3_model'],\n",
    "                ['1Buunx_0kHIWdNWqRq6CBG0ILlAlcPVOb', '/content/sg3-model/', 'stylegan3-r-ffhq-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1YiCvVqosdRwta3qwMQHNAzuSRGKnSRp1', '/content/sg3-model/', 'stylegan3-r-ffhqu-256x256', '.pkl', 'sg3_model'],\n",
    "                ['1z42DkzZUFhMpuWFHtMNvD6GApcL1lwG7', '/content/sg3-model/', 'stylegan3-r-ffhqu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1BOln2JzcatBT6LTqbsdmrwVb8GJzvhNa', '/content/sg3-model/', 'stylegan3-r-metfaces-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1lh8nIxnX-xmBuu1QQokfFPBvZQPXEo0e', '/content/sg3-model/', 'stylegan3-r-metfacesu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['18ZAuZj9fWwbHx07RB8COJsepnOYtyHli', '/content/sg3-model/', 'stylegan3-t-afhqv2-512x512', '.pkl', 'sg3_model'],\n",
    "                ['14OyRIEfpvhKkHooMpCKnzM3cDkOTXr6p', '/content/sg3-model/', 'stylegan3-t-ffhq-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1Yb5Cvf2DQ57-hX37gc4dq_Mo2UFMetnw', '/content/sg3-model/', 'stylegan3-t-ffhqu-256x256', '.pkl', 'sg3_model'],\n",
    "                ['1XwObqI_egXDiKXoEaCn83utVEzM7Miln', '/content/sg3-model/', 'stylegan3-t-ffhqu-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['1DH6C87Xr5wSG5mPZ8Y9GZgymsgBMTzMP', '/content/sg3-model/', 'stylegan3-t-metfaces-1024x1024', '.pkl', 'sg3_model'],\n",
    "                ['11Mn6U-mcJulhSzUetwX1Q03h7EXrZxS_', '/content/sg3-model/', 'stylegan3-t-metfacesu-1024x1024', '.pkl', 'sg3_model'],\n",
    "         #       ['14kT780a1MmSLDdmNVEOfZpx2aRGpkRLO', '/content/sg3-model/', 'sg3_cosplayface-snapshot-stylegan3t-008000', '.pkl', 'sg3_model'],\n",
    "                ['1Ncs7wUsbfSEPJCcxiTLDOYjLT6UY9wT2', '/content/sg3-model/', 'sg3_alien-sunglases-256_network-snapshot-000074', '.pkl', 'sg3_model'],\n",
    "                ['1CtKjqv7Te5X3L0KuZLIbzi7fbmpLakYS', '/content/sg3-model/', 'sg3_Benches-512_network-snapshot-011000', '.pkl', 'sg3_model'],\n",
    "                ['15LkW8nCsVRrzjjYTVGlUJSnfGDi1RwyI', '/content/sg3-model/', 'sg3_flowers-256_network-snapshot-000069', '.pkl', 'sg3_model'],\n",
    "                ['1RcmJNbWy9As2OMVGiVhMFM0qUKCYB1IK', '/content/sg3-model/', 'sg3_Landscapes_lhq-256-stylegan3-t-25Mimg', '.pkl', 'sg3_model'],\n",
    "                ['1iO_T0MvNw59MPAueoqUHKzpoh40vyLrZ', '/content/sg3-model/', 'sg3_mechanical-devices-from-the-future-256_network-snapshot-000029', '.pkl', 'sg3_model'],\n",
    "                ['1mMZSFynUd_6AIuC8PkDWdeHWY4VyIqYm', '/content/sg3-model/', 'sg3_scifi-city-256_network-snapshot-000210', '.pkl', 'sg3_model'],\n",
    "                ['14DpmYfsX3K9JhkS0BV5YtgZ71wJOInsd', '/content/sg3-model/', 'sg3_scifi-spaceship-256_network-snapshot-000162', '.pkl', 'sg3_model'],\n",
    "                ['13Q5bDnng7VfqYq6g-t8jVybR-E_Df_q3', '/content/sg3-model/', 'sg3_wikiart-1024-stylegan3-t-17.2Mimg', '.pkl', 'sg3_model'],\n",
    "                ['10Q6npsBKdRWMb0LxZUzN6FBSNeB4KTA6', '/content/sg3-model/', 'sg3_yellow-alien-512_network-snapshot-000236', '.pkl', 'sg3_model'],\n",
    "                ['10l7ADbHmZgjSrrpNzOD8r5grJqwxfRd3', '/content/sg3-model/', 'stylegan3_sneaksnap', '.pkl', 'sg3_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg3_models][0], dest_path=files_path[sg3_models][1]+files_path[sg3_models][2]+files_path[sg3_models][3])\n",
    "  files_path[0][1]=files_path[sg3_models][1]+files_path[sg3_models][2]+files_path[sg3_models][3]\n",
    "\n",
    "if generate&gen_sg2_ext_models:\n",
    "  files_path = [['15Ht8LCHRKtGU18ogmcDH6W37v4SrqGug', '/content/sg2-ext-model/', 'sg2-ext-cosplay-faces-512x512-px_cosplayface-snapshot-004000-18160-FID367', '.pkl', 'sg2_ext_model'],\n",
    "                ['1pOYc3O1YdlOpHYnA9LLhti4isOz1vrPl', '/content/sg2-ext-model/', 'sg2-ext-cosplay-faces-512x512-px_cosplayface-snapshot-001360-19520-FID359', '.pkl', 'sg2_ext_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_ext_models][0], dest_path=files_path[sg2_ext_models][1]+files_path[sg2_ext_models][2]+files_path[sg2_ext_models][3])\n",
    "  files_path[0][1]=files_path[sg2_ext_models][1]+files_path[sg2_ext_models][2]+files_path[sg2_ext_models][3]\n",
    "\n",
    "if generate&gen_pytorch:\n",
    " if generate&gen_sg2_models:\n",
    "  files_path = [['1h8zxPcVrSqsgaY6XZS8-ciIAyYoJBM6t', '/content/sg2-model/', 'sg2_GANscapes', '.pkl', 'sg2_model'],\n",
    "                ['1yruyUn4IdykQmdaOT5Nm9Na18N4UtHDQ', '/content/sg2-model/', 'sg2_minecraft-gan-2020-12-22', '.pkl', 'sg2_model'],\n",
    "                ['1aD0cgxnP_C1MSBKkZm1PvGXZLbKGg_hk', '/content/sg2-model/', 'sg2_modern-art_network-snapshot-026392', '.pkl', 'sg2_model'],\n",
    "                ['1ZufizRwpPk21CxK7FBUiGy_cCfSWEyo_', '/content/sg2-model/', 'sg2_network-snapshot-sneakGAN-0000144', '.pkl', 'sg2_model'],\n",
    "                ['1MRPhvrUrCJBoGj4H139bD3Mw2aVYHygs', '/content/sg2-model/', 'sg2_painting-faces_network-snapshot-metfaces2', '.pkl', 'sg2_model'],\n",
    "                ['1Zb5m_ZGMtd4ozz1uiiNI7lpYc-J4G89B', '/content/sg2-model/', 'sg2_textures', '.pkl', 'sg2_model'],\n",
    "                ['1Jb8UqqoAwTtjIx0bTci21EgSsCPHYtWW', '/content/sg2-model/', 'sg2_trypophobia', '.pkl', 'sg2_model'],\n",
    "                ['1_6IrHv971aTBqiI1OcsCriPSaKJah9WI', '/content/sg2-model/', 'sg2_wildlife_network-snapshot-027750', '.pkl', 'sg2_model'],\n",
    "                ['1ZstIAlDdoZcoIoqR9KVYoS0mbDq14gFV', '/content/sg2-model/', 'StyleGAN2_microscopev1', '.pkl', 'sg2_model'],\n",
    "                ['1vq1zasHT1PJS6l7-IBK7NU2SRWUc3FQO', '/content/sg2-model/', 'sg2_fursona_network-e621-r-512-3194880', '.pkl', 'sg2_model'],\n",
    "                ['1394o1nrjWpOPc-phbu4kY11jCu7V7ma7', '/content/sg2-model/', 'sg2_Maps_mapdreamer', '.pkl', 'sg2_model'],\n",
    "                ['1o1rajqJ_USE_VNoJkDW31oHdNm6aAwI1', '/content/sg2-model/', 'sg2_my-little-pony_network-ponies-1024-151552', '.pkl', 'sg2_model'],\n",
    "                ['1JpTTC0C7bKIZ4mggEIByU70gg_3f61dx', '/content/sg2-model/', 'stylegan2-car-config-e', '.pkl', 'sg2_model'],\n",
    "                ['18x-SfrvmwbUFECVXTp56UJj84uTeQGQM', '/content/sg2-model/', 'stylegan2-car-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qsLYOWbVKqKai5ZKpbVlEuiOB1_OKguK', '/content/sg2-model/', 'stylegan2-cat-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1IN8ThfVAWDSNKybUJmWixz1ES9yQpED8', '/content/sg2-model/', 'stylegan2-church-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qceKeMe0NUWZgnw5Dl5smVAkmLXcygai', '/content/sg2-model/', 'stylegan2-ffhq-config-e', '.pkl', 'sg2_model'],\n",
    "                ['1GVYtx73gtC3IUktrqYD-0zarlU53Jw-H', '/content/sg2-model/', 'stylegan2-ffhq-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1abhVX-KB5u-0vUXHwk9ba2FTww442Oj5', '/content/sg2-model/', 'stylegan2-horse-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1mpAOmlxrnPWy_4RjIJxnulRHI6oX09JB', '/content/sg2-model/', 'stylegan2-imagenet-512_model.ckpt-533504', '.pkl', 'sg2_model'],\n",
    "                ['1v8Wh8LaaOuBM7uGf4HoXxnsbem3KUGN_', '/content/sg2-model/', 'stylegan2-wikiart-conditional-model_network-snapshot-012052', '.pkl', 'sg2_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_models][0], dest_path=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3])\n",
    "  files_path[0][1]=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3]\n",
    "if generate&gen_tf1:\n",
    " if generate&gen_sg2_models:\n",
    "  files_path = [['1h8zxPcVrSqsgaY6XZS8-ciIAyYoJBM6t', '/content/sg2-model/', 'sg2_GANscapes', '.pkl', 'sg2_model'],\n",
    "                ['1yruyUn4IdykQmdaOT5Nm9Na18N4UtHDQ', '/content/sg2-model/', 'sg2_minecraft-gan-2020-12-22', '.pkl', 'sg2_model'],\n",
    "                ['1aD0cgxnP_C1MSBKkZm1PvGXZLbKGg_hk', '/content/sg2-model/', 'sg2_modern-art_network-snapshot-026392', '.pkl', 'sg2_model'],\n",
    "                ['1MRPhvrUrCJBoGj4H139bD3Mw2aVYHygs', '/content/sg2-model/', 'sg2_painting-faces_network-snapshot-metfaces2', '.pkl', 'sg2_model'],\n",
    "                ['1Zb5m_ZGMtd4ozz1uiiNI7lpYc-J4G89B', '/content/sg2-model/', 'sg2_textures', '.pkl', 'sg2_model'],\n",
    "                ['1Jb8UqqoAwTtjIx0bTci21EgSsCPHYtWW', '/content/sg2-model/', 'sg2_trypophobia', '.pkl', 'sg2_model'],\n",
    "                ['1EdKrIa3ASx63hgq4qt5-bnAYjlyPCMy4', '/content/sg2-model/', 'sg2_ukiyoe-faces_ukiyoe-256-slim-diffAug-002789', '.pkl', 'sg2_model'],\n",
    "                ['1_6IrHv971aTBqiI1OcsCriPSaKJah9WI', '/content/sg2-model/', 'sg2_wildlife_network-snapshot-027750', '.pkl', 'sg2_model'],\n",
    "                ['1ZstIAlDdoZcoIoqR9KVYoS0mbDq14gFV', '/content/sg2-model/', 'StyleGAN2_microscopev1', '.pkl', 'sg2_model'],\n",
    "                ['1BmGxteqoSvpik-6VgbhOU-PaU5hZVtGw', '/content/sg2-model/', 'stylegan2-100-shot-grumpy_cat', '.pkl', 'sg2_model'],\n",
    "                ['1bSC97gtbp621mnLDpmwnQHN8Z2WLAahM', '/content/sg2-model/', 'stylegan2-100-shot-obama', '.pkl', 'sg2_model'],\n",
    "                ['1UYX_yQjCZ8nLQW0VWbLgmN8V09ChGNAn', '/content/sg2-model/', 'stylegan2-100-shot-panda', '.pkl', 'sg2_model'],\n",
    "                ['11-hSrs8F03rWuOh9Ijvfm5W0xLE6Jnve', '/content/sg2-model/', 'stylegan2-ffhq', '.pkl', 'sg2_model'],\n",
    "                ['1QD8iPkTJaQmQ-Q0E875CBiJrXI_-r8Zj', '/content/sg2-model/', 'sg2_ffhq-256-config-e-003810', '.pkl', 'sg2_model'],\n",
    "                ['1DAisKVy71O0YloSlonYL1rWOUbk_2LDF', '/content/sg2-model/', 'sg2_ffhq-512-avg-tpurun1', '.pkl', 'sg2_model'],\n",
    "                ['1vq1zasHT1PJS6l7-IBK7NU2SRWUc3FQO', '/content/sg2-model/', 'sg2_fursona_network-e621-r-512-3194880', '.pkl', 'sg2_model'],\n",
    "                ['1394o1nrjWpOPc-phbu4kY11jCu7V7ma7', '/content/sg2-model/', 'sg2_Maps_mapdreamer', '.pkl', 'sg2_model'],\n",
    "                ['1o1rajqJ_USE_VNoJkDW31oHdNm6aAwI1', '/content/sg2-model/', 'sg2_my-little-pony_network-ponies-1024-151552', '.pkl', 'sg2_model'],\n",
    "                ['1JpTTC0C7bKIZ4mggEIByU70gg_3f61dx', '/content/sg2-model/', 'stylegan2-car-config-e', '.pkl', 'sg2_model'],\n",
    "                ['18x-SfrvmwbUFECVXTp56UJj84uTeQGQM', '/content/sg2-model/', 'stylegan2-car-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qsLYOWbVKqKai5ZKpbVlEuiOB1_OKguK', '/content/sg2-model/', 'stylegan2-cat-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1IN8ThfVAWDSNKybUJmWixz1ES9yQpED8', '/content/sg2-model/', 'stylegan2-church-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1qceKeMe0NUWZgnw5Dl5smVAkmLXcygai', '/content/sg2-model/', 'stylegan2-ffhq-config-e', '.pkl', 'sg2_model'],\n",
    "                ['1GVYtx73gtC3IUktrqYD-0zarlU53Jw-H', '/content/sg2-model/', 'stylegan2-ffhq-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1abhVX-KB5u-0vUXHwk9ba2FTww442Oj5', '/content/sg2-model/', 'stylegan2-horse-config-f', '.pkl', 'sg2_model'],\n",
    "                ['1mpAOmlxrnPWy_4RjIJxnulRHI6oX09JB', '/content/sg2-model/', 'stylegan2-imagenet-512_model.ckpt-533504', '.pkl', 'sg2_model'],\n",
    "                ['1v8Wh8LaaOuBM7uGf4HoXxnsbem3KUGN_', '/content/sg2-model/', 'stylegan2-wikiart-conditional-model_network-snapshot-012052', '.pkl', 'sg2_model']]\n",
    "  download_file_from_google_drive(file_id=files_path[sg2_models][0], dest_path=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3])\n",
    "  files_path[0][1]=files_path[sg2_models][1]+files_path[sg2_models][2]+files_path[sg2_models][3]\n",
    "\n",
    "\n",
    "if generate&gen_stylegan2:\n",
    " if generate&gen_tf1:\n",
    "#if generate_stylegan2_ada or generate_stylegan2_ext:\n",
    "  import dnnlib\n",
    "  import dnnlib.tflib as tflib  \n",
    "  tflib.init_tf()\n",
    "  \n",
    "  import pickle\n",
    "  network_pkl=files_path[0][1]\n",
    "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
    " #       _G, _D, Gs = pickle.load(fp)\n",
    "  _G, _D, Gs = pickle.load(open(network_pkl, \"rb\"))\n",
    "\n",
    "if generate&gen_sg2_nvlabs_ada_pt:\n",
    "\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "  #!pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "\n",
    "if generate&gen_sg3_nvlabs_pt:\n",
    "\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "#  !pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G3 = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
    "\n",
    "if generate&gen_sg3_Expl0dingCat_pt:\n",
    "\n",
    "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
    "#  !pip install torch==1.7.1\n",
    "#  %pip install ninja\n",
    "#  import pickle\n",
    "  import copy\n",
    "  import os\n",
    "  #from time import perf_counter\n",
    "\n",
    "  #import click\n",
    "  import imageio\n",
    "  import numpy as np\n",
    "  import PIL.Image\n",
    "  import torch\n",
    "  import torch.nn.functional as F\n",
    "\n",
    "  import dnnlib\n",
    "  import legacy\n",
    "  network_pkl=files_path[0][1]\n",
    "\n",
    "  device = torch.device('cuda')\n",
    "  with dnnlib.util.open_url(network_pkl) as fp:\n",
    "      G3m = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZiiNucjOiH8",
    "outputId": "c8af67e9-3253-417c-c060-12a8a8cad517"
   },
   "outputs": [],
   "source": [
    "#@title methods { run: \"auto\" }\n",
    "\n",
    "method = \"wpli\" #@param ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']\n",
    "print('You selected', method)\n",
    "methods = [method]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IpzFG9myQWXl"
   },
   "outputs": [],
   "source": [
    "#@title bands { run: \"auto\" }\n",
    "\n",
    "band = \"8.0,12.0\" #@param ['4.0,7.0', '8.0,12.0', '13.0,29.0', '30.0,45.0']\n",
    "print('You selected', band)\n",
    "import json\n",
    "bands = [json.loads('['+band+']')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "B6d2TUfLSIS3"
   },
   "outputs": [],
   "source": [
    "#@title tf1_wavegan_drums { run: \"auto\" }\n",
    "\n",
    "mono_stereo_swap = \"stereo with swap\" #@param ['mono', 'stereo without swap', 'stereo with swap']\n",
    "print('You selected', mono_stereo_swap)\n",
    "generate = gen_tf1 | gen_wavegan | gen_drums\n",
    "if mono_stereo_swap == \"mono\":\n",
    "  generate = generate\n",
    "if mono_stereo_swap == \"stereo without swap\":\n",
    "  generate = generate | gen_wg_stereo\n",
    "if mono_stereo_swap == \"stereo with swap\":\n",
    "  generate = generate | gen_wg_stereo | gen_wg_st_swap\n",
    "  \n",
    "generate = generate | gen_jpeg |gen_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_cS7s4r8BcrB"
   },
   "outputs": [],
   "source": [
    "methods = ['coh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5q_2zf1JBcjE"
   },
   "outputs": [],
   "source": [
    "methods = ['plv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kbmu62mGBccC"
   },
   "outputs": [],
   "source": [
    "methods = ['ciplv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fn0h9pgXBcRp"
   },
   "outputs": [],
   "source": [
    "methods = ['ppc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hjpxs4q2BcIZ"
   },
   "outputs": [],
   "source": [
    "methods = ['pli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EXYkvvyjBb_y"
   },
   "outputs": [],
   "source": [
    "methods = ['wpli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OBOTEr1N38s"
   },
   "outputs": [],
   "source": [
    "methods = ['coh']\n",
    "#methods = ['plv']\n",
    "#methods = ['ciplv']\n",
    "#methods = ['ppc']\n",
    "#methods = ['pli']\n",
    "#methods = ['wpli']\n",
    "#methods = ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bzOvkuFuCtCh"
   },
   "outputs": [],
   "source": [
    "bands = [[4.,7.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cBKZSj8YCs-Y"
   },
   "outputs": [],
   "source": [
    "bands = [[8.,12.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AFFiaT_5Cs66"
   },
   "outputs": [],
   "source": [
    "bands = [[13.,29.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHpj38JXCwY_"
   },
   "outputs": [],
   "source": [
    "bands = [[30.,45.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2yUC8TD1nrT"
   },
   "outputs": [],
   "source": [
    "#bands = [[4.,7.]]\n",
    "#bands = [[8.,12.]]\n",
    "bands = [[4.,7.],[8.,12.]]\n",
    "#bands = [[13.,29.]]\n",
    "#bands = [[8.,12.],[13.,29.]]\n",
    "#bands = [[4.,7.],[13.,29.]]\n",
    "#bands = [[4.,7.],[8.,12.],[13.,29.]]\n",
    "#bands = [[30.,45.]]\n",
    "#bands = [[4.,7.],[30.,45.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1bMmefN_y0x"
   },
   "outputs": [],
   "source": [
    "generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_nvlabs_ada | gen_anime_protraits\n",
    "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_drums\n",
    "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_anime_protraits | gen_wavegan | gen_drums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XGADYii2xXyR"
   },
   "outputs": [],
   "source": [
    "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_wavegan_stereo | gen_drums\n",
    "generate = gen_tf1 | gen_wavegan | gen_wg_stereo | gen_drums\n",
    "generate = generate | gen_jpeg |gen_mp3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaVoVmCc8grr"
   },
   "outputs": [],
   "source": [
    "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_wavegan_stereo | gen_wavegan_stereo_swap | gen_drums\n",
    "generate = gen_tf1 | gen_wavegan | gen_wg_stereo | gen_wg_st_swap | gen_drums\n",
    "generate = generate | gen_jpeg |gen_mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVigZ0vLVBMj"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g1cXinGXEkTR"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dozWgxSrvC5"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iBp7jy5zD5X"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJd_aYyNrs8J"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hZUBDU8frsnJ"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKO70vv4rr8J"
   },
   "outputs": [],
   "source": [
    "fps_sg2=fps_wg*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eeU21L1eEk_x"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/1)\n",
    "ysize=int(512/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pnRG1eZwu3f7"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/2)\n",
    "ysize=int(512/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6nRQTQbGvffi"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/3)\n",
    "ysize=int(512/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvcL8hjFvoOh"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/4)\n",
    "ysize=int(512/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GizuQ5TNvpZZ"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/5)\n",
    "ysize=int(512/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zpoZlAo8vqMJ"
   },
   "outputs": [],
   "source": [
    "xsize=int(512/6)\n",
    "ysize=int(512/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7M3q-mfvIbjA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#if generate_stylegan2:\n",
    "fps_sg2=1\n",
    "#if generate_wavegan:\n",
    "fps_wg=hz/(32768*2)\n",
    "fps_sg2=fps_wg\n",
    "\n",
    "duration=2*1/fps_wg#-0.2\n",
    "#overlap=duration/32#-0.1\n",
    "#overlap=0.1\n",
    "#overlap=0\n",
    "#duration=5*1/8\n",
    "overlap=0\n",
    "#overlap=duration-0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxafHdQ6rP5y"
   },
   "outputs": [],
   "source": [
    "fps_sg2=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEY8ZE90g4Bl"
   },
   "outputs": [],
   "source": [
    "n_sample=1\n",
    "inputSize=1024\n",
    "z = np.random.randn(n_sample, inputSize).astype(\"float32\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHm9yDes4i-V"
   },
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9NBWWs1HAzf7"
   },
   "outputs": [],
   "source": [
    "video_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KubmOemcqU_4"
   },
   "outputs": [],
   "source": [
    "\n",
    "from IPython import display as ipythondisplay\n",
    "import io\n",
    "import os\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "def show_video(vid):\n",
    "  ext = os.path.splitext(vid)[-1][1:]\n",
    "  video = io.open(vid, 'r+b').read()\n",
    "  ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "              loop controls style=\"height: 400px;\">\n",
    "              <source src=\"data:video/{1}';base64,{0}\" type=\"video/{1}\" />\n",
    "              </video>'''.format(base64.b64encode(video).decode('ascii'), ext)))\n",
    "\n",
    "show_video('/content/out/output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRaKPKotYCq4"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('/content/out/output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6JXcX4OYAsw"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "!cp -r -v \"/content/out\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EEG_stream_connectivity_Generate_Abstract_Art&Anime_Portraits&TADNE&Drums_with_StyleGAN2&WaveGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
