{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "EEG_stream_connectivity_Generate_Abstract_Art&Anime_Portraits&TADNE&Drums_with_StyleGAN2&WaveGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/neuroidss/EEG-GAN-audio-video/blob/main/EEG_stream_connectivity_Generate_Abstract_Art%26Anime_Portraits%26TADNE%26Drums_with_StyleGAN2%26WaveGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SD4RO2F-xOT"
      },
      "source": [
        "gen_tpu = 1 << 0\n",
        "gen_gpu = 1 << 1\n",
        "gen_pytorch = 1 << 2\n",
        "gen_tf1 = 1 << 3\n",
        "gen_tf2 = 1 << 4\n",
        "gen_stylegan2 = 1 << 5\n",
        "gen_sg2_nagolinc_pt = 1 << 6\n",
        "gen_sg2_ada_pt = 1 << 7\n",
        "gen_sg2_tf1 = 1 << 8\n",
        "gen_sg2_tf2 = 1 << 9\n",
        "gen_sg2_rosasalberto_tf2 = 1 << 10\n",
        "gen_anime_tf2_npy = 1 << 11\n",
        "gen_tadne_tf2_npy = 1 << 12\n",
        "gen_anime_protraits_tf2_npy = 1 << 13\n",
        "gen_abctract_art_tf2_npy = 1 << 14\n",
        "gen_tf2_npy = 1 << 15\n",
        "gen_sg2_moono_tf2 = 1 << 16\n",
        "gen_anime_tf2 = 1 << 17\n",
        "gen_sg2_shawwn_tpu = 1 << 18\n",
        "gen_sg2_cyrilzakka_tpu = 1 << 19\n",
        "gen_sg2_nvlabs = 1 << 20\n",
        "gen_anime = 1 << 21\n",
        "gen_sg2_shawwn = 1 << 22\n",
        "gen_tadne = 1 << 23\n",
        "gen_sg2_ada = 1 << 24\n",
        "gen_anime_protraits = 1 << 25\n",
        "gen_abctract_art = 1 << 26\n",
        "gen_wavegan = 1 << 27\n",
        "gen_drums = 1 << 28\n",
        "gen_mp3 = 1 << 29\n",
        "gen_wav = 1 << 30\n",
        "gen_png = 1 << 31\n",
        "gen_jpeg = 1 << 32\n",
        "gen_heatmap = 1 << 33\n",
        "\n",
        "  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q08NMGPUAfmh"
      },
      "source": [
        "generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_anime_protraits\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_abctract_art\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne\n",
        "#generate = gen_gpu | gen_pytorch | gen_sg2_nagolinc_pt | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne\n",
        "#generate = gen_gpu | gen_tf1 | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_anime_protraits | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_abctract_art | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_pytorch | gen_sg2_nagolinc_pt | gen_tf1 | gen_stylegan2 | gen_sg2_shawwn | gen_tadne | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_anime_protraits_tf2_npy\n",
        "#generate = gen_gpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_abctract_art_tf2_npy\n",
        "#generate = gen_tpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_anime_protraits_tf2_npy\n",
        "#generate = gen_tpu | gen_tf2 | gen_stylegan2 | gen_sg2_rosasalberto_tf2 | gen_abctract_art_tf2_npy\n",
        "#generate = gen_tpu | gen_tf1 | gen_wavegan | gen_drums\n",
        "\n",
        "#generate = generate | gen_png |gen_wav\n",
        "generate = generate | gen_jpeg |gen_mp3\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkq7jIXnJm1W"
      },
      "source": [
        "##biosemi16-2:\n",
        "ch_names_wg = ['FP1','F3','T7','C3','P3','Pz','O1','O2','P4','C4','T8','F4','FP2','Fz']\n",
        "ch_locations_wg=[0,3,6,7,11,12,14,16,18,22,23,26,29,30]\n",
        "\n",
        "#biosemi32\n",
        "ch_names_sg2 = ['FP1','AF3','F7','F3','FC1','FC5','T7','C3','CP1','CP5','P7','P3','Pz','PO3','O1','Oz','O2','PO4','P4','P8','CP6','CP2','C4','T8','FC6','FC2','F4','F8','AF4','FP2','Fz','Cz']\n",
        "ch_locations_sg2=[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
        "##Bernard's 19ch:\n",
        "#ch_names = [\"FP2\",\"FP1\",\"O2\",\"T6\",\"T4\",\"F8\",\"F4\",\"C4\",\"P4\",\"F3\",\"C3\",\"P3\",\"O1\",\"T5\",\"T3\",\"F7\",\"FZ\",\"PZ\"]#,\"other\"]\n",
        "#ch_locations=[4,24,0,1,2,3,5,6,7,25,26,27,28,29,30,31,16,12]#,8]\n",
        "##Bernard's 2ch:\n",
        "#ch_names = [\"FP2\",\"FP1\"]#,\"other\"]\n",
        "#ch_locations=[4,24]#,8]\n",
        "\n",
        "bands = [[8.,12.]]\n",
        "#bands = [[4.,7.],[8.,12.]]\n",
        "#bands = [[8.,12.],[8.,12.],[8.,12.]]\n",
        "methods = ['coh']\n",
        "#methods = ['plv']\n",
        "#methods = ['ciplv']\n",
        "#methods = ['ppc']\n",
        "#methods = ['pli']\n",
        "#methods = ['wpli']\n",
        "#methods = ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']\n",
        "\n",
        "#vol=1\n",
        "vol=6\n",
        "#vol=0.1\n",
        "\n",
        "duration=5*1/8\n",
        "overlap=0\n",
        "#overlap=duration-0.1\n",
        "xsize=512\n",
        "ysize=512\n",
        "#xsize=512/2\n",
        "#ysize=512/2\n",
        "hz=44100\n",
        "#fps=hz/(32768)\n",
        "\n",
        "#if generate_stylegan2:\n",
        "fps_sg2=1\n",
        "#if generate_wavegan:\n",
        "fps_wg=hz/(32768*2)\n",
        "fps_sg2=fps_wg\n",
        "fps_hm=fps_wg\n",
        "\n",
        "#if 1/fps_wg-0.2>duration:\n",
        "#  duration=1/fps_wg-0.2\n",
        "#  overlap=duration-0.1\n",
        "if 2*1/fps_wg>duration:\n",
        "  duration=2*1/fps_wg\n",
        "  overlap=0\n",
        "\n",
        "if generate&gen_wavegan:\n",
        "  dim_wg = 100\n",
        "if generate&gen_stylegan2:\n",
        "  dim_sg2 = 512\n",
        "if generate&gen_sg2_shawwn:\n",
        "  dim_sg2 = 1024\n",
        "\n",
        "stepSize = 1/pow(2,24)\n",
        "vref = 2.50 #2.5V voltage ref +/- 250nV\n",
        "gain = 8\n",
        "\n",
        "vscale = (vref/gain)*stepSize #volts per step.\n",
        "uVperStep = 1000000 * ((vref/gain)*stepSize) #uV per step.\n",
        "scalar = 1/(1000000 / ((vref/gain)*stepSize)) #steps per uV."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exdhoEe151Ja"
      },
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WErNtyaMBkg",
        "outputId": "ccc13cc4-7e3c-46e6-d9e5-4332a1474e04"
      },
      "source": [
        "if generate&gen_tf1:\n",
        "  %tensorflow_version 1.x\n",
        "if generate&gen_tf2:\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Tensorflow version: 1.15.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLsvM-V7Oh9S",
        "outputId": "f0cd9c42-41c1-434a-af53-16d38221e181"
      },
      "source": [
        "if generate&gen_tf1:\n",
        " if generate&gen_gpu:\n",
        "  from tensorflow.python.client import device_lib\n",
        "  print(device_lib.list_local_devices())\n",
        "\n",
        " if generate&gen_tpu:\n",
        "  import os\n",
        "  import tensorflow.compat.v1 as tf\n",
        "  tf.disable_eager_execution()\n",
        "  import pprint\n",
        "  assert 'COLAB_TPU_ADDR' in os.environ, 'Did you forget to switch to TPU?'\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "  with tf.Session(tpu_address) as sess:\n",
        "    devices = sess.list_devices()\n",
        "  pprint.pprint(devices)\n",
        "  device_is_tpu = [True if 'TPU' in str(x) else False for x in devices]\n",
        "  assert True in device_is_tpu, 'Did you forget to switch to TPU?'\n",
        "\n",
        "if generate&gen_tf2:\n",
        " try: # detect TPUs\n",
        "  tpu = None\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n",
        "  tf.config.experimental_connect_to_cluster(tpu)\n",
        "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "  strategy = tf.distribute.TPUStrategy(tpu)\n",
        " except ValueError: # detect GPUs\n",
        "  strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n",
        "  #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n",
        "  #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n",
        "\n",
        " print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 16285641775006292306\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 10032703855539980859\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 5262327244307022855\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 11338832282\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 8969548225017325322\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaHracqcMbGG",
        "outputId": "44a6e280-80d1-4189-bdeb-01a198e6540c"
      },
      "source": [
        "if generate&gen_sg2_nvlabs:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/NVlabs/stylegan2.git\n",
        "  %cd /content/stylegan2\n",
        "if generate&gen_sg2_ada:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/NVlabs/stylegan2-ada.git\n",
        "  %cd /content/stylegan2-ada\n",
        "if generate&gen_sg2_shawwn:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/shawwn/stylegan2.git stylegan2-shawwn\n",
        "  %cd /content/stylegan2-shawwn\n",
        "if generate&gen_sg2_cyrilzakka_tpu:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/cyrilzakka/stylegan2-tpu.git stylegan2-cyrilzakka-tpu\n",
        "  %cd /content/stylegan2-cyrilzakka-tpu\n",
        "  #!pip install -r requirements.txt\n",
        "  #!pip install tensorflow-gpu==2.4.0\n",
        "  #!pip install Keras-Applications==1.0.7\n",
        "  #!pip install Keras-Preprocessing==1.0.9\n",
        "if generate&gen_sg2_shawwn_tpu:\n",
        "  %cd /content\n",
        "  !git clone --branch tpu https://github.com/shawwn/stylegan2.git stylegan2-shawwn-tpu\n",
        "  %cd /content/stylegan2-shawwn-tpu\n",
        "if generate&gen_sg2_moono_tf2:\n",
        "  %cd /content\n",
        "  #!git clone https://github.com/NVlabs/stylegan2.git\n",
        "  #%cd /content/stylegan2\n",
        "  !git clone https://github.com/moono/stylegan2-tf-2.x.git\n",
        "  %cd /content/stylegan2-tf-2.x\n",
        "if generate&gen_sg2_rosasalberto_tf2:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/rosasalberto/StyleGAN2-TensorFlow-2.x.git\n",
        "  %cd /content/StyleGAN2-TensorFlow-2.x\n",
        "if generate&gen_sg2_nagolinc_pt:\n",
        "  #%cd /content\n",
        "  !git clone https://github.com/nagolinc/stylegan2-pytorch.git /content/stylegan2-pytorch/\n",
        "  #%cd /content/stylegan2-pytorch\n",
        "if generate&gen_sg2_ada_pt:\n",
        "  %cd /content\n",
        "  !git clone https://github.com/NVlabs/stylegan2-ada-pytorch\n",
        "  %cd stylegan2-ada-pytorch"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stylegan2-ada'...\n",
            "remote: Enumerating objects: 71, done.\u001b[K\n",
            "remote: Total 71 (delta 0), reused 0 (delta 0), pack-reused 71\u001b[K\n",
            "Unpacking objects: 100% (71/71), done.\n",
            "/content/stylegan2-ada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uqYszSxLKjt1",
        "outputId": "58dbbbd8-2b0e-43b0-85ea-66b60e36b2e6"
      },
      "source": [
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "files_path=[]\n",
        "if generate&gen_drums:\n",
        "  files_path = [['1ZJir-_ls92s56LFmw_HVuQ7ANqFFN5WG', '/content/model/model.ckpt-18637.data-00000-of-00001'],\n",
        "              ['1d5ayi4w-70AvKYPk-8sXzsSzpK1jMRgm', '/content/model/model.ckpt-18637.index'],  \n",
        "              ['15CWn0yK3FKsHbAOGNLQYVg4eZC1oNIrL', '/content/model/model.ckpt-18637.meta'],  \n",
        "              ['1x5QEFeoochk-rhvtvJc98kIB5_SAwn0u', '/content/model/args.txt'],  \n",
        "              ['1UgSZaBTCTDXaPbfv8l0wmpHbD5u051o5', '/content/model/graph.pbtxt'],  \n",
        "              ['1LGfAkuOFvA3NdFE_rOq9WyeXGGgEOf0F', '/content/model/checkpoint'],  \n",
        "              ['1bPD0bXCC_18oWbUjmjkacF-CShlA6yNd', '/content/model/infer/infer.pbtxt'],  \n",
        "              ['13OQuRx7Ku6KJ9o9FU-JN3yB0Njul9Vem', '/content/model/infer/infer.meta']]\n",
        "for i in range(len(files_path)):\n",
        "  gdd.download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
        "files_path=[]\n",
        "if generate&gen_abctract_art:\n",
        "  files_path = [['1ie1vWw1JNsfrZWRtMvhteqzVz4mt4KGa', '/content/model/sg2-ada_abstract_network-snapshot-000188.pkl',\n",
        "                 'sg2-ada_abstract_network-snapshot-000188','stylegan2-ada']]\n",
        "if generate&gen_anime_protraits:\n",
        "  files_path = [['1aUrChOhq5jDEddZK1v_Dp1vYNlHSBL9o', '/content/model/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl', \n",
        "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664','stylegan2-ada']]\n",
        "if generate&gen_tadne:\n",
        "#  files_path = [['1sdnL-lIl2kYAnuleafK-5GPiLNHfxh4W', '/content/model/sg2-ext_aydao-anime-danbooru2019s-512-5268480.pkl', \n",
        "#                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480','stylegan2-shawwn']]\n",
        "  files_path = [['1LCkyOPmcWBsPlQX_DxKAuPM1Ew_nh83I', '/content/model/sg2-ext_network-tadne.pkl', \n",
        "                 'sg2-ext_network-tadne','stylegan2-shawwn']]\n",
        "  #files_path = [['1l5zG0g_RMEAwFUK_veD1EZweVEoY9gUT', '/content/model/aydao-anime-danbooru2019s-512-5268480.pkl']]\n",
        "#  files_path = [['1BHeqOZ58WZ-vACR2MJkh1ZVbJK2B-Kle', '/content/model/network-snapshot-017325.pkl']]\n",
        "#  files_path = [['1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez', '/content/model/network-snapshot-018528.pkl']]\n",
        "if generate&gen_anime:\n",
        "  files_path = [['1YckI8gwqPbZBI8X4eaQAJCgWx-CqCTdi', '/content/model/sg2_anime_network-snapshot-018528.pkl', \n",
        "                 'sg2_anime_network-snapshot-018528']]\n",
        "if generate&gen_anime_tf2:\n",
        "  files_path = [['1-1neAg_FUymzBvCStMe7CfV94-VD22kk', '/content/stylegan2-tf-2.x/official-converted/cuda/ckpt-0.data-00000-of-00001'],\n",
        "              ['1-4ih0wi68y4xH5tg0_kClpuWDSnvdmoE', '/content/stylegan2-tf-2.x/official-converted/cuda/ckpt-0.index'],\n",
        "              ['1-C6H58vmfZykqWpilR1u9puH8oPFQtcQ', '/content/stylegan2-tf-2.x/official-converted/cuda/checkpoint']]\n",
        "if generate&gen_abctract_art_tf2_npy:\n",
        "  files_path = [['1cauGWIVGGiMJA0_OZftJU3-rVAVdFwZM', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ada_abstract_network-snapshot-000188.npy',\n",
        "                 'sg2-ada_abstract_network-snapshot-000188']]\n",
        "if generate&gen_anime_protraits_tf2_npy:\n",
        "  files_path = [['1-Cp-RRJnjvfCIrD0ylaUYxvLbxN4aj8K', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.npy', \n",
        "                 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664']]\n",
        "if generate&gen_tadne_tf2_npy:\n",
        "  files_path = [['1-36-rfueVBWvigBvCuwzrXKl1AeVtzu6', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2-ext_aydao-anime-danbooru2019s-512-5268480.npy', \n",
        "                 'sg2-ext_aydao-anime-danbooru2019s-512-5268480']]\n",
        "if generate&gen_anime_tf2_npy:\n",
        "  files_path = [['1--ajK29hgTTAYNcZhQk9lLFhwUlXqxNA', '/content/StyleGAN2-TensorFlow-2.x/weights/sg2_anime_network-snapshot-018528.npy', \n",
        "                 'sg2_anime_network-snapshot-018528']]\n",
        "\n",
        "#https://drive.google.com/file/d/1ie1vWw1JNsfrZWRtMvhteqzVz4mt4KGa/view?usp=sharing\n",
        "#network-snapshot-000188.pkl\n",
        "#https://drive.google.com/file/d/1YckI8gwqPbZBI8X4eaQAJCgWx-CqCTdi/view?usp=sharing\n",
        "#network-snapshot-018528.pkl\n",
        "\n",
        "\n",
        "for i in range(len(files_path)):\n",
        "  gdd.download_file_from_google_drive(file_id=files_path[i][0], dest_path=files_path[i][1])\n",
        "\n",
        "if generate&gen_stylegan2:\n",
        "  import PIL.Image \n",
        "  !pip install tqdm\n",
        "  from tqdm import tqdm\n",
        "  !pip install imageio==2.4.1\n",
        "  !pip install imageio-ffmpeg==0.4.3 pyspng==0.1.0\n",
        "\n",
        "if generate&gen_sg2_rosasalberto_tf2:\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  from utils.utils_stylegan2 import convert_images_to_uint8\n",
        "\n",
        "  def generate_and_plot_images(gen, seed, w_avg, truncation_psi=1):\n",
        "    \"\"\" plot images from generator output \"\"\"\n",
        "    \n",
        "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
        "    for i in range(3):\n",
        "    \n",
        "        # creating random latent vector\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, 512).astype('float32')\n",
        "\n",
        "        # running mapping network\n",
        "        dlatents = gen.mapping_network(z)\n",
        "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
        "        dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
        "        # running synthesis network\n",
        "        out = gen.synthesis_network(dlatents)\n",
        "\n",
        "        #converting image/s to uint8\n",
        "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "\n",
        "        #plotting images\n",
        "        ax[i].axis('off')\n",
        "        img_plot = ax[i].imshow(img.numpy()[0])\n",
        "        \n",
        "        seed += 1\n",
        "\n",
        "  impl = 'ref' # 'ref' if cuda is not available in your machine\n",
        "  gpu = False # False if tensorflow cpu is used\n",
        "  if generate&gen_tpu:\n",
        "    impl = 'ref' # 'ref' if cuda is not available in your machine\n",
        "    gpu = False # False if tensorflow cpu is used\n",
        "  if generate&gen_gpu:\n",
        "    impl = 'cuda' # 'ref' if cuda is not available in your machine\n",
        "    gpu = True # False if tensorflow cpu is used\n",
        "\n",
        "  import tensorflow as tf\n",
        "  import numpy as np\n",
        "\n",
        "  from utils.weights_map import available_weights, synthesis_weights, mapping_weights, weights_stylegan2_dir\n",
        "  from utils.utils_stylegan2 import nf\n",
        "  from layers.dense_layer import DenseLayer\n",
        "  from layers.synthesis_main_layer import SynthesisMainLayer\n",
        "  from layers.to_rgb_layer import ToRgbLayer\n",
        "  from dnnlib.ops.upfirdn_2d import upsample_2d\n",
        "\n",
        "  class MappingNetwork(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator mapping network, from z to dlatents for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, **kwargs):\n",
        "        \n",
        "        super(MappingNetwork, self).__init__(**kwargs)\n",
        "        \n",
        "        self.dlatent_size = 512\n",
        "        self.dlatent_vector = (int(np.log2(resolution))-1)*2\n",
        "        self.mapping_layers = 8\n",
        "        self.lrmul = 0.01\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.weights_dict = {}\n",
        "        for i in range(self.mapping_layers):\n",
        "            setattr(self, 'Dense{}'.format(i), DenseLayer(fmaps=512, lrmul=self.lrmul, name='Dense{}'.format(i)))\n",
        "    \n",
        "        self.g_mapping_broadcast = tf.keras.layers.RepeatVector(self.dlatent_vector)\n",
        "            \n",
        "    def call(self, z):\n",
        "        \n",
        "        z = tf.cast(z, 'float32')\n",
        "        \n",
        "        # Normalize inputs\n",
        "        scale = tf.math.rsqrt(tf.reduce_mean(tf.square(z), axis=1, keepdims=True) + 1e-8)\n",
        "        x = tf.math.multiply(z, scale)\n",
        "        \n",
        "        # Mapping\n",
        "        for i in range(self.mapping_layers):\n",
        "        \n",
        "            x = getattr(self, 'Dense{}'.format(i))(x)\n",
        "            x = tf.math.multiply(tf.nn.leaky_relu(x, 0.2), tf.math.sqrt(2.))\n",
        "        \n",
        "        # Broadcasting\n",
        "        dlatents = self.g_mapping_broadcast(x)\n",
        "        \n",
        "        return dlatents\n",
        "\n",
        "  class SynthesisNetwork(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator synthesis network from dlatents to img tensor for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, impl='cuda', gpu=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        resolution : int, optional\n",
        "            Resolution output of the synthesis network, will be parsed to the floor integer power of 2. \n",
        "            The default is 1024.\n",
        "        impl : str, optional\n",
        "            Wether to run some convolutions in custom tensorflow operations or cuda operations. 'ref' and 'cuda' available.\n",
        "            The default is 'cuda'.\n",
        "        gpu : boolean, optional\n",
        "            Wether to use gpu. The default is True.\n",
        "        \"\"\"\n",
        "        super(SynthesisNetwork, self).__init__(**kwargs)\n",
        "        \n",
        "        self.impl = impl\n",
        "        self.gpu = gpu\n",
        "        self.resolution = resolution\n",
        "        \n",
        "        self.resolution_log2 = int(np.log2(self.resolution))\n",
        "        self.resample_kernel = [1, 3, 3, 1]\n",
        "        \n",
        "    def build(self, input_shape):\n",
        "        \n",
        "        #constant layer\n",
        "        self.const_4_4 = self.add_weight(name='4x4/Const/const', shape=(1, 512, 4, 4), \n",
        "                                        initializer=tf.random_normal_initializer(0, 1), trainable=True)\n",
        "        #early layer 4x4\n",
        "        self.layer_4_4 = SynthesisMainLayer(fmaps=nf(1), impl=self.impl, gpu=self.gpu, name='4x4')\n",
        "        self.torgb_4_4 = ToRgbLayer(impl=self.impl, gpu=self.gpu, name='4x4')\n",
        "        #main layers\n",
        "        for res in range(3, self.resolution_log2 + 1):\n",
        "            res_str = str(2**res)\n",
        "            setattr(self, 'layer_{}_{}_up'.format(res_str, res_str), \n",
        "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, up=True, name='{}x{}'.format(res_str, res_str)))\n",
        "            setattr(self, 'layer_{}_{}'.format(res_str, res_str), \n",
        "                    SynthesisMainLayer(fmaps=nf(res-1), impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
        "            setattr(self, 'torgb_{}_{}'.format(res_str, res_str), \n",
        "                    ToRgbLayer(impl=self.impl, gpu=self.gpu, name='{}x{}'.format(res_str, res_str)))\n",
        "        \n",
        "    def call(self, dlatents_in):\n",
        "        \n",
        "        dlatents_in = tf.cast(dlatents_in, 'float32')\n",
        "        y = None\n",
        "        \n",
        "        # Early layers\n",
        "        x = tf.tile(tf.cast(self.const_4_4, 'float32'), [tf.shape(dlatents_in)[0], 1, 1, 1])\n",
        "        x = self.layer_4_4(x, dlatents_in[:, 0])\n",
        "        y = self.torgb_4_4(x, dlatents_in[:, 1], y)\n",
        "                \n",
        "        # Main layers\n",
        "        for res in range(3, self.resolution_log2 + 1):\n",
        "            x = getattr(self, 'layer_{}_{}_up'.format(2**res, 2**res))(x, dlatents_in[:, res*2-5])\n",
        "            x = getattr(self, 'layer_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-4])\n",
        "            y = upsample_2d(y, k=self.resample_kernel, impl=self.impl, gpu=self.gpu)\n",
        "            y = getattr(self, 'torgb_{}_{}'.format(2**res, 2**res))(x, dlatents_in[:, res*2-3], y)\n",
        "                    \n",
        "        images_out = y\n",
        "        return tf.identity(images_out, name='images_out')\n",
        "    \n",
        "  class StyleGan2Generator(tf.keras.layers.Layer):\n",
        "    \"\"\"\n",
        "    StyleGan2 generator config f for tensorflow 2.x\n",
        "    \"\"\"\n",
        "    def __init__(self, resolution=1024, weights=None, impl='cuda', gpu=True, **kwargs):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        resolution : int, optional\n",
        "            Resolution output of the synthesis network, will be parsed \n",
        "            to the floor integer power of 2. \n",
        "            The default is 1024.\n",
        "        weights : string, optional\n",
        "            weights name in weights dir to be loaded. The default is None.\n",
        "        impl : str, optional\n",
        "            Wether to run some convolutions in custom tensorflow operations \n",
        "            or cuda operations. 'ref' and 'cuda' available.\n",
        "            The default is 'cuda'.\n",
        "        gpu : boolean, optional\n",
        "            Wether to use gpu. The default is True.\n",
        "        \"\"\"\n",
        "        super(StyleGan2Generator, self).__init__(**kwargs)\n",
        "        \n",
        "        self.resolution = resolution\n",
        "        if weights is not None: self.__adjust_resolution(weights)\n",
        "\n",
        "        self.mapping_network = MappingNetwork(resolution=self.resolution,name='Mapping_network')\n",
        "        self.synthesis_network = SynthesisNetwork(resolution=self.resolution, impl=impl, \n",
        "                                                  gpu=gpu, name='Synthesis_network')\n",
        "        \n",
        "        # load weights\n",
        "        if weights is not None:\n",
        "            #we run the network to define it, not the most efficient thing to do...\n",
        "            _ = self(tf.zeros(shape=(1, 512)))\n",
        "            self.__load_weights(weights)\n",
        "        \n",
        "    def call(self, z):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        z : tensor, latent vector of shape [batch, 512]\n",
        "        Returns\n",
        "        -------\n",
        "        img : tensor, image generated by the generator of shape  [batch, channel, height, width]\n",
        "        \"\"\"\n",
        "        dlatents = self.mapping_network(z)\n",
        "        img = self.synthesis_network(dlatents)\n",
        "\n",
        "        return img\n",
        "    \n",
        "    def __adjust_resolution(self, weights_name):\n",
        "        \"\"\"\n",
        "        Adjust resolution of the synthesis network output. \n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_name : name of the weights\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "        \"\"\"\n",
        "        if  weights_name == 'ffhq': \n",
        "            self.resolution = 1024\n",
        "        elif weights_name == 'car': \n",
        "            self.resolution = 512\n",
        "        elif weights_name in ['cat', 'church', 'horse']: \n",
        "            self.resolution = 256\n",
        "        elif weights_name == 'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664': \n",
        "            self.resolution = 512\n",
        "        elif weights_name == 'sg2_anime_network-snapshot-018528': \n",
        "            self.resolution = 512\n",
        "        elif weights_name == 'sg2-ext_aydao-anime-danbooru2019s-512-5268480': \n",
        "            self.resolution = 1024\n",
        "        elif weights_name == 'sg2-ada_abstract_network-snapshot-000188': \n",
        "            self.resolution = 512    \n",
        "    def __load_weights(self, weights_name):\n",
        "        \"\"\"\n",
        "        Load pretrained weights, stored as a dict with numpy arrays.\n",
        "        Parameters\n",
        "        ----------\n",
        "        weights_name : name of the weights\n",
        "        Returns\n",
        "        -------\n",
        "        None.\n",
        "        \"\"\"\n",
        "        \n",
        "        if (weights_name in available_weights) and type(weights_name) == str:\n",
        "            data = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
        "            #datatmp = np.load(weights_stylegan2_dir + weights_name + '.npy', allow_pickle=True)[()]\n",
        "            #data=datatmp.copy()\n",
        "            #for key in datatmp.keys(): \n",
        "            #  if not (key[:4]=='disc'):\n",
        "            #    del data[key]\n",
        "            \n",
        "            weights_mapping = [data.get(key) for key in mapping_weights]\n",
        "            #print(weights_mapping)\n",
        "            weights_synthesis = [data.get(key) for key in synthesis_weights[weights_name]]\n",
        "            #print(weights_synthesis)\n",
        "            \n",
        "            self.mapping_network.set_weights(weights_mapping)\n",
        "            self.synthesis_network.set_weights(weights_synthesis)\n",
        "            \n",
        "            print(\"Loaded {} generator weights!\".format(weights_name))\n",
        "        else:\n",
        "            raise Exception('Cannot load {} weights'.format(weights_name))\n",
        "\n",
        "  def generate_and_plot_images_notrunc(gen, seed):\n",
        "    \"\"\" plot images from generator output \"\"\"\n",
        "    \n",
        "    fig, ax = plt.subplots(1,3,figsize=(15,15))\n",
        "    for i in range(3):\n",
        "    \n",
        "        # creating random latent vector\n",
        "        rnd = np.random.RandomState(seed)\n",
        "        z = rnd.randn(1, 512).astype('float32')\n",
        "\n",
        "        # running mapping network\n",
        "        dlatents = gen.mapping_network(z)\n",
        "        # adjusting dlatents depending on truncation psi, if truncatio_psi = 1, no adjust\n",
        "        #dlatents = w_avg + (dlatents - w_avg) * truncation_psi \n",
        "        # running synthesis network\n",
        "        out = gen.synthesis_network(dlatents)\n",
        "\n",
        "        #converting image/s to uint8\n",
        "        img = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "\n",
        "        #plotting images\n",
        "        ax[i].axis('off')\n",
        "        img_plot = ax[i].imshow(img.numpy()[0])\n",
        "        #plt.axis('off')\n",
        "        #plt.imshow(img.numpy()[0])\n",
        "        #plt.show()\n",
        "        seed += 1\n",
        "\n",
        "\n",
        "  weights_name = files_path[0][2]\n",
        "\n",
        "  from utils.weights_map import synthesis_weights_1024, synthesis_weights_512, synthesis_weights_256\n",
        "  from utils.weights_map import discriminator_weights_1024, discriminator_weights_512, discriminator_weights_256\n",
        "\n",
        "  available_weights = ['ffhq', 'car', 'cat', 'church', 'horse', \n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664',\n",
        "    'sg2_anime_network-snapshot-018528',\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480',\n",
        "    'sg2-ada_abstract_network-snapshot-000188']\n",
        "\n",
        "  synthesis_weights = {\n",
        "    'ffhq' : synthesis_weights_1024,\n",
        "    'car' : synthesis_weights_512,\n",
        "    'cat' : synthesis_weights_256,\n",
        "    'horse' : synthesis_weights_256,\n",
        "    'church' : synthesis_weights_256,\n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : synthesis_weights_512,\n",
        "    'sg2_anime_network-snapshot-018528' : synthesis_weights_512,\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : synthesis_weights_1024,\n",
        "    'sg2-ada_abstract_network-snapshot-000188' : synthesis_weights_512\n",
        "    }\n",
        "\n",
        "  discriminator_weights = {\n",
        "    'ffhq' : discriminator_weights_1024,\n",
        "    'car' : discriminator_weights_512,\n",
        "    'cat' : discriminator_weights_256,\n",
        "    'horse' : discriminator_weights_256,\n",
        "    'church' : discriminator_weights_256,\n",
        "    'sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664' : discriminator_weights_512,\n",
        "    'sg2_anime_network-snapshot-018528' : discriminator_weights_512,\n",
        "    'sg2-ext_aydao-anime-danbooru2019s-512-5268480' : discriminator_weights_1024,\n",
        "    'sg2-ada_abstract_network-snapshot-000188' : discriminator_weights_512\n",
        "    }\n",
        "\n",
        "  # instantiating generator network\n",
        "  generator = StyleGan2Generator(weights=weights_name, impl=impl, gpu=gpu)\n",
        "\n",
        "  # loading w average\n",
        "  #w_average = np.load('weights/{}_dlatent_avg.npy'.format(weights_name))\n",
        "\n",
        "if generate&gen_sg2_moono_tf2:\n",
        "  \n",
        "  import os\n",
        "  import numpy as np\n",
        "  import tensorflow as tf\n",
        "  from PIL import Image\n",
        "  from stylegan2.utils import postprocess_images\n",
        "  from load_models import load_generator\n",
        "  from copy_official_weights import convert_official_weights_together\n",
        "  \n",
        "  if True:\n",
        "    from tf_utils import allow_memory_growth\n",
        "\n",
        "    allow_memory_growth()\n",
        "\n",
        "    # common variables\n",
        "    ckpt_dir_base = './official-converted'\n",
        "\n",
        "    use_custom_cuda=True\n",
        "    # saving phase\n",
        "    #for use_custom_cuda in [True, False]:\n",
        "    #    ckpt_dir = os.path.join(ckpt_dir_base, 'cuda') if use_custom_cuda else os.path.join(ckpt_dir_base, 'ref')\n",
        "    #    convert_official_weights_together(ckpt_dir, use_custom_cuda)\n",
        "\n",
        "    # inference phase\n",
        "    ckpt_dir_cuda = os.path.join(ckpt_dir_base, 'cuda')\n",
        "    ckpt_dir_ref = os.path.join(ckpt_dir_base, 'ref')\n",
        "\n",
        "    g_clone = load_generator(g_params=None, is_g_clone=True, ckpt_dir=ckpt_dir_cuda, custom_cuda=use_custom_cuda)\n",
        "\n",
        "#if generate_stylegan2_tpu:\n",
        "#  tflib.init_tf()\n",
        "#  import pretrained_networks\n",
        "#  _G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
        "if generate&gen_stylegan2:\n",
        " if generate&gen_tf1:\n",
        "#if generate_stylegan2_ada or generate_stylegan2_ext:\n",
        "  import dnnlib\n",
        "  import dnnlib.tflib as tflib  \n",
        "  tflib.init_tf()\n",
        "  \n",
        "  import pickle\n",
        "  network_pkl=files_path[0][1]\n",
        "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
        " #       _G, _D, Gs = pickle.load(fp)\n",
        "  _G, _D, Gs = pickle.load(open(network_pkl, \"rb\"))\n",
        "\n",
        "  if generate&gen_tf2_npy:\n",
        "    import numpy as np\n",
        "    data = {}\n",
        "\n",
        "#    import pretrained_networks\n",
        "#    g, d, Gs_network = pretrained_networks.load_networks('/content/model/2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl')\n",
        "#    for key in  d.trainables.keys():\n",
        "#        data['disc_'+ key] = d.get_var(key)\n",
        "    #print(_G)\n",
        "    #print(_D)\n",
        "    #print(Gs)\n",
        "    \n",
        "    for key in  _G.trainables.keys():\n",
        "        data[key[key.find('/')+1:]] = _G.get_var(key)\n",
        "    #for key in  Gs.trainables.keys():\n",
        "    #    data[key[key.find('/')+1:]] = Gs.get_var(key)\n",
        "    #for key in  _G.trainables.keys():\n",
        "    #    data[key] = _G.get_var(key)\n",
        "    #for key in  Gs.trainables.keys():\n",
        "    #    data['gens_'+ key] = Gs.get_var(key)\n",
        "\n",
        "    for key in  _D.trainables.keys():\n",
        "        data['disc_'+ key] = _D.get_var(key)\n",
        "    np.save('/content/model/{}.npy'.format(files_path[0][2]), data, allow_pickle=True)\n",
        "    #from google.colab import files\n",
        "    #files.download('/content/model/{}.npy'.format(files_path[0][2]))\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    !cp -r -v \"/content/model/{files_path[0][2]}.npy\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video/models/{files_path[0][2]}.npy\"\n",
        "\n",
        "\n",
        "!mkdir '/content/out'\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Downloading 1aUrChOhq5jDEddZK1v_Dp1vYNlHSBL9o into /content/model/sg2-ada_2020-01-11-skylion-stylegan2-animeportraits-networksnapshot-024664.pkl... Done.\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.0)\n",
            "Requirement already satisfied: imageio==2.4.1 in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio==2.4.1) (7.1.2)\n",
            "Requirement already satisfied: imageio-ffmpeg==0.4.3 in /usr/local/lib/python3.7/dist-packages (0.4.3)\n",
            "Requirement already satisfied: pyspng==0.1.0 in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyspng==0.1.0) (1.19.5)\n",
            "mkdir: cannot create directory ‘/content/out’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhYyUwxJ1oxu"
      },
      "source": [
        "if generate&gen_sg2_nagolinc_pt:\n",
        "\n",
        "  import subprocess\n",
        "\n",
        "  CUDA_version = [s for s in subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"UTF-8\").split(\", \") if s.startswith(\"release\")][0].split(\" \")[-1]\n",
        "  print(\"CUDA version:\", CUDA_version)\n",
        "\n",
        "  if CUDA_version == \"10.0\":\n",
        "    torch_version_suffix = \"+cu100\"\n",
        "  elif CUDA_version == \"10.1\":\n",
        "    torch_version_suffix = \"+cu101\"\n",
        "  elif CUDA_version == \"10.2\":\n",
        "    torch_version_suffix = \"\"\n",
        "  else:\n",
        "    torch_version_suffix = \"+cu110\"\n",
        "\n",
        "  !pip install ninja\n",
        "\n",
        "  !pip install torch==1.7.1{torch_version_suffix} torchvision==0.8.2{torch_version_suffix} -f https://download.pytorch.org/whl/torch_stable.html ftfy regex\n",
        "\n",
        "  %cd /content/stylegan2-pytorch\n",
        "  from convert_weight import convertStyleGan2\n",
        "\n",
        "#conver the model from tf to torch\n",
        "  ckpt, g, disc,g_train = convertStyleGan2(_G,_D,Gs)#,style_dim=dim_sg2,max_channel_size=dim_sg2)\n",
        "  latent_avg=ckpt[\"latent_avg\"]\n",
        "\n",
        "  import torch\n",
        "\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  def fmtImg(r):\n",
        "    img = ((r+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
        "    return PIL.Image.fromarray(img, 'RGB')\n",
        "\n",
        "  device='cuda'\n",
        "  n_sample=1\n",
        "\n",
        "  g = g.to(device)\n",
        "\n",
        "  inputSize=1024#dim_sg2\n",
        "  import numpy as np\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrgaAwdJOkee"
      },
      "source": [
        "if generate&gen_sg2_ada_pt:\n",
        "\n",
        "  !pip install click requests tqdm pyspng ninja imageio-ffmpeg==0.4.3\n",
        "  !pip install torch==1.7.1\n",
        "#  %pip install ninja\n",
        "#  import pickle\n",
        "  import copy\n",
        "  import os\n",
        "  #from time import perf_counter\n",
        "\n",
        "  #import click\n",
        "  import imageio\n",
        "  import numpy as np\n",
        "  import PIL.Image\n",
        "  import torch\n",
        "  import torch.nn.functional as F\n",
        "\n",
        "  import dnnlib\n",
        "  import legacy\n",
        "  network_pkl=files_path[0][1]\n",
        "\n",
        "  device = torch.device('cuda')\n",
        "  with dnnlib.util.open_url(network_pkl) as fp:\n",
        "      G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUKP12wZTYT7"
      },
      "source": [
        "#generate_and_plot_images_notrunc(generator, seed=396)\n",
        "\n",
        "# not using truncation\n",
        "#generate_and_plot_images(generator, seed=96, w_avg=w_average)\n",
        "\n",
        "# using truncation 0.5\n",
        "#generate_and_plot_images(generator, seed=96, w_avg=w_average, truncation_psi=0.5)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrZhTCe5USvq"
      },
      "source": [
        "#def gen():\n",
        "#  global generator\n",
        "#  seed = 6600\n",
        "#  # creating random latent vector\n",
        "#  rnd = np.random.RandomState(seed)\n",
        "#  __z = rnd.randn(1, 512).astype('float32')\n",
        "#  # running mapping network\n",
        "#  dlatents = generator.mapping_network(__z)  \n",
        "# \n",
        "#  out = generator.synthesis_network(dlatents)\n",
        "#  #converting image/s to uint8\n",
        "#  images = convert_images_to_uint8(out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "#gen()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aA95OcEv5YU"
      },
      "source": [
        "if generate&gen_wavegan:\n",
        " if generate&gen_drums:\n",
        "  # Load the model\n",
        "  tf.reset_default_graph()\n",
        "  saver = tf.train.import_meta_graph('/content/model/infer/infer.meta')\n",
        "  graph = tf.get_default_graph()\n",
        "  sess = tf.InteractiveSession()\n",
        "  sess.close()\n",
        "  sess = tf.InteractiveSession()\n",
        "  saver.restore(sess, f'/content/model/model.ckpt-18637')\n",
        "  #dim = 100\n",
        "  break_len = 65536\n",
        "\n",
        "  z = graph.get_tensor_by_name('z:0')\n",
        "  G_z = graph.get_tensor_by_name('G_z:0')\n",
        "\n",
        "  import numpy as np\n",
        "  from IPython.display import display, Audio\n",
        "  #from google.colab import files\n",
        "  import scipy.io.wavfile\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "  !mkdir \"./neuralfunk examples\"\n",
        "\n",
        "  def generate_trajectory(n_iter, _z0=None, mov_last=None, jump=0.3, smooth=0.3, include_z0=True):\n",
        "    _z = np.empty((n_iter + int(not include_z0), dim))\n",
        "    _z[0] = _z0 if _z0 is not None else np.random.random(dim)*2-1\n",
        "    mov = mov_last if mov_last is not None else (np.random.random(dim)*2-1)*jump\n",
        "    for i in range(1, len(_z)):\n",
        "        mov = mov*smooth + (np.random.random(dim)*2-1)*jump*(1-smooth)\n",
        "        mov -= (np.abs(_z[i-1] + mov) > 1) * 2 * mov\n",
        "        _z[i] = _z[i-1] + mov\n",
        "    return _z[-n_iter:], mov  \n",
        "  !pip install pydub\n",
        "  from pydub import AudioSegment"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lt3tZX8iYM1",
        "outputId": "3a06e1b7-f29d-4eff-8bee-a8cf8d17f479"
      },
      "source": [
        "!pip install mne\n",
        "\n",
        "import mne\n",
        "from mne import io\n",
        "from mne.datasets import sample\n",
        "from mne.minimum_norm import read_inverse_operator, compute_source_psd\n",
        "\n",
        "from mne.connectivity import spectral_connectivity, seed_target_indices\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "FwhsStNzSHeW",
        "outputId": "5cf8a939-7a4a-4226-a7cc-3ca124798fc6"
      },
      "source": [
        "sfreq = 512 \n",
        "#ch_types=['eeg']*len(ch_names)\n",
        "#info = mne.create_info(ch_names = ch_names, sfreq = sfreq, ch_types=ch_types)\n",
        "ch_types_wg=['eeg']*len(ch_names_wg)\n",
        "info_wg = mne.create_info(ch_names = ch_names_wg, sfreq = sfreq, ch_types=ch_types_wg)\n",
        "ch_types_sg2=['eeg']*len(ch_names_sg2)\n",
        "info_sg2 = mne.create_info(ch_names = ch_names_sg2, sfreq = sfreq, ch_types=ch_types_sg2)\n",
        " \n",
        "#label_names = ch_names\n",
        "#no_names = [''] * len(label_names)\n",
        " \n",
        "from IPython.display import Javascript\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Javascript\n",
        "import json\n",
        "data_read=False\n",
        " \n",
        "import base64\n",
        "from io import BytesIO\n",
        " \n",
        "data_read=None\n",
        "data_buffer=None\n",
        "data_analyse=None\n",
        "\n",
        "from time import perf_counter\n",
        "time100=perf_counter()\n",
        "time_dir=f'{(time100*1000):9.0f}'\n",
        "#%mkdir '/content/gdrive/MyDrive/EEG-GAN-audio-video/out/{time_dir}'\n",
        "\n",
        "if generate&gen_stylegan2:#_ada or generate_stylegan2_ext:\n",
        "  from IPython.display import Image\n",
        "  import matplotlib.figure\n",
        "  import imageio\n",
        "  #fps=3\n",
        "  #video_out = imageio.get_writer('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+time_dir+'/output.mp4', mode='I', fps=fps_sg2, codec='libx264', bitrate='16M')\n",
        " \n",
        "  js_image = \"\"\n",
        "  from PIL import ImageFont, ImageDraw\n",
        " \n",
        "  if generate&gen_sg2_rosasalberto_tf2:\n",
        "    __z = None\n",
        "    dlatents = None\n",
        "  if generate&gen_sg2_moono_tf2:\n",
        "    seed = 6600\n",
        "    rnd = np.random.RandomState(seed)\n",
        "    latents = rnd.randn(1, g_clone.z_dim)\n",
        "    labels = rnd.randn(1, g_clone.labels_dim)\n",
        "    latents = latents.astype(np.float32)\n",
        "    labels = labels.astype(np.float32)\n",
        "    #print([latents, labels])\n",
        "    #image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
        "    #Gs_kwargs.randomize_noise = False\n",
        "    #image_out = postprocess_images(image_out)\n",
        "    #image_out = image_out.numpy()\n",
        "    #print(image_out)\n",
        "  if generate&gen_sg2_nagolinc_pt:\n",
        "    __z1 = None\n",
        "  if generate&gen_sg2_ada_pt:\n",
        "    ws=None\n",
        "  if generate&gen_sg2_shawwn:\n",
        "    Gs_kwargs = dnnlib.EasyDict()\n",
        "    Gs_kwargs.randomize_noise = False\n",
        "    _z1 = None\n",
        "  elif generate&gen_tf1:\n",
        "   Gs_kwargs = dnnlib.EasyDict()\n",
        "   #Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=False)\n",
        "   Gs_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "   Gs_kwargs.randomize_noise = False\n",
        "   _z1 = None\n",
        " \n",
        "if generate&gen_wavegan:\n",
        "  _G_z = None\n",
        "  _G_z_full = None\n",
        "  _G_z_full2 = None\n",
        "  _z = None\n",
        " \n",
        "samples=0\n",
        " \n",
        "last_frame_wg=-1\n",
        "last_frame_sg2=-1\n",
        "time111=perf_counter()\n",
        " \n",
        "last_time=0\n",
        "def target_func1(comm, msg):\n",
        "  time000=perf_counter()\n",
        "  #import dnnlib \n",
        "  #import dnnlib.tflib as tflib \n",
        "  #import PIL.Image \n",
        "  #from tqdm import tqdm\n",
        "  ##global _G, _D, Gs\n",
        "  #tflib.init_tf()\n",
        "  #with dnnlib.util.open_url(network_pkl) as fp:\n",
        "  #   _G, _D, Gs = pickle.load(fp)\n",
        " \n",
        "  # Only send the response if it's the data we are expecting.\n",
        "  #if msg['content']['data'] == 'the data':\n",
        "  #  comm.send({\n",
        "  #        'response': 'got comm open!',\n",
        "  #      }, None, msg['buffers']);\n",
        "  #  print(msg['buffers'])\n",
        "  #else:\n",
        "    #print(msg['content']['data'])\n",
        "    #data_read=True\n",
        "  global last_time\n",
        "  global time100\n",
        "  global samples\n",
        "  #array_to_receive_as_json = '[[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0],[0]]'\n",
        "  array_to_receive_as_json = msg['content']['data']\n",
        "  #global data_read\n",
        "  data_read = json.loads(array_to_receive_as_json)\n",
        "  #print('got data')\n",
        "  #print(data_read)\n",
        "  new_data_len=len(data_read[0])\n",
        "  #print(new_data_len)\n",
        "  samples=samples+new_data_len#len(data_analyse[0])\n",
        "  time110=perf_counter()\n",
        "  out_text=f'{(samples):7.0f}'+' sam, '\n",
        "  out_text=out_text+f'{(new_data_len):4.0f}'+\" sam/pac, \"\n",
        "  out_text=out_text+f'{(time110-time100):7.2f}'+\" sec, \"\n",
        "  out_text=out_text+f'{(samples/(time110-time100)):7.2f}'+' sam/sec'\n",
        "  out_text=out_text+f'{(time110-time100)-last_time:7.2f}'+\" sec, \"\n",
        "  out_text=out_text+f'{(new_data_len/((time110-time100)-last_time)):7.2f}'+' sam/sec'\n",
        "  last_time=(time110-time100)\n",
        "  #comm.send({\n",
        "  #        'response': out_text,\n",
        "  #      }, None, msg['buffers']);\n",
        "  #print(out_text)\n",
        "  global ch_locations,bands,duration,overlap,methods,uVperStep,sfreq,dim_sg2,dim_wg\n",
        "  global ch_names_wg, info_wg, ch_names_sg2, info_sg2\n",
        "  #global label_names,ch_locations,info,bands,duration,overlap,methods,uVperStep,sfreq,dim_sg2,dim_wg\n",
        "  #print(duration)\n",
        "  send_wg=False\n",
        "  send_sg2=False\n",
        "  \n",
        "  if not (data_read is None):\n",
        "      #print('read_data-data_read')\n",
        "      #print(len(data_read[0]))\n",
        "      global data_buffer, data_analyse\n",
        "      if data_buffer is None:\n",
        "        data_buffer=data_read\n",
        "      else:\n",
        "        data_buffer=np.concatenate((data_buffer,data_read),axis=1)\n",
        "      data_read = None\n",
        " \n",
        "      data_buffer_len=len(data_buffer[0])\n",
        "      #print(data_buffer_len)\n",
        "      #if (int(duration*sfreq)+1)>(int(sfreq/fps)):\n",
        "      if True:\n",
        "        data_slice_len=int(duration*sfreq)+1\n",
        "      #else:\n",
        "      #  data_slice_len=int(sfreq/fps)+1\n",
        "      #print(data_slice_len)\n",
        "      if data_buffer_len>data_slice_len:\n",
        "        data_buffer=data_buffer[0:len(data_buffer),data_buffer_len-data_slice_len:data_buffer_len]\n",
        "      #print(len(data_buffer[0]))\n",
        "      #print(data_slice_len)\n",
        "      data_analyse=None\n",
        "      if len(data_buffer[0])==data_slice_len:\n",
        "       global last_frame_sg2, fps_sg2\n",
        "       global last_frame_wg, fps_wg\n",
        "       if generate&gen_wavegan: \n",
        "        this_frame_wg=int((time000-time100)*fps_wg+1/(2*fps_sg2/fps_wg))\n",
        "        if this_frame_wg>last_frame_wg:\n",
        "          data_analyse=data_buffer\n",
        "          last_frame_wg=this_frame_wg\n",
        "          send_wg=True\n",
        "          #print(f'{(time000-time100)*fps_wg:7.2f}'+\" frame wavegan\")\n",
        "       if generate&gen_stylegan2:   \n",
        "        #global last_frame_sg2, fps_sg2\n",
        "        this_frame_sg2=int((time000-time100)*fps_sg2)\n",
        "        if this_frame_sg2>last_frame_sg2:\n",
        "          #if not send_wg:\n",
        "          data_analyse=data_buffer\n",
        "          last_frame_sg2=this_frame_sg2\n",
        "          send_sg2=True\n",
        "          #print(f'{(time000-time100)*fps_sg2:7.2f}'+\" frame stylegan2\")\n",
        "      #data_buffer=data_analyse\n",
        "      #print('read_data-data_analyse')\n",
        "      #print(len(data_analyse[0]))\n",
        "  \n",
        "  #if False: \n",
        "  #if True: \n",
        "  if not(data_analyse is None):\n",
        "    #if (time111-time000)>=(1/fps):\n",
        "      time111=perf_counter()\n",
        "      if send_wg:\n",
        "        ch_names=ch_names_wg\n",
        "        ch_locations=ch_locations_wg\n",
        "        info=info_wg\n",
        "      elif send_sg2:\n",
        "        ch_names=ch_names_sg2\n",
        "        ch_locations=ch_locations_sg2\n",
        "        info=info_sg2\n",
        "      data_uv = [0]*len(ch_names)\n",
        "      for j in range(len(ch_names)):\n",
        "        data_uv[j]=[0]*len(data_analyse[ch_locations[j]])\n",
        "        for i in range(len(data_analyse[ch_locations[j]])):\n",
        "          data_uv[j][i] = data_analyse[ch_locations[j]][i] * uVperStep * 2\n",
        "      data_analyse=None\n",
        "  \n",
        "      time002=perf_counter()\n",
        "      #print (f'002: {(time002-time000):.1f}s')\n",
        "\n",
        "      raw = mne.io.RawArray(data_uv, info, verbose=50)\n",
        "      time003=perf_counter()\n",
        "      #print (f'003: {(time003-time000):.1f}s')\n",
        "      datas=[]\n",
        "      for band in range(len(bands)):\n",
        "        datas.append(raw)\n",
        "      time004=perf_counter()\n",
        "      epochs = []\n",
        "      #print (f'004: {(time004-time000):.1f}s')\n",
        "      for band in range(len(bands)):\n",
        "        epochs.append(mne.make_fixed_length_epochs(datas[band], duration=duration/2, preload=True, overlap=overlap, verbose=50))\n",
        "      time005=perf_counter()\n",
        "      #print (f'005: {(time005-time000):.1f}s')\n",
        "      n_generate=int((float(len(data_uv[0]))/float(sfreq))/duration)\n",
        "      n_generate=1\n",
        "      part_len = 10\n",
        "      #dim = 512\n",
        "      part_len = 1\n",
        " \n",
        "      n_parts = n_generate//part_len\n",
        "      if n_generate%part_len>0:\n",
        "        n_parts=n_parts+1\n",
        "      n_parts=1\n",
        "      global vol\n",
        "    \n",
        "      if generate&gen_wavegan:\n",
        "        psd_array_wg=np.random.rand(part_len, dim_wg) \n",
        "      if generate&gen_stylegan2:\n",
        "        psd_array_sg2=np.random.rand(part_len, dim_sg2) \n",
        "      time006=perf_counter()\n",
        "      #print (f'006: {(time006-time000):.1f}s')\n",
        "    \n",
        "      for j in range(n_parts): # display separate audio for each break\n",
        "        for i in range(part_len): # display separate audio for each break\n",
        "            ji = j * part_len + i\n",
        "            \n",
        "            if (i==0) and (n_generate-ji<part_len):\n",
        "              if generate&gen_wavegan:\n",
        "                psd_array_wg=np.random.rand((n_generate-ji), dim_wg) \n",
        "              if generate&gen_stylegan2:\n",
        "                psd_array_sg2=np.random.rand((n_generate-ji), dim_sg2) \n",
        "        \n",
        "            sfreq = raw.info['sfreq']  # the sampling frequency\n",
        "            time0061=perf_counter()\n",
        "            #print (f'0061: {(time0061-time000):.1f}s')\n",
        "            \n",
        "            if generate&gen_wavegan:# and send_wg:\n",
        "              psds_wg=np.zeros(dim_wg)\n",
        "            if generate&gen_stylegan2:\n",
        "              psds_sg2=np.zeros(dim_sg2)\n",
        "            \n",
        "            for method in range(len(methods)):\n",
        "             for band in range(len(bands)):\n",
        "              fmin=bands[band][0]\n",
        "              fmax=bands[band][1]\n",
        "              time0071=perf_counter()\n",
        "              #print (f'0071: {(time0071-time000):.1f}s')\n",
        "              #if band == 0:\n",
        "              #print(epochs[band])\n",
        "              con, freqs, times, n_epochs, n_tapers = spectral_connectivity(\n",
        "                epochs[band], method=methods[method], mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "                #epochs[band][ji:ji+1], method=methods[method], mode='multitaper', sfreq=sfreq, fmin=fmin,\n",
        "                fmax=fmax, faverage=True, mt_adaptive=True, n_jobs=1, verbose=50)\n",
        "              time007=perf_counter()\n",
        "              #print (f'007: {(time007-time000):.1f}s')\n",
        "              coh_len=int(len(ch_names)*(len(ch_names)-1)/2)\n",
        "              psds_shift1=int(round(method*len(bands)+band)*coh_len)\n",
        "              ji1=0\n",
        "              for j1 in range(0,len(ch_names)): # display separate audio for each break\n",
        "                for i1 in range(0,j1): # display separate audio for each break\n",
        "                  #print(ji1)\n",
        "                  if generate&gen_wavegan:\n",
        "                   if ji1+psds_shift1<dim_wg:\n",
        "                    psds_wg[ji1+psds_shift1]=(con[j1][i1][0]-0.5)*1\n",
        "                  if generate&gen_stylegan2:\n",
        "                   for i01 in range(0,int(dim_sg2/coh_len)):\n",
        "                     if ji1+psds_shift1+coh_len*i01<dim_sg2:\n",
        "                      #print(ji1+psds_shift1+coh_len*i01)\n",
        "                      psds_sg2[ji1+psds_shift1+coh_len*i01]=(con[j1][i1][0]-0.5)*1\n",
        "                  ji1 = ji1+1\n",
        "            if generate&gen_wavegan:\n",
        "              psd_array_wg[i]=psds_wg\n",
        "            if generate&gen_stylegan2:\n",
        "              psd_array_sg2[i]=psds_sg2\n",
        "            if (i==part_len-1) or (ji==n_generate-1) :\n",
        "             encodeds=[]\n",
        "             #print('encodeds=[]')\n",
        "             if generate&gen_wavegan:\n",
        "               if send_wg:\n",
        "                global G_z, z, _G_z, _G_z_full, _G_z_full2#, _z\n",
        "                _z = psd_array_wg * vol\n",
        "                #print('>>sess.run')\n",
        "                _G_z = sess.run(G_z, {z: _z})[:,:,0]\n",
        "                #print('<<sess.run')\n",
        "                if j==0:\n",
        "                  _G_z_full=_G_z\n",
        "                else:\n",
        "                  _G_z_full=np.append(_G_z_full,_G_z)\n",
        "                #if _G_z_full2 is None:\n",
        "                #  _G_z_full2=_G_z_full\n",
        "                #else:\n",
        "                #  _G_z_full2=np.append(_G_z_full2,_G_z_full)\n",
        "                                    \n",
        "                if (ji==n_generate-1) :\n",
        " \n",
        "                    buffer = BytesIO()\n",
        "                    if generate&gen_mp3:\n",
        "                      buffer_wav = BytesIO()\n",
        "                      scipy.io.wavfile.write(buffer_wav, hz, _G_z_full.flatten()) # change rate for different tempo\n",
        "                      AudioSegment.from_wav(buffer_wav).export(buffer, format=\"mp3\")\n",
        "                    if generate&gen_wav:\n",
        "                      scipy.io.wavfile.write(buffer, hz, _G_z_full.flatten()) # change rate for different tempo\n",
        "                    \n",
        "                    #wave.open(buffer, mode='wb')\n",
        "                    #AudioSegment.from_wav(buffer).export('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+\n",
        "                    #               f'{(time100*1000):9.0f}'+'/'+f'{(time000*1000):9.0f}'+'.mp3', format=\"mp3\")\n",
        " \n",
        "                    buffer.seek(0)\n",
        "                    mysound = buffer.getvalue()\n",
        "                    if generate&gen_mp3:\n",
        "                      encoded= \"data:audio/mp3;base64,\"+base64.b64encode(mysound).decode()\n",
        "                    if generate&gen_wav:\n",
        "                      encoded= \"data:audio/wav;base64,\"+base64.b64encode(mysound).decode()\n",
        "                    #print('audio encoded')\n",
        " \n",
        "                    time110=perf_counter()\n",
        "                    #print (f'110: {(time110-time000):.1f}s')\n",
        "                    #js_image=js\n",
        "                    #encodeds.append(encoded)\n",
        "                    comm.send({\n",
        "                      'response': encoded,\n",
        "                      }, None, msg['buffers']);\n",
        "                    #break\n",
        "    \n",
        "                  #encoded = base64.b64encode(image_asarray).decode('ascii')\n",
        "                  #js='''this.photo.src = \"data:image/png;base64,{0}\"'''.format(encoded)\n",
        " \n",
        "                  \n",
        "                  #js='''senderChannel.postMessage(\"{0}\")'''.format(encoded)\n",
        "                    #js='''playAudio1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
        "                    #js_image=js\n",
        "             if generate&gen_stylegan2:\n",
        "              if send_sg2:#_ada or generate_stylegan2_ext:\n",
        "               if generate&gen_sg2_rosasalberto_tf2:\n",
        "                global generator, dlatents, __z\n",
        " \n",
        "                #seed = 6600\n",
        "                # creating random latent vector\n",
        "                #rnd = np.random.RandomState(seed)\n",
        "                #__z = rnd.randn(1, 512).astype('float32')\n",
        "                # running mapping network\n",
        "                time1101=perf_counter()\n",
        "                #print (f'1101: {(time1101-time000):.1f}s')\n",
        "                #dlatents = generator.mapping_network(__z)  \n",
        "                time1102=perf_counter()\n",
        "                #print (f'1102: {(time1102-time000):.1f}s')\n",
        " \n",
        "                __z = psd_array_sg2 * vol\n",
        "                dlatents = generator.mapping_network(__z)\n",
        "                time1103=perf_counter()\n",
        "                #print (f'1103: {(time1103-time000):.1f}s')\n",
        "                image_out = generator.synthesis_network(dlatents)\n",
        "                time1104=perf_counter()\n",
        "                #print (f'1104: {(time1104-time000):.1f}s')\n",
        "                #converting image/s to uint8\n",
        "                img = convert_images_to_uint8(image_out, nchw_to_nhwc=True, uint8_cast=True)\n",
        "                #plotting images\n",
        "                #ax[i].axis('off')\n",
        "                #img_plot = ax[i].imshow(img.numpy()[0])   \n",
        "                time1105=perf_counter()\n",
        "                #print (f'1105: {(time1105-time000):.1f}s')\n",
        "                #images=[img.numpy()[0]]\n",
        "                images=img.numpy()\n",
        "               elif generate&gen_sg2_moono_tf2:\n",
        "                 global g_clone, latents, labels\n",
        "                 latents = psd_array_sg2 * vol\n",
        "                 image_out = g_clone([latents, labels], training=False, truncation_psi=0.5)\n",
        "                 image_out = postprocess_images(image_out)\n",
        "                 image = image_out.numpy()\n",
        "               elif generate&gen_sg2_nagolinc_pt:\n",
        "                global device, __z1, g, latent_avg\n",
        "                __z1 = psd_array_sg2 * vol\n",
        "                with torch.no_grad():\n",
        "                  img_pt, _ = g(\n",
        "                    [torch.from_numpy(np.float32(__z1)).to(device)],\n",
        "                    truncation=0.5,\n",
        "                    truncation_latent=latent_avg.to(device),\n",
        "                    randomize_noise=False,\n",
        "                  )\n",
        "                images=img_pt.cpu().numpy()\n",
        "               elif generate&gen_sg2_ada_pt:\n",
        "                global G, ws#, device\n",
        "                device = torch.device('cuda')\n",
        " \n",
        "                z_samples = psd_array_sg2 * vol\n",
        "                w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
        "                w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
        "                w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
        "                w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
        "                ws = (w_opt).repeat([1, G.mapping.num_ws, 1])\n",
        " \n",
        "                synth_images = G.synthesis(ws, noise_mode='const')\n",
        "                synth_images = (synth_images + 1) * (255/2)\n",
        "                synth_images = synth_images.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
        "                #out.append_data(synth_images)\n",
        "                images=[synth_images]\n",
        "               elif generate&gen_tf1:\n",
        "                global _G, _D, Gs, Gs_kwargs, _z1\n",
        "                _z1 = psd_array_sg2 * vol\n",
        "                time1101=perf_counter()\n",
        "                #print (f'1101: {(time1101-time000):.1f}s')\n",
        "                #print('>>Gs.run')\n",
        "                images = Gs.run(_z1, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "                #print('<<Gs.run')\n",
        "                time1102=perf_counter()\n",
        "                #print (f'1102: {(time1102-time000):.1f}s')\n",
        "                #if generate&gen_sg2_shawwn:\n",
        "                #  n_sample=1\n",
        "                #  inputSize=1024\n",
        "                #  z = np.random.randn(n_sample, inputSize).astype(\"float32\")\n",
        "                #  images = Gs.run(z, None, **Gs_kwargs) # [minibatch, height, width, channel]\n",
        "\n",
        "               if True:\n",
        "                for image in images:\n",
        "                  time1110=perf_counter()\n",
        "                  #print (f'1110: {(time1110-time000):.1f}s')\n",
        "                  #print(image)\n",
        "                  if generate&gen_sg2_nagolinc_pt:\n",
        "                    image = ((image+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
        "                  elif generate&gen_sg2_shawwn:\n",
        "                    image = ((image+1)/2*256).clip(0,255).astype(np.uint8).transpose(1,2,0)\n",
        "                  #if generate_stylega2_ada_pytorch:\n",
        " \n",
        "                  image_pil=PIL.Image.fromarray(image, 'RGB')\n",
        "                  #if generate&gen_sg2_shawwn:\n",
        "                  #  display(image_pil)\n",
        "                  #print(image_pil)\n",
        "                  image_asarray=np.asarray(image_pil)\n",
        "                  #print(image_asarray)\n",
        "                  time1111=perf_counter()\n",
        "                  #print (f'1111: {(time1111-time000):.1f}s')\n",
        "                  #global video_out\n",
        "                  #video_out.append_data(image_asarray)\n",
        "                  time1112=perf_counter()\n",
        "                  #print (f'1112: {(time1112-time000):.1f}s')\n",
        "                  img=image_pil.resize((xsize,ysize),PIL.Image.ANTIALIAS)\n",
        "                  #print(img)\n",
        "                  time1113=perf_counter()\n",
        "                  #print (f'1113: {(time1113-time000):.1f}s')\n",
        "                  buffer = BytesIO()\n",
        "                  if generate&gen_jpeg:\n",
        "                    img.save(buffer,format=\"JPEG\")                  #Enregistre l'image dans le buffer\n",
        "                  if generate&gen_png:\n",
        "                    img.save(buffer,format=\"PNG\")                  #Enregistre l'image dans le buffer\n",
        "                  #img.save('/content/gdrive/MyDrive/EEG-GAN-audio-video/out/'+\n",
        "                  #          f'{(time100*1000):9.0f}'+'/'+f'{(time000*1000):9.0f}'+'.png',format=\"PNG\")\n",
        "\n",
        " \n",
        "                  buffer.seek(0)\n",
        "                  time1114=perf_counter()\n",
        "                  #print (f'1114: {(time1114-time000):.1f}s')\n",
        "                  myimage = buffer.getvalue()   \n",
        "                  #encoded=myimage\n",
        "                  if generate&gen_jpeg:\n",
        "                    encoded= \"data:image/jpeg;base64,\"+base64.b64encode(myimage).decode()\n",
        "                  if generate&gen_png:\n",
        "                    encoded= \"data:image/png;base64,\"+base64.b64encode(myimage).decode()\n",
        "                  #print('image encoded')\n",
        "                  js='''displayPhoto1(\"{0}\",{1},{2})'''.format(encoded,xsize,ysize)\n",
        "                if (ji==n_generate-1) :\n",
        "                    time110=perf_counter()\n",
        "                    #print (f'110: {(time110-time000):.1f}s')\n",
        "                    #js_image=js\n",
        "                    #print('>>encodeds.append(encoded)')\n",
        "                    #encodeds.append(encoded)\n",
        "                    #print('<<encodeds.append(encoded)')\n",
        "                    comm.send({\n",
        "                      'response': encoded,\n",
        "                      }, None, msg['buffers']);\n",
        "                    #print('image sent')\n",
        "                    #break\n",
        "              #print('audio&image send')\n",
        "              #comm.send({\n",
        "              #  'response': 'close',\n",
        "                #'response': json.dumps(encodeds),\n",
        "              #}, None, msg['buffers']);\n",
        "              #break\n",
        " \n",
        "    #if not(js_image==\"\"):\n",
        "    #  js=js_image\n",
        "    #  js_image=\"\"\n",
        "    #  eval_js(js)\n",
        "#      if True:\n",
        "      if False:\n",
        "                    time111=perf_counter()\n",
        "                    print (f'000: {(time111-time000):.1f}s, '+\n",
        "                      f'001: {(time111-time001):.1f}s, '+\n",
        "                      f'110: {(time111-time110):.1f}s, '+\n",
        "                      f'001-000: {(time001-time000):.1f}s, {(time001-time000)*100/(time111-time000):.0f}%, '+\n",
        "                      f'110-001: {(time110-time001):.1f}s, {(time110-time001)*100/(time111-time000):.0f}%. '+\n",
        "                      f'111-110: {(time111-time110):.1f}s, {(time111-time110)*100/(time111-time000):.0f}%')\n",
        " \n",
        "  if False:\n",
        "    comm.send({\n",
        "      'response': 'close',\n",
        "      #'response': json.dumps(encodeds),\n",
        "      }, None, msg['buffers']);\n",
        " \n",
        "data_read=False\n",
        "get_ipython().kernel.comm_manager.register_target('comm_target1', target_func1)\n",
        "#target_func1('{1}','{1}')\n",
        "#for i in range(100):\n",
        "#  get_ipython().kernel.comm_manager.register_target(str(i), target_func1)\n",
        " \n",
        "Javascript('''\n",
        "//Joshua Brewster, GPL (copyleft)\n",
        " \n",
        "//import 'regenerator-runtime/runtime' //For async functions on node\\\\\n",
        " \n",
        " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
        " \n",
        "    constructor(\n",
        "        onDecodedCallback = this.onDecodedCallback,\n",
        "        onConnectedCallback = this.onConnectedCallback,\n",
        "        onDisconnectedCallback = this.onDisconnectedCallback,\n",
        "        CustomDecoder = this.decode,\n",
        "        baudrate = 921600//115200\n",
        "        ) {\n",
        " \n",
        "        this.onDecodedCallback = onDecodedCallback;\n",
        "        this.onConnectedCallback = onConnectedCallback;\n",
        "        this.onDisconnectedCallback = onDisconnectedCallback;\n",
        "        this.decode = CustomDecoder;\n",
        "        //Free EEG 32 data structure:\n",
        "        \n",
        "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
        "        //    Total = 105 bytes/line\n",
        "        \n",
        "        this.connected = false;\n",
        "        this.subscribed = false;\n",
        "        this.buffer = [];\n",
        "        this.startByte = 160; // Start byte value\n",
        "        this.stopByte = 192; // Stop byte value\n",
        "        this.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
        "        this.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
        "        this.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
        " \n",
        "        this.sps = 512; // Sample rate\n",
        "        this.nChannels = 32;\n",
        "        this.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
        "        this.updateMs = 1000/this.sps; //even spacing\n",
        "        this.stepSize = 1/Math.pow(2,24);\n",
        "        this.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
        "        this.gain = 8;\n",
        " \n",
        "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
        "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
        "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
        " \n",
        "        this.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
        "        \n",
        "        this.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
        "            count: 0,\n",
        "            startms: 0,\n",
        "            ms: [],\n",
        "            'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
        "            'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
        "            'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
        "            'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
        "            'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
        "        };\n",
        " \n",
        "    this.bufferednewLines = 0;\n",
        "    this.data_slice=[];\n",
        "    this.data_slice_size=512*(5*1/8+0.1);\n",
        "    this.ready_to_send_data = false;\n",
        "    this.data_send_count=0;\n",
        "\n",
        "    this.xsize=%(xsize)d;\n",
        "    this.ysize=%(ysize)d;\n",
        "\n",
        "    this.generate_stylegan2=true;\n",
        "    this.generate_stylegan2=%(generate_stylegan2)d;\n",
        "    \n",
        "    //this.generate_stylegan2=false;\n",
        "    this.generate_wavegan=true;\n",
        "    this.generate_wavegan=%(generate_wavegan)d;\n",
        "    this.generate_heatmap=true;\n",
        "    this.generate_heatmap=%(generate_heatmap)d;\n",
        "    //data:audio/wav;base64,\n",
        "    //data:image/jpeg;base64,\n",
        "    this.time100=Date.now();\n",
        "    this.time000=Date.now();\n",
        "    this.this_frame_wg=-1;\n",
        "    this.last_frame_wg=-1;\n",
        "    this.send_wg=false;\n",
        "    this.this_frame_sg2=-1;\n",
        "    this.last_frame_sg2=-1;\n",
        "    this.send_sg2=false;\n",
        "\n",
        "    if(this.generate_stylegan2)\n",
        "    {\n",
        "      this.fps_sg2=1;\n",
        "    }\n",
        "    if(this.generate_wavegan)\n",
        "    {\n",
        "      this.hz=44100;\n",
        "      this.fps_wg=this.hz/(32768*2);\n",
        "      //this.fps=this.hz/(32768);\n",
        "    }\n",
        "      this.fps_sg2=this.fps_wg;\n",
        "      this.fps_wg=%(fps_wg)f;\n",
        "      this.fps_sg2=%(fps_sg2)f;\n",
        "      this.fps_hm=%(fps_hm)f;\n",
        "    this.samples_count=0;\n",
        "    //this.channel=None;\n",
        " \n",
        "        this.resetDataBuffers();\n",
        " \n",
        "        //navigator.serial utils\n",
        "        if(!navigator.serial){\n",
        "            console.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
        "        }\n",
        "        this.port = null;\n",
        "        this.reader = null;\n",
        "        this.baudrate = baudrate;\n",
        " \n",
        "    }\n",
        "    \n",
        "    resetDataBuffers(){\n",
        "        this.data.count = 0;\n",
        "        this.data.startms = 0;\n",
        "        for(const prop in this.data) {\n",
        "            if(typeof this.data[prop] === \"object\"){\n",
        "                this.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
        "            }\n",
        "        }\n",
        "    }\n",
        " \n",
        "    setScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
        "        this.stepSize = stepSize;\n",
        "        this.vref = vref; //2.5V voltage ref +/- 250nV\n",
        "        this.gain = gain;\n",
        " \n",
        "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
        "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
        "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
        "    }\n",
        " \n",
        "    getLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
        "        let ct = count;\n",
        "        if(ct <= 1) {\n",
        "            return [this.data[channel][this.data.count-1]];\n",
        "        }\n",
        "        else {\n",
        "            if(ct > this.data.count) {\n",
        "                ct = this.data.count;\n",
        "            }\n",
        "            return this.data[channel].slice(this.data.count-ct,this.data.count);\n",
        "        }\n",
        "    }\n",
        " \n",
        "    bytesToInt16(x0,x1){\n",
        "        return x0 * 256 + x1;\n",
        "    }\n",
        " \n",
        "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
        "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
        "    }\n",
        " \n",
        "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
        "        return x0 * 65536 + x1 * 256 + x2;\n",
        "    }\n",
        " \n",
        "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
        "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
        "    }\n",
        " \n",
        "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
        " \n",
        "        var needle = this.searchString\n",
        "        var haystack = buffer;\n",
        "        var search = this.boyerMoore(needle);\n",
        "        var skip = search.byteLength;\n",
        "        var indices = [];\n",
        "        let newLines = 0;\n",
        "    \n",
        "        for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
        "            indices.push(i);\n",
        "        }\n",
        "        //console.log(indices);\n",
        "        if(indices.length >= 2){\n",
        "            for(let k = 1; k < indices.length; k++) {\n",
        "                if(indices[k] - indices[k-1] !== 105) {\n",
        "                    \n",
        "                } //This is not a valid sequence going by size, drop sequence and return\n",
        "                else {\n",
        "                    var line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
        "                    \n",
        "                    // line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
        " \n",
        "                    //line found, decode.\n",
        "                    if(this.data.count < this.maxBufferedSamples){\n",
        "                        this.data.count++;\n",
        "                    }\n",
        " \n",
        "                    if(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
        "                    else {\n",
        "                        this.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
        "                        \n",
        "                        if(this.data.count >= this.maxBufferedSamples) {\n",
        "                            this.data.ms.splice(0,5120);\n",
        "                            this.data.ms.push(new Array(5120).fill(0));\n",
        "                        }\n",
        "                    }//Assume no dropped samples\n",
        "                  var sample_count = line[2];\n",
        "                  var sample_count_diff = sample_count-this.samples_count;\n",
        "          if(sample_count_diff<0){\n",
        "            sample_count_diff+=256;\n",
        "          }\n",
        "          if(sample_count_diff!=1)\n",
        "          {\n",
        "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
        "          }\n",
        "          this.samples_count=sample_count;\n",
        " \n",
        "                    for(var i = 3; i < 99; i+=3) {\n",
        "                        var channel = \"A\"+(i-3)/3;\n",
        "                        this.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
        "                        if(this.data.count >= this.maxBufferedSamples) { \n",
        "                            this.data[channel].splice(0,5120);\n",
        "                            this.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
        "                        }\n",
        "                            //console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
        "                    }\n",
        " \n",
        "                    this.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
        "                    this.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
        "                    this.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
        " \n",
        "                    \n",
        "                    if(this.data.count >= this.maxBufferedSamples) { \n",
        "                        this.data[\"Ax\"].splice(0,5120);\n",
        "                        this.data[\"Ay\"].splice(0,5120);\n",
        "                        this.data[\"Az\"].splice(0,5120);\n",
        "                        this.data[\"Ax\"].push(new Array(5120).fill(0))\n",
        "                        this.data[\"Ay\"].push(new Array(5120).fill(0))\n",
        "                        this.data[\"Az\"].push(new Array(5120).fill(0))\n",
        "                        this.data.count -= 5120;\n",
        "                    }\n",
        "                    //console.log(this.data)\n",
        "                    newLines++;\n",
        "                    //console.log(indices[k-1],indices[k])\n",
        "                    //console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
        "                    //indices.shift();\n",
        "                }\n",
        "                \n",
        "            }\n",
        "            if(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
        "   \n",
        "            return newLines;\n",
        "            //Continue\n",
        "        }\n",
        "        //else {this.buffer = []; return false;}\n",
        "    }\n",
        "    //Callbacks\n",
        "    onDecodedCallback(newLinesInt){\n",
        "        //console.log(\"new samples:\", newLinesInt);\n",
        "        this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
        "    }\n",
        " \n",
        "    onConnectedCallback() {\n",
        "        console.log(\"port connected!\");\n",
        "    }\n",
        " \n",
        "    onDisconnectedCallback() {\n",
        "        console.log(\"port disconnected!\");\n",
        "    }\n",
        " \n",
        "    onReceive(value){\n",
        "        this.buffer.push(...value);\n",
        " \n",
        "        let newLines = this.decode(this.buffer);\n",
        "        //console.log(this.data)\n",
        "        //console.log(\"decoding... \", this.buffer.length)\n",
        "        if(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
        "    }\n",
        " \n",
        "    async onPortSelected(port,baud=this.baudrate) {\n",
        "        try{\n",
        "            try {\n",
        "                await port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
        "                this.onConnectedCallback();\n",
        "                this.connected = true;\n",
        "                this.subscribed = true;\n",
        "                this.subscribe(port);//this.subscribeSafe(port);\n",
        "        \n",
        "            } //API inconsistency in syntax between linux and windows\n",
        "            catch {\n",
        "                await port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
        "                this.onConnectedCallback();\n",
        "                this.connected = true;\n",
        "                this.subscribed = true;\n",
        "                this.subscribe(port);//this.subscribeSafe(port);\n",
        "            }\n",
        "        }\n",
        "        catch(err){\n",
        "            console.log(err);\n",
        "            this.connected = false;\n",
        "        }\n",
        "    }\n",
        " \n",
        "    async subscribe(port){\n",
        "        if (this.port.readable && this.subscribed === true) {\n",
        "            this.reader = port.readable.getReader();\n",
        "            const streamData = async () => {\n",
        "                try {\n",
        "                    const { value, done } = await this.reader.read();\n",
        "                    if (done || this.subscribed === false) {\n",
        "                        // Allow the serial port to be closed later.\n",
        "                        await this.reader.releaseLock();\n",
        "                        \n",
        "                    }\n",
        "                    if (value) {\n",
        "                        //console.log(value.length);\n",
        "                        try{\n",
        "                            this.onReceive(value);\n",
        "                        }\n",
        "                        catch (err) {console.log(err)}\n",
        "                        //console.log(\"new Read\");\n",
        "                        //console.log(this.decoder.decode(value));\n",
        "                    }\n",
        "                    if(this.subscribed === true) {\n",
        "                        setTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
        "                    }\n",
        "                } catch (error) {\n",
        "                    console.log(error);// TODO: Handle non-fatal read error.\n",
        "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
        "                        this.subscribed = false;\n",
        "                        setTimeout(async ()=>{\n",
        "                            try{\n",
        "                            if (this.reader) {\n",
        "                                await this.reader.releaseLock();\n",
        "                                this.reader = null;\n",
        "                            }\n",
        "                            } catch (er){ console.error(er);}\n",
        "                            this.subscribed = true; \n",
        "                            this.subscribe(port);\n",
        "                            //if that fails then close port and reopen it\n",
        "                        },30); //try to resubscribe \n",
        "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
        "                        if(this.port){\n",
        "                            this.subscribed = false;\n",
        "                            setTimeout(async () => {\n",
        "                                try{\n",
        "                                if (this.reader) {\n",
        "                                    await this.reader.releaseLock();\n",
        "                                    this.reader = null;\n",
        "                                }\n",
        "                                await port.close();\n",
        "                                } catch (er){ console.error(er);}\n",
        "                                //this.port = null;\n",
        "                                this.connected = false;\n",
        "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
        "                            }, 50);\n",
        "                        }\n",
        "                    }\n",
        "                     else {\n",
        "                        this.closePort();   \n",
        "                    }   \n",
        "                }\n",
        "            }\n",
        "            streamData();\n",
        "        }\n",
        "    }\n",
        " \n",
        "    //Unfinished\n",
        "    async subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
        "        var readable = new Promise((resolve,reject) => {\n",
        "            while(this.port.readable && this.subscribed === true){\n",
        "                this.reader = port.readable.getReader();\n",
        "                var looper = true;\n",
        "                var prom1 = new Promise((resolve,reject) => {\n",
        "                    return this.reader.read();\n",
        "                });\n",
        " \n",
        "                var prom2 = new Promise((resolve,reject) => {\n",
        "                    setTimeout(resolve,100,\"readfail\");\n",
        "                });\n",
        "                while(looper === true ) {\n",
        "                    //console.log(\"reading...\");\n",
        "                    Promise.race([prom1,prom2]).then((result) => {\n",
        "                        console.log(\"newpromise\")\n",
        "                        if(result === \"readfail\"){\n",
        "                            console.log(result);\n",
        "                        }\n",
        "                        else{\n",
        "                            const {value, done} = result;\n",
        "                            if(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
        "                                resolve(this.reader.releaseLock())}).then(() => {\n",
        "                                    looper = false;\n",
        "                                    return;\n",
        "                                });\n",
        "                            }\n",
        "                            else{\n",
        "                                this.onReceive(value);\n",
        "                            }\n",
        "                        }\n",
        "                    });\n",
        "                }\n",
        "            }\n",
        "            resolve(\"not readable\");\n",
        "        });\n",
        "    }\n",
        " \n",
        "    async closePort(port=this.port) {\n",
        "        //if(this.reader) {this.reader.releaseLock();}\n",
        "        if(this.port){\n",
        "            this.subscribed = false;\n",
        "            setTimeout(async () => {\n",
        "                if (this.reader) {\n",
        "                    await this.reader.releaseLock();\n",
        "                    this.reader = null;\n",
        "                }\n",
        "                await port.close();\n",
        "                this.port = null;\n",
        "                this.connected = false;\n",
        "                this.onDisconnectedCallback();\n",
        "            }, 100);\n",
        "        }\n",
        "    }\n",
        " \n",
        "    async setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
        " \n",
        "        const filters = [\n",
        "            { usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
        "        ];\n",
        " \n",
        "        this.port = await navigator.serial.requestPort();\n",
        "        navigator.serial.addEventListener(\"disconnect\",(e) => {\n",
        "            this.closePort(this.port);\n",
        "        });\n",
        "        this.onPortSelected(this.port,baudrate);\n",
        " \n",
        "        //navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
        " \n",
        "    }\n",
        " \n",
        " \n",
        "    //Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
        "    asUint8Array(input) {\n",
        "        if (input instanceof Uint8Array) {\n",
        "            return input;\n",
        "        } else if (typeof(input) === 'string') {\n",
        "            // This naive transform only supports ASCII patterns. UTF-8 support\n",
        "            // not necessary for the intended use case here.\n",
        "            var arr = new Uint8Array(input.length);\n",
        "            for (var i = 0; i < input.length; i++) {\n",
        "            var c = input.charCodeAt(i);\n",
        "            if (c > 127) {\n",
        "                throw new TypeError(\"Only ASCII patterns are supported\");\n",
        "            }\n",
        "            arr[i] = c;\n",
        "            }\n",
        "            return arr;\n",
        "        } else {\n",
        "            // Assume that it's already something that can be coerced.\n",
        "            return new Uint8Array(input);\n",
        "        }\n",
        "    }\n",
        " \n",
        "    boyerMoore(patternBuffer) {\n",
        "        // Implementation of Boyer-Moore substring search ported from page 772 of\n",
        "        // Algorithms Fourth Edition (Sedgewick, Wayne)\n",
        "        // http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
        "        \n",
        "//      USAGE:\n",
        "            // needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
        "            // haystack should be an ArrayBuffer or Uint8Array\n",
        "//          var search = boyerMoore(needle);\n",
        "//          var skip = search.byteLength;\n",
        "//          var indices = [];\n",
        "//          for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
        "//              indices.push(i);\n",
        "//          }\n",
        "        \n",
        "        var pattern = this.asUint8Array(patternBuffer);\n",
        "        var M = pattern.length;\n",
        "        if (M === 0) {\n",
        "            throw new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
        "        }\n",
        "        // radix\n",
        "        var R = 256;\n",
        "        var rightmost_positions = new Int32Array(R);\n",
        "        // position of the rightmost occurrence of the byte c in the pattern\n",
        "        for (var c = 0; c < R; c++) {\n",
        "            // -1 for bytes not in pattern\n",
        "            rightmost_positions[c] = -1;\n",
        "        }\n",
        "        for (var j = 0; j < M; j++) {\n",
        "            // rightmost position for bytes in pattern\n",
        "            rightmost_positions[pattern[j]] = j;\n",
        "        }\n",
        "        var boyerMooreSearch = (txtBuffer, start, end) => {\n",
        "            // Return offset of first match, -1 if no match.\n",
        "            var txt = this.asUint8Array(txtBuffer);\n",
        "            if (start === undefined) start = 0;\n",
        "            if (end === undefined) end = txt.length;\n",
        "            var pat = pattern;\n",
        "            var right = rightmost_positions;\n",
        "            var lastIndex = end - pat.length;\n",
        "            var lastPatIndex = pat.length - 1;\n",
        "            var skip;\n",
        "            for (var i = start; i <= lastIndex; i += skip) {\n",
        "                skip = 0;\n",
        "                for (var j = lastPatIndex; j >= 0; j--) {\n",
        "                var c = txt[i + j];\n",
        "                if (pat[j] !== c) {\n",
        "                    skip = Math.max(1, j - right[c]);\n",
        "                    break;\n",
        "                }\n",
        "                }\n",
        "                if (skip === 0) {\n",
        "                return i;\n",
        "                }\n",
        "            }\n",
        "            return -1;\n",
        "        };\n",
        "        boyerMooreSearch.byteLength = pattern.byteLength;\n",
        "        return boyerMooreSearch;\n",
        "    }\n",
        "    //---------------------end copy/pasted solution------------------------\n",
        " \n",
        "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
        "        //this.lastnewLines=this.bufferednewLines;\n",
        "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
        "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
        "     {\n",
        "      //this.ready_to_send_data = false;\n",
        "      this.data_slice = [\n",
        "        //device.data.ms.slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
        "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
        "        ];\n",
        "  this.bufferednewLines=0;\n",
        "  //const buffer = new Uint8Array(10);\n",
        "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
        "  //  buffer[i] = i\n",
        "  //}\n",
        "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
        "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
        "  this.data_send_count++;\n",
        "  //if(this.channel==None)\n",
        "  //{\n",
        "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
        "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
        "  //} else \n",
        "  //{\n",
        "    //this.channel.send(this.data_send_count.toString())\n",
        "  //}\n",
        "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
        "  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
        "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
        "  let success = false;\n",
        "  for await (const message of channel.messages) {\n",
        "    if (message.data.response == 'close') {\n",
        "    //if (message.data.response == 'got comm open!') {\n",
        "      //const responseBuffer = new Uint8Array(message.buffers[0]);\n",
        "      //for (let i = 0; i < buffer.length; ++i) {\n",
        "      //  if (responseBuffer[i] != buffer[i]) {\n",
        "      //    console.error('comm buffer different at ' + i);\n",
        "      //    document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
        "      //    return;\n",
        "      //  }\n",
        "      //}\n",
        "      // Close the channel once the expected message is received. This should\n",
        "      // cause the messages iterator to complete and for the for-await loop to\n",
        "      // end.\n",
        "      //console.error('comm buffer same ' + responseBuffer);\n",
        "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
        "      channel.close();\n",
        "    }\n",
        "    //console.log('audio&image received');\n",
        "    //var message_parsed=JSON.parse(message.data.response);\n",
        "    //console.log('audio&image decoded');\n",
        "    //for(let i = 0; i < message_parsed.length; ++i)\n",
        "    {\n",
        "      \n",
        "      if (this.generate_wavegan)\n",
        "      {\n",
        "        //if((typeof message_parsed[i]) === 'string')\n",
        "        {\n",
        "          if(message.data.response.startsWith('data:audio'))\n",
        "          //if(message_parsed[i].startsWith('data:audio'))\n",
        "          {\n",
        "            //document.body.appendChild(document.createTextNode('audio decoded'));\n",
        "            //await \n",
        "            //playAudio1(message_parsed[i]);\n",
        "            //await \n",
        "            playAudio1(message.data.response);\n",
        "            device.time000=Date.now();\n",
        "            var frame_time=parseInt((1000/device.fps_wg)/1);\n",
        "            var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
        "            setTimeout(playAudio2,next_time);\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "      if (this.generate_stylegan2)\n",
        "      {\n",
        "        //if((typeof message_parsed[i]) === 'string')\n",
        "        {\n",
        "          //console.log(\"image string\");\n",
        "          if(message.data.response.startsWith('data:image'))\n",
        "          //if(message_parsed[i].startsWith('data:image'))\n",
        "          {\n",
        "            //document.body.appendChild(document.createTextNode('image decoded'));\n",
        "            //await \n",
        "            //displayPhoto1(message_parsed[i]);\n",
        "            //await \n",
        "            displayPhoto1(message.data.response,device.xsize,device.ysize);\n",
        "            device.time000=Date.now();\n",
        "            var frame_time=parseInt((1000/device.fps_sg2));//wg)/3);\n",
        "            var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
        "            setTimeout(displayPhoto4,next_time);\n",
        "          }\n",
        "        }\n",
        "        //else\n",
        "        {\n",
        "          //console.log(\"image not string\");\n",
        "          //displayPhoto3(message_parsed[i]);\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "      this.ready_to_send_data = true;\n",
        "  //document.body.appendChild(document.createTextNode('done2.'));\n",
        "     } \n",
        " \n",
        "    }\n",
        " \n",
        "}\n",
        " \n",
        "device = new eeg32();\n",
        " \n",
        "    connect = async () => {\n",
        "        await this.device.setupSerialAsync();\n",
        "    }\n",
        " \n",
        "    disconnect = () => {\n",
        "        if (this.ui) this.ui.deleteNode()\n",
        "        this.device.closePort();\n",
        "    }\n",
        " \n",
        " \n",
        "        //const canvas = document.createElement('canvas');\n",
        "      //const audio = document.createElement('audio');\n",
        "      //const audio1 = document.createElement('audio');\n",
        "      //const audio2 = document.createElement('audio');\n",
        "      var audios = new Array();\n",
        "      if(device.generate_wavegan)\n",
        "      {\n",
        "        const audios_length = 5;\n",
        "        for(let i = 0; i < audios_length; i++)\n",
        "        {\n",
        "          audios[i]=document.createElement('audio');\n",
        "        }\n",
        "      }\n",
        " \n",
        "          //var ctx = canvas.getContext(\"2d\");\n",
        " \n",
        "      var images = new Array();\n",
        "      var canvases = new Array();\n",
        "      if(device.generate_stylegan2)\n",
        "      {\n",
        "        const images_length = 1;\n",
        "        const canvases_length = images_length;\n",
        "        for(let i = 0; i < images_length; i++)\n",
        "        {\n",
        "          //images[i]=document.createElement('image');\n",
        "          canvases[i]=document.createElement('canvas');\n",
        "          var ctx = canvases[i].getContext(\"2d\");\n",
        "          images[i]=new Image();\n",
        "          //images[i].onload = function() {\n",
        "          //  ctx.drawImage(images[i], 0, 0);\n",
        "          //};\n",
        "        }\n",
        "      }\n",
        "      //var image = new Image();\n",
        "      //image.onload = function() {\n",
        "      //  ctx.drawImage(image, 0, 0);\n",
        "      //};\n",
        "const div = document.createElement('div');\n",
        "const div2 = document.createElement('div');\n",
        "const div3 = document.createElement('div');\n",
        "const btnconnect = document.createElement('button');\n",
        "const btndisconnect = document.createElement('button');\n",
        "const capture = document.createElement('button');\n",
        "                  \n",
        "    async function takePhoto2(quality=1) {\n",
        "      btnconnect.remove();\n",
        "      capture.remove();\n",
        "      device.ready_to_send_data = true;\n",
        "    }\n",
        " \n",
        "    async function takePhoto(quality=1) {\n",
        " \n",
        "      btnconnect.textContent = 'connect';\n",
        "      div.appendChild(btnconnect);\n",
        "      btnconnect.onclick = this.connect;\n",
        "      \n",
        "      btndisconnect.textContent = 'disconnect';\n",
        "      div.appendChild(btndisconnect);\n",
        "      btndisconnect.onclick = this.disconnect;\n",
        "      \n",
        "      capture.textContent = 'Capture';\n",
        "      capture.onclick = takePhoto2;\n",
        "      div.appendChild(capture);\n",
        "     \n",
        "      //div.appendChild(canvas);\n",
        "      //div.appendChild(audio);\n",
        "      //div.appendChild(audio1);\n",
        "      //div.appendChild(audio2);\n",
        "      if(device.generate_wavegan)\n",
        "      {\n",
        "        for(let i = 0; i < audios.length; i++)\n",
        "        {\n",
        "          div2.appendChild(audios[i]);\n",
        "          //audios[i].controls = true;\n",
        "          //audios[i].autoplay = true;\n",
        "        }\n",
        "      }\n",
        "      if(device.generate_stylegan2)\n",
        "      {\n",
        "        for(let i = 0; i <canvases.length; i++)\n",
        "        {\n",
        "          div3.appendChild(canvases[i]);\n",
        "        }\n",
        "      }\n",
        "      //for(let i = 0; i < images.length; i++)\n",
        "      //{\n",
        "      //  div.appendChild(images[i]);\n",
        "      //}\n",
        " \n",
        "      document.body.appendChild(div);\n",
        "      document.body.appendChild(div2);\n",
        "      document.body.appendChild(div3);\n",
        "         await new Promise((resolve) => capture.onclick = resolve);\n",
        " \n",
        "      btnconnect.remove();\n",
        "      capture.remove();\n",
        "      device.ready_to_send_data = true;\n",
        "    }\n",
        " \n",
        "    async function takePhoto1(quality=1) {  \n",
        "      //var data_slice_send=this.device.data_slice;\n",
        "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
        "      //var data_slice_send=[this.device.data_slice[0]];\n",
        "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
        "        //console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
        "        //console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
        "      device.bufferednewLines=0;\n",
        "      return data_slice_send;      \n",
        "    }\n",
        " \n",
        "    async function displayPhoto1(photodata,photoWidth=512,photoHeight=512) {\n",
        "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
        "    }\n",
        "    var image_now=0;\n",
        "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
        "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "     //image.src = photodata;\n",
        "      {\n",
        "       if(canvases[image_now%%images.length].width != photoWidth)\n",
        "       {\n",
        "         canvases[image_now%%images.length].width = photoWidth;\n",
        "       }\n",
        "       if(canvases[image_now%%images.length].height != photoHeight) \n",
        "       {\n",
        "         canvases[image_now%%images.length].height = photoHeight;\n",
        "       }\n",
        "       images[image_now%%images.length].src = photodata;\n",
        "        //audios[audio_now%%audios.length].play();\n",
        "      }\n",
        "      //image_now++;\n",
        "    }\n",
        "    async function displayPhoto4(photodata){//},photoWidth,photoHeight) {\n",
        "      ctx.drawImage(images[image_now%%images.length], 0, 0);\n",
        "      image_now++;\n",
        "    }\n",
        "    var img_step=0;\n",
        "    async function displayPhoto3(photodata,photoWidth=512,photoHeight=512) {\n",
        "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "      fs.writeFile('img0.jpg', photodata, function (err) {\n",
        "        // console.log(\"save img!\" );\n",
        "      });\n",
        "      var photofile='img0.jpg?'+img_step;\n",
        "      img_step+=1;\n",
        "      //console.log(\"save img!\" );\n",
        "      await displayPhoto2(photofile,photoWidth,photoHeight);\n",
        "    }\n",
        " \n",
        "    var audio_now=0;\n",
        "    async function playAudio1(audiodata){//},photoWidth=512,photoHeight=512) {\n",
        "      //const canvas = document.createElement('canvas');\n",
        "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
        "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
        "      //audio.controls = true;\n",
        "      //audio.autoplay = true;\n",
        "      //audio1.controls = true;\n",
        "      //audio1.autoplay = true;\n",
        "      //audio2.controls = true;\n",
        "      //audio2.autoplay = true;\n",
        " \n",
        "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
        "      //var canvas = document.getElementById(\"c\");\n",
        "      ///var ctx = canvas.getContext(\"2d\");\n",
        " \n",
        "      ///var image = new Image();\n",
        "      ///image.onload = function() {\n",
        "      ///  ctx.drawImage(image, 0, 0);\n",
        "      ///};\n",
        "      //audio.src = audiodata;\n",
        "      //audio.play()\n",
        "      //if(audio_now%%2==0)\n",
        "      //{\n",
        "      //  audio1.src = audiodata;\n",
        "      //  audio1.play()\n",
        "      //}\n",
        "      //else\n",
        "      //{\n",
        "      //  audio2.src = audiodata;\n",
        "      //  audio2.play()\n",
        "      //}\n",
        "      //for(let i = 0; i < audios.length; ++i)\n",
        "      {\n",
        "        audios[audio_now%%audios.length].src = audiodata;\n",
        "        //if(audio_now==0)\n",
        "        {\n",
        "          audios[audio_now%%audios.length].controls = true;\n",
        "          //audios[audio_now%%audios.length].autoplay = true;\n",
        "        }\n",
        "        //audios[audio_now%%audios.length].play();\n",
        "      }\n",
        "      //audio_now++;\n",
        " \n",
        "    }\n",
        "    async function playAudio2(audiodata){//},photoWidth=512,photoHeight=512) {\n",
        "      audios[audio_now%%audios.length].play();\n",
        "      audio_now++;\n",
        "    }\n",
        "    \n",
        "  takePhoto();\n",
        "  data_count=0;\n",
        "\n",
        "async function check_to_send() {\n",
        "  //while(true)\n",
        "  {\n",
        "   if(device.bufferednewLines)\n",
        "   {\n",
        "    //if(this.bufferednewLines>this.data_slice_size)\n",
        "    //  {\n",
        "    //    this.bufferednewLines=this.data_slice_size;\n",
        "    //  }\n",
        "    /*device.time000=Date.now();\n",
        "    if(device.generate_wavegan)\n",
        "    {\n",
        "      device.this_frame_wg=parseInt((device.time000-device.time100)*device.fps_wg);\n",
        "      if(device.this_frame_wg>device.last_frame_wg)\n",
        "      {\n",
        "        device.last_frame_wg=device.this_frame_wg;\n",
        "        device.send_wg=true;\n",
        "      }\n",
        "    }\n",
        "    if(device.generate_stylegan2)\n",
        "    {\n",
        "      device.this_frame_sg2=parseInt((device.time000-device.time100)*device.fps_sg2);\n",
        "      if(device.this_frame_sg2>device.last_frame_sg2)\n",
        "      {\n",
        "        device.last_frame_sg2=device.this_frame_sg2;\n",
        "        device.send_sg2=true;\n",
        "      }\n",
        "    }\n",
        "    if(device.send_wg || device.send_sg2)\n",
        "    //if(this.bufferednewLines>512/(this.fps_sg2))\n",
        "    if(device.ready_to_send_data)*/\n",
        "    {\n",
        "      //this.bufferednewLines=512/this.fps;\n",
        " \n",
        "        device.takeandsendSlice(device.data.count-1-device.bufferednewLines,device.data.count-1);\n",
        "      device.send_wg=false;\n",
        "      device.send_sg2=false;\n",
        "    }\n",
        "        //console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
        "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
        "   }\n",
        "  }\n",
        "  device.time000=Date.now();\n",
        "  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
        "  var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
        "  setTimeout(check_to_send,next_time);\n",
        "  //console.log(next_time);\n",
        "}\n",
        "  device.time000=Date.now();\n",
        "  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
        "  var next_time=frame_time-((device.time000-device.time100)%%frame_time);\n",
        "  setTimeout(check_to_send,next_time);\n",
        "  //console.log(next_time);\n",
        "//var intervalID = setInterval(check_to_send,(1000/device.fps_wg)/10);\n",
        "//  window.requestAnimationFrame\n",
        " \n",
        "''' % {'xsize':xsize,'ysize':ysize,'generate_stylegan2':generate&gen_stylegan2,'generate_wavegan':generate&gen_wavegan,'generate_heatmap':generate&gen_heatmap,\n",
        "       'fps_sg2':fps_sg2,'fps_wg':fps_wg,'fps_hm':fps_hm})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/javascript": [
              "\n",
              "//Joshua Brewster, GPL (copyleft)\n",
              " \n",
              "//import 'regenerator-runtime/runtime' //For async functions on node\\\n",
              " \n",
              " class eeg32 { //Contains structs and necessary functions/API calls to analyze serial data for the FreeEEG32\n",
              " \n",
              "    constructor(\n",
              "        onDecodedCallback = this.onDecodedCallback,\n",
              "        onConnectedCallback = this.onConnectedCallback,\n",
              "        onDisconnectedCallback = this.onDisconnectedCallback,\n",
              "        CustomDecoder = this.decode,\n",
              "        baudrate = 921600//115200\n",
              "        ) {\n",
              " \n",
              "        this.onDecodedCallback = onDecodedCallback;\n",
              "        this.onConnectedCallback = onConnectedCallback;\n",
              "        this.onDisconnectedCallback = onDisconnectedCallback;\n",
              "        this.decode = CustomDecoder;\n",
              "        //Free EEG 32 data structure:\n",
              "        \n",
              "        //    [stop byte, start byte, counter byte, 32x3 channel data bytes (24 bit), 3x2 accelerometer data bytes, stop byte, start byte...] Gyroscope not enabled yet but would be printed after the accelerometer..\n",
              "        //    Total = 105 bytes/line\n",
              "        \n",
              "        this.connected = false;\n",
              "        this.subscribed = false;\n",
              "        this.buffer = [];\n",
              "        this.startByte = 160; // Start byte value\n",
              "        this.stopByte = 192; // Stop byte value\n",
              "        this.searchString = new Uint8Array([this.stopByte,this.startByte]); //Byte search string\n",
              "        this.readRate = 16.666667; //Throttle EEG read speed. (1.953ms/sample min @103 bytes/line)\n",
              "        this.readBufferSize = 2000; //Serial read buffer size, increase for slower read speeds (~1030bytes every 20ms) to keep up with the stream (or it will crash)\n",
              " \n",
              "        this.sps = 512; // Sample rate\n",
              "        this.nChannels = 32;\n",
              "        this.nPeripheralChannels = 6; // accelerometer and gyroscope (2 bytes * 3 coordinates each)\n",
              "        this.updateMs = 1000/this.sps; //even spacing\n",
              "        this.stepSize = 1/Math.pow(2,24);\n",
              "        this.vref = 2.50; //2.5V voltage ref +/- 250nV\n",
              "        this.gain = 8;\n",
              " \n",
              "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
              "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
              "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
              " \n",
              "        this.maxBufferedSamples = this.sps*60*2; //max samples in buffer this.sps*60*nMinutes = max minutes of data\n",
              "        \n",
              "        this.data = { //Data object to keep our head from exploding. Get current data with e.g. this.data.A0[this.data.count-1]\n",
              "            count: 0,\n",
              "            startms: 0,\n",
              "            ms: [],\n",
              "            'A0': [],'A1': [],'A2': [],'A3': [],'A4': [],'A5': [],'A6': [],'A7': [], //ADC 0\n",
              "            'A8': [],'A9': [],'A10': [],'A11': [],'A12': [],'A13': [],'A14': [],'A15': [], //ADC 1\n",
              "            'A16': [],'A17': [],'A18': [],'A19': [],'A20': [],'A21': [],'A22': [],'A23': [], //ADC 2\n",
              "            'A24': [],'A25': [],'A26': [],'A27': [],'A28': [],'A29': [],'A30': [],'A31': [], //ADC 3\n",
              "            'Ax': [], 'Ay': [], 'Az': [], 'Gx': [], 'Gy': [], 'Gz': []  //Peripheral data (accelerometer, gyroscope)\n",
              "        };\n",
              " \n",
              "    this.bufferednewLines = 0;\n",
              "    this.data_slice=[];\n",
              "    this.data_slice_size=512*(5*1/8+0.1);\n",
              "    this.ready_to_send_data = false;\n",
              "    this.data_send_count=0;\n",
              "\n",
              "    this.xsize=128;\n",
              "    this.ysize=128;\n",
              "\n",
              "    this.generate_stylegan2=true;\n",
              "    this.generate_stylegan2=32;\n",
              "    \n",
              "    //this.generate_stylegan2=false;\n",
              "    this.generate_wavegan=true;\n",
              "    this.generate_wavegan=0;\n",
              "    this.generate_heatmap=true;\n",
              "    this.generate_heatmap=0;\n",
              "    //data:audio/wav;base64,\n",
              "    //data:image/jpeg;base64,\n",
              "    this.time100=Date.now();\n",
              "    this.time000=Date.now();\n",
              "    this.this_frame_wg=-1;\n",
              "    this.last_frame_wg=-1;\n",
              "    this.send_wg=false;\n",
              "    this.this_frame_sg2=-1;\n",
              "    this.last_frame_sg2=-1;\n",
              "    this.send_sg2=false;\n",
              "\n",
              "    if(this.generate_stylegan2)\n",
              "    {\n",
              "      this.fps_sg2=1;\n",
              "    }\n",
              "    if(this.generate_wavegan)\n",
              "    {\n",
              "      this.hz=44100;\n",
              "      this.fps_wg=this.hz/(32768*2);\n",
              "      //this.fps=this.hz/(32768);\n",
              "    }\n",
              "      this.fps_sg2=this.fps_wg;\n",
              "      this.fps_wg=0.672913;\n",
              "      this.fps_sg2=2.691650;\n",
              "      this.fps_hm=0.672913;\n",
              "    this.samples_count=0;\n",
              "    //this.channel=None;\n",
              " \n",
              "        this.resetDataBuffers();\n",
              " \n",
              "        //navigator.serial utils\n",
              "        if(!navigator.serial){\n",
              "            console.error(\"`navigator.serial not found! Enable #enable-experimental-web-platform-features in chrome://flags (search 'experimental')\")\n",
              "        }\n",
              "        this.port = null;\n",
              "        this.reader = null;\n",
              "        this.baudrate = baudrate;\n",
              " \n",
              "    }\n",
              "    \n",
              "    resetDataBuffers(){\n",
              "        this.data.count = 0;\n",
              "        this.data.startms = 0;\n",
              "        for(const prop in this.data) {\n",
              "            if(typeof this.data[prop] === \"object\"){\n",
              "                this.data[prop] = new Array(this.maxBufferedSamples).fill(0);\n",
              "            }\n",
              "        }\n",
              "    }\n",
              " \n",
              "    setScalar(gain=24,stepSize=1/(Math.pow(2,23)-1),vref=4.50) {\n",
              "        this.stepSize = stepSize;\n",
              "        this.vref = vref; //2.5V voltage ref +/- 250nV\n",
              "        this.gain = gain;\n",
              " \n",
              "        this.vscale = (this.vref/this.gain)*this.stepSize; //volts per step.\n",
              "        this.uVperStep = 1000000 * ((this.vref/this.gain)*this.stepSize); //uV per step.\n",
              "        this.scalar = 1/(1000000 / ((this.vref/this.gain)*this.stepSize)); //steps per uV.\n",
              "    }\n",
              " \n",
              "    getLatestData(channel=\"A0\",count=1) { //Return slice of specified size of the latest data from the specified channel\n",
              "        let ct = count;\n",
              "        if(ct <= 1) {\n",
              "            return [this.data[channel][this.data.count-1]];\n",
              "        }\n",
              "        else {\n",
              "            if(ct > this.data.count) {\n",
              "                ct = this.data.count;\n",
              "            }\n",
              "            return this.data[channel].slice(this.data.count-ct,this.data.count);\n",
              "        }\n",
              "    }\n",
              " \n",
              "    bytesToInt16(x0,x1){\n",
              "        return x0 * 256 + x1;\n",
              "    }\n",
              " \n",
              "    int16ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
              "        return [y & 0xFF , (y >> 8) & 0xFF];\n",
              "    }\n",
              " \n",
              "    bytesToInt24(x0,x1,x2){ //Turns a 3 byte sequence into a 24 bit int\n",
              "        return x0 * 65536 + x1 * 256 + x2;\n",
              "    }\n",
              " \n",
              "    int24ToBytes(y){ //Turns a 24 bit int into a 3 byte sequence\n",
              "        return [y & 0xFF , (y >> 8) & 0xFF , (y >> 16) & 0xFF];\n",
              "    }\n",
              " \n",
              "    decode(buffer = this.buffer) { //returns true if successful, returns false if not\n",
              " \n",
              "        var needle = this.searchString\n",
              "        var haystack = buffer;\n",
              "        var search = this.boyerMoore(needle);\n",
              "        var skip = search.byteLength;\n",
              "        var indices = [];\n",
              "        let newLines = 0;\n",
              "    \n",
              "        for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
              "            indices.push(i);\n",
              "        }\n",
              "        //console.log(indices);\n",
              "        if(indices.length >= 2){\n",
              "            for(let k = 1; k < indices.length; k++) {\n",
              "                if(indices[k] - indices[k-1] !== 105) {\n",
              "                    \n",
              "                } //This is not a valid sequence going by size, drop sequence and return\n",
              "                else {\n",
              "                    var line = buffer.slice(indices[k-1],indices[k]+1); //Splice out this line to be decoded\n",
              "                    \n",
              "                    // line[0] = stop byte, line[1] = start byte, line[2] = counter, line[3:99] = ADC data 32x3 bytes, line[100-104] = Accelerometer data 3x2 bytes\n",
              " \n",
              "                    //line found, decode.\n",
              "                    if(this.data.count < this.maxBufferedSamples){\n",
              "                        this.data.count++;\n",
              "                    }\n",
              " \n",
              "                    if(this.data.count-1 === 0) {this.data.ms[this.data.count-1]= Date.now(); this.data.startms = this.data.ms[0];}\n",
              "                    else {\n",
              "                        this.data.ms[this.data.count-1]=this.data.ms[this.data.count-2]+this.updateMs;\n",
              "                        \n",
              "                        if(this.data.count >= this.maxBufferedSamples) {\n",
              "                            this.data.ms.splice(0,5120);\n",
              "                            this.data.ms.push(new Array(5120).fill(0));\n",
              "                        }\n",
              "                    }//Assume no dropped samples\n",
              "                  var sample_count = line[2];\n",
              "                  var sample_count_diff = sample_count-this.samples_count;\n",
              "          if(sample_count_diff<0){\n",
              "            sample_count_diff+=256;\n",
              "          }\n",
              "          if(sample_count_diff!=1)\n",
              "          {\n",
              "            console.error(\"dropped samples:\"+sample_count_diff.toString());\n",
              "          }\n",
              "          this.samples_count=sample_count;\n",
              " \n",
              "                    for(var i = 3; i < 99; i+=3) {\n",
              "                        var channel = \"A\"+(i-3)/3;\n",
              "                        this.data[channel][this.data.count-1]=this.bytesToInt24(line[i],line[i+1],line[i+2]);\n",
              "                        if(this.data.count >= this.maxBufferedSamples) { \n",
              "                            this.data[channel].splice(0,5120);\n",
              "                            this.data[channel].push(new Array(5120).fill(0));//shave off the last 10 seconds of data if buffer full (don't use shift())\n",
              "                        }\n",
              "                            //console.log(this.data[channel][this.data.count-1],indices[k], channel)\n",
              "                    }\n",
              " \n",
              "                    this.data[\"Ax\"][this.data.count-1]=this.bytesToInt16(line[99],line[100]);\n",
              "                    this.data[\"Ay\"][this.data.count-1]=this.bytesToInt16(line[101],line[102]);\n",
              "                    this.data[\"Az\"][this.data.count-1]=this.bytesToInt16(line[103],line[104]);\n",
              " \n",
              "                    \n",
              "                    if(this.data.count >= this.maxBufferedSamples) { \n",
              "                        this.data[\"Ax\"].splice(0,5120);\n",
              "                        this.data[\"Ay\"].splice(0,5120);\n",
              "                        this.data[\"Az\"].splice(0,5120);\n",
              "                        this.data[\"Ax\"].push(new Array(5120).fill(0))\n",
              "                        this.data[\"Ay\"].push(new Array(5120).fill(0))\n",
              "                        this.data[\"Az\"].push(new Array(5120).fill(0))\n",
              "                        this.data.count -= 5120;\n",
              "                    }\n",
              "                    //console.log(this.data)\n",
              "                    newLines++;\n",
              "                    //console.log(indices[k-1],indices[k])\n",
              "                    //console.log(buffer[indices[k-1],buffer[indices[k]]])\n",
              "                    //indices.shift();\n",
              "                }\n",
              "                \n",
              "            }\n",
              "            if(newLines > 0) buffer.splice(0,indices[indices.length-1]);\n",
              "   \n",
              "            return newLines;\n",
              "            //Continue\n",
              "        }\n",
              "        //else {this.buffer = []; return false;}\n",
              "    }\n",
              "    //Callbacks\n",
              "    onDecodedCallback(newLinesInt){\n",
              "        //console.log(\"new samples:\", newLinesInt);\n",
              "        this.bufferednewLines=this.bufferednewLines+newLinesInt;\n",
              "    }\n",
              " \n",
              "    onConnectedCallback() {\n",
              "        console.log(\"port connected!\");\n",
              "    }\n",
              " \n",
              "    onDisconnectedCallback() {\n",
              "        console.log(\"port disconnected!\");\n",
              "    }\n",
              " \n",
              "    onReceive(value){\n",
              "        this.buffer.push(...value);\n",
              " \n",
              "        let newLines = this.decode(this.buffer);\n",
              "        //console.log(this.data)\n",
              "        //console.log(\"decoding... \", this.buffer.length)\n",
              "        if(newLines !== false && newLines !== 0 && !isNaN(newLines) ) this.onDecodedCallback(newLines);\n",
              "    }\n",
              " \n",
              "    async onPortSelected(port,baud=this.baudrate) {\n",
              "        try{\n",
              "            try {\n",
              "                await port.open({ baudRate: baud, bufferSize: this.readBufferSize });\n",
              "                this.onConnectedCallback();\n",
              "                this.connected = true;\n",
              "                this.subscribed = true;\n",
              "                this.subscribe(port);//this.subscribeSafe(port);\n",
              "        \n",
              "            } //API inconsistency in syntax between linux and windows\n",
              "            catch {\n",
              "                await port.open({ baudrate: baud, buffersize: this.readBufferSize });\n",
              "                this.onConnectedCallback();\n",
              "                this.connected = true;\n",
              "                this.subscribed = true;\n",
              "                this.subscribe(port);//this.subscribeSafe(port);\n",
              "            }\n",
              "        }\n",
              "        catch(err){\n",
              "            console.log(err);\n",
              "            this.connected = false;\n",
              "        }\n",
              "    }\n",
              " \n",
              "    async subscribe(port){\n",
              "        if (this.port.readable && this.subscribed === true) {\n",
              "            this.reader = port.readable.getReader();\n",
              "            const streamData = async () => {\n",
              "                try {\n",
              "                    const { value, done } = await this.reader.read();\n",
              "                    if (done || this.subscribed === false) {\n",
              "                        // Allow the serial port to be closed later.\n",
              "                        await this.reader.releaseLock();\n",
              "                        \n",
              "                    }\n",
              "                    if (value) {\n",
              "                        //console.log(value.length);\n",
              "                        try{\n",
              "                            this.onReceive(value);\n",
              "                        }\n",
              "                        catch (err) {console.log(err)}\n",
              "                        //console.log(\"new Read\");\n",
              "                        //console.log(this.decoder.decode(value));\n",
              "                    }\n",
              "                    if(this.subscribed === true) {\n",
              "                        setTimeout(()=>{streamData();}, this.readRate);//Throttled read 1/512sps = 1.953ms/sample @ 103 bytes / line or 1030bytes every 20ms\n",
              "                    }\n",
              "                } catch (error) {\n",
              "                    console.log(error);// TODO: Handle non-fatal read error.\n",
              "                    if(error.message.includes('framing') || error.message.includes('overflow') || error.message.includes('Overflow') || error.message.includes('break')) {\n",
              "                        this.subscribed = false;\n",
              "                        setTimeout(async ()=>{\n",
              "                            try{\n",
              "                            if (this.reader) {\n",
              "                                await this.reader.releaseLock();\n",
              "                                this.reader = null;\n",
              "                            }\n",
              "                            } catch (er){ console.error(er);}\n",
              "                            this.subscribed = true; \n",
              "                            this.subscribe(port);\n",
              "                            //if that fails then close port and reopen it\n",
              "                        },30); //try to resubscribe \n",
              "                    } else if (error.message.includes('parity') || error.message.includes('Parity') || error.message.includes('overrun') ) {\n",
              "                        if(this.port){\n",
              "                            this.subscribed = false;\n",
              "                            setTimeout(async () => {\n",
              "                                try{\n",
              "                                if (this.reader) {\n",
              "                                    await this.reader.releaseLock();\n",
              "                                    this.reader = null;\n",
              "                                }\n",
              "                                await port.close();\n",
              "                                } catch (er){ console.error(er);}\n",
              "                                //this.port = null;\n",
              "                                this.connected = false;\n",
              "                                setTimeout(()=>{this.onPortSelected(this.port)},100); //close the port and reopen\n",
              "                            }, 50);\n",
              "                        }\n",
              "                    }\n",
              "                     else {\n",
              "                        this.closePort();   \n",
              "                    }   \n",
              "                }\n",
              "            }\n",
              "            streamData();\n",
              "        }\n",
              "    }\n",
              " \n",
              "    //Unfinished\n",
              "    async subscribeSafe(port) { //Using promises instead of async/await to cure hangs when the serial update does not meet tick requirements\n",
              "        var readable = new Promise((resolve,reject) => {\n",
              "            while(this.port.readable && this.subscribed === true){\n",
              "                this.reader = port.readable.getReader();\n",
              "                var looper = true;\n",
              "                var prom1 = new Promise((resolve,reject) => {\n",
              "                    return this.reader.read();\n",
              "                });\n",
              " \n",
              "                var prom2 = new Promise((resolve,reject) => {\n",
              "                    setTimeout(resolve,100,\"readfail\");\n",
              "                });\n",
              "                while(looper === true ) {\n",
              "                    //console.log(\"reading...\");\n",
              "                    Promise.race([prom1,prom2]).then((result) => {\n",
              "                        console.log(\"newpromise\")\n",
              "                        if(result === \"readfail\"){\n",
              "                            console.log(result);\n",
              "                        }\n",
              "                        else{\n",
              "                            const {value, done} = result;\n",
              "                            if(done === true || this.subscribed === true) { var donezo = new Promise((resolve,reject) => {\n",
              "                                resolve(this.reader.releaseLock())}).then(() => {\n",
              "                                    looper = false;\n",
              "                                    return;\n",
              "                                });\n",
              "                            }\n",
              "                            else{\n",
              "                                this.onReceive(value);\n",
              "                            }\n",
              "                        }\n",
              "                    });\n",
              "                }\n",
              "            }\n",
              "            resolve(\"not readable\");\n",
              "        });\n",
              "    }\n",
              " \n",
              "    async closePort(port=this.port) {\n",
              "        //if(this.reader) {this.reader.releaseLock();}\n",
              "        if(this.port){\n",
              "            this.subscribed = false;\n",
              "            setTimeout(async () => {\n",
              "                if (this.reader) {\n",
              "                    await this.reader.releaseLock();\n",
              "                    this.reader = null;\n",
              "                }\n",
              "                await port.close();\n",
              "                this.port = null;\n",
              "                this.connected = false;\n",
              "                this.onDisconnectedCallback();\n",
              "            }, 100);\n",
              "        }\n",
              "    }\n",
              " \n",
              "    async setupSerialAsync(baudrate=this.baudrate) { //You can specify baudrate just in case\n",
              " \n",
              "        const filters = [\n",
              "            { usbVendorId: 0x10c4, usbProductId: 0x0043 } //CP2102 filter (e.g. for UART via ESP32)\n",
              "        ];\n",
              " \n",
              "        this.port = await navigator.serial.requestPort();\n",
              "        navigator.serial.addEventListener(\"disconnect\",(e) => {\n",
              "            this.closePort(this.port);\n",
              "        });\n",
              "        this.onPortSelected(this.port,baudrate);\n",
              " \n",
              "        //navigator.serial.addEventListener(\"onReceive\", (e) => {console.log(e)});//this.onReceive(e));\n",
              " \n",
              "    }\n",
              " \n",
              " \n",
              "    //Boyer Moore fast byte search method copied from https://codereview.stackexchange.com/questions/20136/uint8array-indexof-method-that-allows-to-search-for-byte-sequences\n",
              "    asUint8Array(input) {\n",
              "        if (input instanceof Uint8Array) {\n",
              "            return input;\n",
              "        } else if (typeof(input) === 'string') {\n",
              "            // This naive transform only supports ASCII patterns. UTF-8 support\n",
              "            // not necessary for the intended use case here.\n",
              "            var arr = new Uint8Array(input.length);\n",
              "            for (var i = 0; i < input.length; i++) {\n",
              "            var c = input.charCodeAt(i);\n",
              "            if (c > 127) {\n",
              "                throw new TypeError(\"Only ASCII patterns are supported\");\n",
              "            }\n",
              "            arr[i] = c;\n",
              "            }\n",
              "            return arr;\n",
              "        } else {\n",
              "            // Assume that it's already something that can be coerced.\n",
              "            return new Uint8Array(input);\n",
              "        }\n",
              "    }\n",
              " \n",
              "    boyerMoore(patternBuffer) {\n",
              "        // Implementation of Boyer-Moore substring search ported from page 772 of\n",
              "        // Algorithms Fourth Edition (Sedgewick, Wayne)\n",
              "        // http://algs4.cs.princeton.edu/53substring/BoyerMoore.java.html\n",
              "        \n",
              "//      USAGE:\n",
              "            // needle should be ASCII string, ArrayBuffer, or Uint8Array\n",
              "            // haystack should be an ArrayBuffer or Uint8Array\n",
              "//          var search = boyerMoore(needle);\n",
              "//          var skip = search.byteLength;\n",
              "//          var indices = [];\n",
              "//          for (var i = search(haystack); i !== -1; i = search(haystack, i + skip)) {\n",
              "//              indices.push(i);\n",
              "//          }\n",
              "        \n",
              "        var pattern = this.asUint8Array(patternBuffer);\n",
              "        var M = pattern.length;\n",
              "        if (M === 0) {\n",
              "            throw new TypeError(\"patternBuffer must be at least 1 byte long\");\n",
              "        }\n",
              "        // radix\n",
              "        var R = 256;\n",
              "        var rightmost_positions = new Int32Array(R);\n",
              "        // position of the rightmost occurrence of the byte c in the pattern\n",
              "        for (var c = 0; c < R; c++) {\n",
              "            // -1 for bytes not in pattern\n",
              "            rightmost_positions[c] = -1;\n",
              "        }\n",
              "        for (var j = 0; j < M; j++) {\n",
              "            // rightmost position for bytes in pattern\n",
              "            rightmost_positions[pattern[j]] = j;\n",
              "        }\n",
              "        var boyerMooreSearch = (txtBuffer, start, end) => {\n",
              "            // Return offset of first match, -1 if no match.\n",
              "            var txt = this.asUint8Array(txtBuffer);\n",
              "            if (start === undefined) start = 0;\n",
              "            if (end === undefined) end = txt.length;\n",
              "            var pat = pattern;\n",
              "            var right = rightmost_positions;\n",
              "            var lastIndex = end - pat.length;\n",
              "            var lastPatIndex = pat.length - 1;\n",
              "            var skip;\n",
              "            for (var i = start; i <= lastIndex; i += skip) {\n",
              "                skip = 0;\n",
              "                for (var j = lastPatIndex; j >= 0; j--) {\n",
              "                var c = txt[i + j];\n",
              "                if (pat[j] !== c) {\n",
              "                    skip = Math.max(1, j - right[c]);\n",
              "                    break;\n",
              "                }\n",
              "                }\n",
              "                if (skip === 0) {\n",
              "                return i;\n",
              "                }\n",
              "            }\n",
              "            return -1;\n",
              "        };\n",
              "        boyerMooreSearch.byteLength = pattern.byteLength;\n",
              "        return boyerMooreSearch;\n",
              "    }\n",
              "    //---------------------end copy/pasted solution------------------------\n",
              " \n",
              "    async  takeandsendSlice(data_slice_from,data_slice_to) {\n",
              "        //this.lastnewLines=this.bufferednewLines;\n",
              "     //if(this.ready_to_send_data&&this.bufferednewLines){//&&this.data_slice[0].length)\n",
              "     if(this.ready_to_send_data&&this.bufferednewLines)//&&this.data_slice[0].length)\n",
              "     {\n",
              "      //this.ready_to_send_data = false;\n",
              "      this.data_slice = [\n",
              "        //device.data.ms.slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+0].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+1].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+2].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+3].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+4].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+5].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+6].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+7].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+8].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+9].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+10].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+11].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+12].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+13].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+14].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+15].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+16].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+17].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+18].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+19].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+20].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+21].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+22].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+23].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+24].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+25].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+26].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+27].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+28].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+29].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+30].slice(data_slice_from,data_slice_to),\n",
              "        this.data[\"A\"+31].slice(data_slice_from,data_slice_to)\n",
              "        ];\n",
              "  this.bufferednewLines=0;\n",
              "  //const buffer = new Uint8Array(10);\n",
              "  //for (let i = 0; i < buffer.byteLength; ++i) {\n",
              "  //  buffer[i] = i\n",
              "  //}\n",
              "  var array_to_send_as_json = JSON.stringify(this.data_slice);\n",
              "  //document.body.appendChild(document.createTextNode('sending ready'));\n",
              "  this.data_send_count++;\n",
              "  //if(this.channel==None)\n",
              "  //{\n",
              "  //  this.channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
              "    //this.channel = await google.colab.kernel.comms.open(this.data_send_count.toString(), array_to_send_as_json, []);\n",
              "  //} else \n",
              "  //{\n",
              "    //this.channel.send(this.data_send_count.toString())\n",
              "  //}\n",
              "  //document.body.appendChild(document.createTextNode(array_to_send_as_json));\n",
              "  const channel = await google.colab.kernel.comms.open('comm_target1', array_to_send_as_json, []);\n",
              "  //const channel = await google.colab.kernel.comms.open('comm_target1', 'the data', [buffer.buffer]);\n",
              "  let success = false;\n",
              "  for await (const message of channel.messages) {\n",
              "    if (message.data.response == 'close') {\n",
              "    //if (message.data.response == 'got comm open!') {\n",
              "      //const responseBuffer = new Uint8Array(message.buffers[0]);\n",
              "      //for (let i = 0; i < buffer.length; ++i) {\n",
              "      //  if (responseBuffer[i] != buffer[i]) {\n",
              "      //    console.error('comm buffer different at ' + i);\n",
              "      //    document.body.appendChild(document.createTextNode('comm buffer different at2 ' + i));\n",
              "      //    return;\n",
              "      //  }\n",
              "      //}\n",
              "      // Close the channel once the expected message is received. This should\n",
              "      // cause the messages iterator to complete and for the for-await loop to\n",
              "      // end.\n",
              "      //console.error('comm buffer same ' + responseBuffer);\n",
              "      //document.body.appendChild(document.createTextNode('comm buffer same2 ' + responseBuffer));\n",
              "      channel.close();\n",
              "    }\n",
              "    //console.log('audio&image received');\n",
              "    //var message_parsed=JSON.parse(message.data.response);\n",
              "    //console.log('audio&image decoded');\n",
              "    //for(let i = 0; i < message_parsed.length; ++i)\n",
              "    {\n",
              "      \n",
              "      if (this.generate_wavegan)\n",
              "      {\n",
              "        //if((typeof message_parsed[i]) === 'string')\n",
              "        {\n",
              "          if(message.data.response.startsWith('data:audio'))\n",
              "          //if(message_parsed[i].startsWith('data:audio'))\n",
              "          {\n",
              "            //document.body.appendChild(document.createTextNode('audio decoded'));\n",
              "            //await \n",
              "            //playAudio1(message_parsed[i]);\n",
              "            //await \n",
              "            playAudio1(message.data.response);\n",
              "            device.time000=Date.now();\n",
              "            var frame_time=parseInt((1000/device.fps_wg)/1);\n",
              "            var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
              "            setTimeout(playAudio2,next_time);\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      if (this.generate_stylegan2)\n",
              "      {\n",
              "        //if((typeof message_parsed[i]) === 'string')\n",
              "        {\n",
              "          //console.log(\"image string\");\n",
              "          if(message.data.response.startsWith('data:image'))\n",
              "          //if(message_parsed[i].startsWith('data:image'))\n",
              "          {\n",
              "            //document.body.appendChild(document.createTextNode('image decoded'));\n",
              "            //await \n",
              "            //displayPhoto1(message_parsed[i]);\n",
              "            //await \n",
              "            displayPhoto1(message.data.response,device.xsize,device.ysize);\n",
              "            device.time000=Date.now();\n",
              "            var frame_time=parseInt((1000/device.fps_sg2));//wg)/3);\n",
              "            var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
              "            setTimeout(displayPhoto4,next_time);\n",
              "          }\n",
              "        }\n",
              "        //else\n",
              "        {\n",
              "          //console.log(\"image not string\");\n",
              "          //displayPhoto3(message_parsed[i]);\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "      this.ready_to_send_data = true;\n",
              "  //document.body.appendChild(document.createTextNode('done2.'));\n",
              "     } \n",
              " \n",
              "    }\n",
              " \n",
              "}\n",
              " \n",
              "device = new eeg32();\n",
              " \n",
              "    connect = async () => {\n",
              "        await this.device.setupSerialAsync();\n",
              "    }\n",
              " \n",
              "    disconnect = () => {\n",
              "        if (this.ui) this.ui.deleteNode()\n",
              "        this.device.closePort();\n",
              "    }\n",
              " \n",
              " \n",
              "        //const canvas = document.createElement('canvas');\n",
              "      //const audio = document.createElement('audio');\n",
              "      //const audio1 = document.createElement('audio');\n",
              "      //const audio2 = document.createElement('audio');\n",
              "      var audios = new Array();\n",
              "      if(device.generate_wavegan)\n",
              "      {\n",
              "        const audios_length = 5;\n",
              "        for(let i = 0; i < audios_length; i++)\n",
              "        {\n",
              "          audios[i]=document.createElement('audio');\n",
              "        }\n",
              "      }\n",
              " \n",
              "          //var ctx = canvas.getContext(\"2d\");\n",
              " \n",
              "      var images = new Array();\n",
              "      var canvases = new Array();\n",
              "      if(device.generate_stylegan2)\n",
              "      {\n",
              "        const images_length = 1;\n",
              "        const canvases_length = images_length;\n",
              "        for(let i = 0; i < images_length; i++)\n",
              "        {\n",
              "          //images[i]=document.createElement('image');\n",
              "          canvases[i]=document.createElement('canvas');\n",
              "          var ctx = canvases[i].getContext(\"2d\");\n",
              "          images[i]=new Image();\n",
              "          //images[i].onload = function() {\n",
              "          //  ctx.drawImage(images[i], 0, 0);\n",
              "          //};\n",
              "        }\n",
              "      }\n",
              "      //var image = new Image();\n",
              "      //image.onload = function() {\n",
              "      //  ctx.drawImage(image, 0, 0);\n",
              "      //};\n",
              "const div = document.createElement('div');\n",
              "const div2 = document.createElement('div');\n",
              "const div3 = document.createElement('div');\n",
              "const btnconnect = document.createElement('button');\n",
              "const btndisconnect = document.createElement('button');\n",
              "const capture = document.createElement('button');\n",
              "                  \n",
              "    async function takePhoto2(quality=1) {\n",
              "      btnconnect.remove();\n",
              "      capture.remove();\n",
              "      device.ready_to_send_data = true;\n",
              "    }\n",
              " \n",
              "    async function takePhoto(quality=1) {\n",
              " \n",
              "      btnconnect.textContent = 'connect';\n",
              "      div.appendChild(btnconnect);\n",
              "      btnconnect.onclick = this.connect;\n",
              "      \n",
              "      btndisconnect.textContent = 'disconnect';\n",
              "      div.appendChild(btndisconnect);\n",
              "      btndisconnect.onclick = this.disconnect;\n",
              "      \n",
              "      capture.textContent = 'Capture';\n",
              "      capture.onclick = takePhoto2;\n",
              "      div.appendChild(capture);\n",
              "     \n",
              "      //div.appendChild(canvas);\n",
              "      //div.appendChild(audio);\n",
              "      //div.appendChild(audio1);\n",
              "      //div.appendChild(audio2);\n",
              "      if(device.generate_wavegan)\n",
              "      {\n",
              "        for(let i = 0; i < audios.length; i++)\n",
              "        {\n",
              "          div2.appendChild(audios[i]);\n",
              "          //audios[i].controls = true;\n",
              "          //audios[i].autoplay = true;\n",
              "        }\n",
              "      }\n",
              "      if(device.generate_stylegan2)\n",
              "      {\n",
              "        for(let i = 0; i <canvases.length; i++)\n",
              "        {\n",
              "          div3.appendChild(canvases[i]);\n",
              "        }\n",
              "      }\n",
              "      //for(let i = 0; i < images.length; i++)\n",
              "      //{\n",
              "      //  div.appendChild(images[i]);\n",
              "      //}\n",
              " \n",
              "      document.body.appendChild(div);\n",
              "      document.body.appendChild(div2);\n",
              "      document.body.appendChild(div3);\n",
              "         await new Promise((resolve) => capture.onclick = resolve);\n",
              " \n",
              "      btnconnect.remove();\n",
              "      capture.remove();\n",
              "      device.ready_to_send_data = true;\n",
              "    }\n",
              " \n",
              "    async function takePhoto1(quality=1) {  \n",
              "      //var data_slice_send=this.device.data_slice;\n",
              "      //var data_slice_send=[this.device.data_slice[0],this.device.data_slice[1]];\n",
              "      //var data_slice_send=[this.device.data_slice[0]];\n",
              "      var data_slice_send=[[this.device.data_slice[0][0]]];\n",
              "        //console.log(\"data_slice_send[0].length:\", data_slice_send[0].length);\n",
              "        //console.log(\"device.bufferednewLines:\", device.bufferednewLines);\n",
              "      device.bufferednewLines=0;\n",
              "      return data_slice_send;      \n",
              "    }\n",
              " \n",
              "    async function displayPhoto1(photodata,photoWidth=512,photoHeight=512) {\n",
              "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "      await displayPhoto2(photodata,photoWidth,photoHeight);\n",
              "    }\n",
              "    var image_now=0;\n",
              "    async function displayPhoto2(photodata,photoWidth,photoHeight) {\n",
              "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "     //image.src = photodata;\n",
              "      {\n",
              "       if(canvases[image_now%images.length].width != photoWidth)\n",
              "       {\n",
              "         canvases[image_now%images.length].width = photoWidth;\n",
              "       }\n",
              "       if(canvases[image_now%images.length].height != photoHeight) \n",
              "       {\n",
              "         canvases[image_now%images.length].height = photoHeight;\n",
              "       }\n",
              "       images[image_now%images.length].src = photodata;\n",
              "        //audios[audio_now%audios.length].play();\n",
              "      }\n",
              "      //image_now++;\n",
              "    }\n",
              "    async function displayPhoto4(photodata){//},photoWidth,photoHeight) {\n",
              "      ctx.drawImage(images[image_now%images.length], 0, 0);\n",
              "      image_now++;\n",
              "    }\n",
              "    var img_step=0;\n",
              "    async function displayPhoto3(photodata,photoWidth=512,photoHeight=512) {\n",
              "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "      fs.writeFile('img0.jpg', photodata, function (err) {\n",
              "        // console.log(\"save img!\" );\n",
              "      });\n",
              "      var photofile='img0.jpg?'+img_step;\n",
              "      img_step+=1;\n",
              "      //console.log(\"save img!\" );\n",
              "      await displayPhoto2(photofile,photoWidth,photoHeight);\n",
              "    }\n",
              " \n",
              "    var audio_now=0;\n",
              "    async function playAudio1(audiodata){//},photoWidth=512,photoHeight=512) {\n",
              "      //const canvas = document.createElement('canvas');\n",
              "      //if(canvas.width != photoWidth) canvas.width = photoWidth;\n",
              "      //if(canvas.height != photoHeight) canvas.height = photoHeight;\n",
              "      //audio.controls = true;\n",
              "      //audio.autoplay = true;\n",
              "      //audio1.controls = true;\n",
              "      //audio1.autoplay = true;\n",
              "      //audio2.controls = true;\n",
              "      //audio2.autoplay = true;\n",
              " \n",
              "      //canvas.getContext('2d').drawImage(photodata, 0, 0);\n",
              "      //var canvas = document.getElementById(\"c\");\n",
              "      ///var ctx = canvas.getContext(\"2d\");\n",
              " \n",
              "      ///var image = new Image();\n",
              "      ///image.onload = function() {\n",
              "      ///  ctx.drawImage(image, 0, 0);\n",
              "      ///};\n",
              "      //audio.src = audiodata;\n",
              "      //audio.play()\n",
              "      //if(audio_now%2==0)\n",
              "      //{\n",
              "      //  audio1.src = audiodata;\n",
              "      //  audio1.play()\n",
              "      //}\n",
              "      //else\n",
              "      //{\n",
              "      //  audio2.src = audiodata;\n",
              "      //  audio2.play()\n",
              "      //}\n",
              "      //for(let i = 0; i < audios.length; ++i)\n",
              "      {\n",
              "        audios[audio_now%audios.length].src = audiodata;\n",
              "        //if(audio_now==0)\n",
              "        {\n",
              "          audios[audio_now%audios.length].controls = true;\n",
              "          //audios[audio_now%audios.length].autoplay = true;\n",
              "        }\n",
              "        //audios[audio_now%audios.length].play();\n",
              "      }\n",
              "      //audio_now++;\n",
              " \n",
              "    }\n",
              "    async function playAudio2(audiodata){//},photoWidth=512,photoHeight=512) {\n",
              "      audios[audio_now%audios.length].play();\n",
              "      audio_now++;\n",
              "    }\n",
              "    \n",
              "  takePhoto();\n",
              "  data_count=0;\n",
              "\n",
              "async function check_to_send() {\n",
              "  //while(true)\n",
              "  {\n",
              "   if(device.bufferednewLines)\n",
              "   {\n",
              "    //if(this.bufferednewLines>this.data_slice_size)\n",
              "    //  {\n",
              "    //    this.bufferednewLines=this.data_slice_size;\n",
              "    //  }\n",
              "    /*device.time000=Date.now();\n",
              "    if(device.generate_wavegan)\n",
              "    {\n",
              "      device.this_frame_wg=parseInt((device.time000-device.time100)*device.fps_wg);\n",
              "      if(device.this_frame_wg>device.last_frame_wg)\n",
              "      {\n",
              "        device.last_frame_wg=device.this_frame_wg;\n",
              "        device.send_wg=true;\n",
              "      }\n",
              "    }\n",
              "    if(device.generate_stylegan2)\n",
              "    {\n",
              "      device.this_frame_sg2=parseInt((device.time000-device.time100)*device.fps_sg2);\n",
              "      if(device.this_frame_sg2>device.last_frame_sg2)\n",
              "      {\n",
              "        device.last_frame_sg2=device.this_frame_sg2;\n",
              "        device.send_sg2=true;\n",
              "      }\n",
              "    }\n",
              "    if(device.send_wg || device.send_sg2)\n",
              "    //if(this.bufferednewLines>512/(this.fps_sg2))\n",
              "    if(device.ready_to_send_data)*/\n",
              "    {\n",
              "      //this.bufferednewLines=512/this.fps;\n",
              " \n",
              "        device.takeandsendSlice(device.data.count-1-device.bufferednewLines,device.data.count-1);\n",
              "      device.send_wg=false;\n",
              "      device.send_sg2=false;\n",
              "    }\n",
              "        //console.log(\"this.bufferednewLines:\", this.bufferednewLines);\n",
              "    //this.takeSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "    //this.takeandsendSlice(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "    //this.takeandsendSliceBroadcast(this.data.count-1-this.bufferednewLines,this.data.count-1);\n",
              "   }\n",
              "  }\n",
              "  device.time000=Date.now();\n",
              "  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
              "  var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
              "  setTimeout(check_to_send,next_time);\n",
              "  //console.log(next_time);\n",
              "}\n",
              "  device.time000=Date.now();\n",
              "  var frame_time=parseInt((1000/device.fps_wg)/12);\n",
              "  var next_time=frame_time-((device.time000-device.time100)%frame_time);\n",
              "  setTimeout(check_to_send,next_time);\n",
              "  //console.log(next_time);\n",
              "//var intervalID = setInterval(check_to_send,(1000/device.fps_wg)/10);\n",
              "//  window.requestAnimationFrame\n",
              " \n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLhd7pdGj-PY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "88923b84-0c5f-47a7-db90-d13496debcd8"
      },
      "source": [
        "stop"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OBOTEr1N38s"
      },
      "source": [
        "methods = ['coh']\n",
        "#methods = ['plv']\n",
        "#methods = ['ciplv']\n",
        "#methods = ['ppc']\n",
        "#methods = ['pli']\n",
        "#methods = ['wpli']\n",
        "#methods = ['coh', 'plv', 'ciplv', 'ppc', 'pli', 'wpli']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2yUC8TD1nrT"
      },
      "source": [
        "#bands = [[4.,7.]]\n",
        "#bands = [[8.,12.]]\n",
        "bands = [[4.,7.],[8.,12.]]\n",
        "#bands = [[13.,29.]]\n",
        "#bands = [[8.,12.],[13.,29.]]\n",
        "#bands = [[4.,7.],[13.,29.]]\n",
        "#bands = [[4.,7.],[8.,12.],[13.,29.]]\n",
        "#bands = [[30.,45.]]\n",
        "#bands = [[4.,7.],[30.,45.]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1bMmefN_y0x"
      },
      "source": [
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_anime_protraits\n",
        "generate = gen_gpu | gen_tf1 | gen_wavegan | gen_drums\n",
        "#generate = gen_gpu | gen_tf1 | gen_stylegan2 | gen_sg2_ada | gen_anime_protraits | gen_wavegan | gen_drums\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dozWgxSrvC5"
      },
      "source": [
        "fps_sg2=fps_wg*2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iBp7jy5zD5X"
      },
      "source": [
        "fps_sg2=fps_wg*3\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJd_aYyNrs8J"
      },
      "source": [
        "fps_sg2=fps_wg*4"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZUBDU8frsnJ"
      },
      "source": [
        "fps_sg2=fps_wg*5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKO70vv4rr8J"
      },
      "source": [
        "fps_sg2=fps_wg*6"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnRG1eZwu3f7"
      },
      "source": [
        "xsize=int(512/2)\n",
        "ysize=int(512/2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nRQTQbGvffi"
      },
      "source": [
        "xsize=int(512/3)\n",
        "ysize=int(512/3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvcL8hjFvoOh"
      },
      "source": [
        "xsize=int(512/4)\n",
        "ysize=int(512/4)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GizuQ5TNvpZZ"
      },
      "source": [
        "xsize=int(512/5)\n",
        "ysize=int(512/5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpoZlAo8vqMJ"
      },
      "source": [
        "xsize=int(512/6)\n",
        "ysize=int(512/6)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3q-mfvIbjA"
      },
      "source": [
        "\n",
        "\n",
        "#if generate_stylegan2:\n",
        "fps_sg2=1\n",
        "#if generate_wavegan:\n",
        "fps_wg=hz/(32768*2)\n",
        "fps_sg2=fps_wg\n",
        "\n",
        "duration=2*1/fps_wg#-0.2\n",
        "#overlap=duration/32#-0.1\n",
        "#overlap=0.1\n",
        "#overlap=0\n",
        "#duration=5*1/8\n",
        "overlap=0\n",
        "#overlap=duration-0.1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxafHdQ6rP5y"
      },
      "source": [
        "fps_sg2=2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEY8ZE90g4Bl"
      },
      "source": [
        "n_sample=1\n",
        "inputSize=1024\n",
        "z = np.random.randn(n_sample, inputSize).astype(\"float32\")\n",
        "print(z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHm9yDes4i-V"
      },
      "source": [
        "stop"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NBWWs1HAzf7"
      },
      "source": [
        "video_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KubmOemcqU_4"
      },
      "source": [
        "\n",
        "from IPython import display as ipythondisplay\n",
        "import io\n",
        "import os\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "def show_video(vid):\n",
        "  ext = os.path.splitext(vid)[-1][1:]\n",
        "  video = io.open(vid, 'r+b').read()\n",
        "  ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "              loop controls style=\"height: 400px;\">\n",
        "              <source src=\"data:video/{1}';base64,{0}\" type=\"video/{1}\" />\n",
        "              </video>'''.format(base64.b64encode(video).decode('ascii'), ext)))\n",
        "\n",
        "show_video('/content/out/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRaKPKotYCq4"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/out/output.mp4')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6JXcX4OYAsw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp -r -v \"/content/out\" \"/content/gdrive/MyDrive/EEG-GAN-audio-video\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}